{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#documentation","title":"Documentation","text":"<p>now we release 1.5.3, and start developing 1.5.4</p>"},{"location":"#getting-started","title":"Getting Started","text":"Installation <p>                                     Get started with CAREamics installation.                                 </p> Current State <p>                                     Check out where we stand and where we want to go.                                 </p> Guides <p>                                     In-depth guides on CAREamics usage and features.                                 </p> Applications <p>                                     Examples of CAREamics in action on various datasets.                                 </p> Algorithms <p>                                     Dive into the various CAREamics algorithms.                                 </p> Code Reference <p>                                     Code documentation for all CAREamics libraries.                                 </p>"},{"location":"#feedback","title":"Feedback","text":"<p>We are always welcoming feedback on what to improve of what features could be useful, therefore do not hesitate to open an issue on the Github repository!</p>"},{"location":"current_state/","title":"Current state","text":"<p>CAREamics is an on-going project and will include new algorithms in the next releases.  We are currently reaching Milestone 1, which corresponds to Noise2Void in 2D and 3D.</p>"},{"location":"current_state/#milestones","title":"Milestones","text":"<p> denotes the Milestone being currently worked on.</p> <p>v0.1.0 Milestone 1: N2V </p> <ul> <li> Tooling (ruff, mypy, gh actions, pre-commit)</li> <li> TIFF dataloader</li> <li> In memory dataset</li> <li> N2V 2D/3D</li> <li> Configuration</li> <li> Training</li> <li> Prediction</li> <li> Checkpoints</li> <li> Export to bioimage.io format</li> <li> Documentation</li> </ul> <p>v0.2.0 Milestone 2: Zarr dataset, N2V2, StructN2V</p> <p>v0.3.0 Milestone 3: PN2V, PPN2V</p> <p>v0.4.0 Milestone 4: CARE, N2N, cryoCARE</p> <p>v0.5.0 Milestone 5: DivNoising, HDN</p> <p>v0.6.0 Milestone 6: DenoiSeg, UNet segmentation</p> <p>v0.7.0 Milestone 7: EmbedSeg</p>"},{"location":"installation/","title":"Installation","text":"<p>CAREamics is a deep-learning library and we therefore recommend having GPU support as training the algorithms on the CPU can be very slow. MacOS users can also benefit from GPU-acceleration if they have the new chip generations (M1, M2, etc.).</p>"},{"location":"installation/#step-by-step","title":"Step-by-step","text":"<p>We recommend using conda  (miniconda) or  mamba (miniforge) to install  all packages in a virtual environment. </p> mambaconda LinuxmacOSWindows <ol> <li>Open the terminal and type <code>mamba</code> to verify that mamba is available.</li> <li> <p>Create a new environment:</p> <pre><code>mamba create -n careamics python=3.10\nmamba activate careamics\n</code></pre> </li> <li> <p>Install PyTorch (you can find the official instructions  here):</p> <pre><code>mamba install pytorch torchvision pytorch-cuda=11.8 -c pytorch -c nvidia\n</code></pre> </li> <li> <p>Verify that the GPU is available:</p> <pre><code>python -c \"import torch; print([torch.cuda.get_device_properties(i) for i in range(torch.cuda.device_count())])\"\n</code></pre> <p>This should show a list of available GPUs. If the list is empty, then you will need to change the <code>pytorch</code> and <code>pytorch-cuda</code> versions to match your hardware.</p> </li> <li> <p>Install CAREamics:</p> <pre><code>pip install --pre \"careamics[all]\"\n</code></pre> </li> </ol> <p>These instructions were tested on a linux virtual machine (RedHat 8.6) with a  NVIDIA A40-8Q GPU.</p> <p>(Instructions to come)</p> <p>In Windows systems, we will use unix-style commands. To do so, we recommend installing Git for Windows and using it as your terminal.</p> <p>(Instructions to come)</p> LinuxmacOSWindows <ol> <li>Open the terminal and type <code>mamba</code> to verify that mamba is available.</li> <li> <p>Create a new environment:</p> <pre><code>conda create -n careamics python=3.10\nconda activate careamics\n</code></pre> </li> <li> <p>Install PyTorch (you can find the official instructions  here):</p> <pre><code>conda install pytorch torchvision pytorch-cuda=11.8 -c pytorch -c nvidia\n</code></pre> </li> <li> <p>Verify that the GPU is available:</p> <pre><code>python -c \"import torch; print([torch.cuda.get_device_properties(i) for i in range(torch.cuda.device_count())])\"\n</code></pre> <p>This should show a list of available GPUs. If the list is empty, then you will need to change the <code>pytorch</code> and <code>pytorch-cuda</code> versions to match your hardware.</p> </li> <li> <p>Install CAREamics:</p> <pre><code>pip install --pre \"careamics[all]\"\n</code></pre> </li> </ol> <p>These instructions were tested on a linux virtual machine (RedHat 8.6) with a  NVIDIA A40-8Q GPU.</p> <p>(Instructions to come)</p> <p>In Windows systems, we will use unix-style commands. To do so, we recommend installing Git for Windows and using it as your terminal.</p> <p>(Instructions to come)</p>"},{"location":"installation/#quickstart","title":"Quickstart","text":"<p>Once you have installed CAREamics, the easiest way to get started is to look at the applications for full examples and the  guides for in-depth tweaking.</p>"},{"location":"algorithms/","title":"Algorithms","text":"Noise2Void <p>                                     A self-supervised denoising algorithm.                                 </p>"},{"location":"algorithms/n2v/","title":"Noise2Void","text":"<p>Noise2Void (N2V) is a self-supervised denoising method. It trains by randomly masking pixels in the input image and predicting their masked value from the surrounding pixels.</p> <p>N2V relies on two fundamental hypotheses:</p> <ul> <li>The underlying structures are continuous</li> <li>The noise is pixel-wise independent</li> </ul> <p>The corollory from these hypotheses is that if we consider the value of a pixel being the sum of the true signal value and a certain amount of noise, then:</p> <ul> <li>The true signal value can be estimated from the surrounding pixels</li> <li>The noise cannot be estimated from the surrounding pixels</li> </ul> <p>Therefore, in cases where the hypotheses hold, N2V can be use to estimate the true signal and thereby removing the noise.</p>"},{"location":"algorithms/n2v/#reference","title":"Reference","text":"<p>Alexander Krull, Tim-Oliver Buchholz, and Florian Jug. \"Noise2Void - learning denoising from single noisy images.\" Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition, 2019.</p> <p>Joshua Batson, and Loic Royer. \"Noise2Self: Blind denoising by self-supervision.\"  International Conference on Machine Learning. Proceedings of Machine Learning Research, 2019.</p>"},{"location":"applications/","title":"Applications","text":"<p>This section contains a list of example applications.</p>"},{"location":"applications/#n2v","title":"N2V","text":"<ul> <li>2D SEM</li> </ul>"},{"location":"applications/SUMMARY/","title":"SUMMARY","text":"<ul> <li>Applications</li> <li>N2V<ul> <li>2D SEM</li> </ul> </li> </ul>"},{"location":"applications/N2V/2D_SEM/","title":"2D SEM","text":"In\u00a0[\u00a0]: Copied! <pre>import pprint\nimport shutil\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport tifffile\nfrom careamics_portfolio import PortfolioManager\nfrom matplotlib.pyplot import imshow\n\nfrom careamics.engine import Engine\n</pre> import pprint import shutil from pathlib import Path  import matplotlib.pyplot as plt import tifffile from careamics_portfolio import PortfolioManager from matplotlib.pyplot import imshow  from careamics.engine import Engine In\u00a0[\u00a0]: Copied! <pre># Explore portfolio\nportfolio = PortfolioManager()\nprint(portfolio.denoising)\n</pre> # Explore portfolio portfolio = PortfolioManager() print(portfolio.denoising) In\u00a0[\u00a0]: Copied! <pre># Download files\nroot_path = Path(\"./data\")\nfiles = portfolio.denoising.N2V_SEM.download(root_path)\nprint(f\"List of downloaded files: {files}\")\n</pre> # Download files root_path = Path(\"./data\") files = portfolio.denoising.N2V_SEM.download(root_path) print(f\"List of downloaded files: {files}\") In\u00a0[\u00a0]: Copied! <pre># Load images\ntrain_image = tifffile.imread(files[0])\nprint(f\"Train image shape: {train_image.shape}\")\nimshow(train_image, cmap=\"gray\")\n</pre> # Load images train_image = tifffile.imread(files[0]) print(f\"Train image shape: {train_image.shape}\") imshow(train_image, cmap=\"gray\") In\u00a0[\u00a0]: Copied! <pre>val_image = tifffile.imread(files[1])\nprint(f\"Validation image shape: {val_image.shape}\")\nimshow(val_image, cmap=\"gray\")\n</pre> val_image = tifffile.imread(files[1]) print(f\"Validation image shape: {val_image.shape}\") imshow(val_image, cmap=\"gray\") In\u00a0[\u00a0]: Copied! <pre>data_path = Path(root_path / \"n2v_sem\")\ntrain_path = data_path / \"train\"\nval_path = data_path / \"val\"\n\ntrain_path.mkdir(parents=True, exist_ok=True)\nval_path.mkdir(parents=True, exist_ok=True)\n\nshutil.copy(root_path / files[0], train_path / \"train_image.tif\")\nshutil.copy(root_path / files[1], val_path / \"val_image.tif\")\n</pre> data_path = Path(root_path / \"n2v_sem\") train_path = data_path / \"train\" val_path = data_path / \"val\"  train_path.mkdir(parents=True, exist_ok=True) val_path.mkdir(parents=True, exist_ok=True)  shutil.copy(root_path / files[0], train_path / \"train_image.tif\") shutil.copy(root_path / files[1], val_path / \"val_image.tif\") In\u00a0[\u00a0]: Copied! <pre>engine = Engine(config_path=\"n2v_2D_SEM.yml\")\n</pre> engine = Engine(config_path=\"n2v_2D_SEM.yml\") In\u00a0[\u00a0]: Copied! <pre>pprint.PrettyPrinter(indent=2).pprint(engine.cfg.model_dump(exclude_optionals=False))\n</pre> pprint.PrettyPrinter(indent=2).pprint(engine.cfg.model_dump(exclude_optionals=False)) In\u00a0[\u00a0]: Copied! <pre>train_stats, val_stats = engine.train(train_path=train_path, val_path=val_path)\n</pre> train_stats, val_stats = engine.train(train_path=train_path, val_path=val_path) In\u00a0[\u00a0]: Copied! <pre>plt.plot([next(iter(d.values())) for d in train_stats], label=\"Train loss\")\nplt.plot([next(iter(d.values())) for d in val_stats], label=\"Validation loss\")\nplt.legend(loc=\"best\")\nplt.xlabel(\"Epoch\")\n</pre> plt.plot([next(iter(d.values())) for d in train_stats], label=\"Train loss\") plt.plot([next(iter(d.values())) for d in val_stats], label=\"Validation loss\") plt.legend(loc=\"best\") plt.xlabel(\"Epoch\") In\u00a0[\u00a0]: Copied! <pre>preds = engine.predict(input=train_path, tile_shape=[256, 256], overlaps=[48, 48])\n</pre> preds = engine.predict(input=train_path, tile_shape=[256, 256], overlaps=[48, 48]) In\u00a0[\u00a0]: Copied! <pre>imshow(preds.squeeze(), cmap=\"gray\")\n</pre> imshow(preds.squeeze(), cmap=\"gray\") In\u00a0[\u00a0]: Copied! <pre>engine.save_as_bioimage(engine.cfg.experiment_name + \"bioimage.zip\")\n</pre> engine.save_as_bioimage(engine.cfg.experiment_name + \"bioimage.zip\") In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"applications/N2V/2D_SEM/#import-dataset-portfolio","title":"Import Dataset Portfolio\u00b6","text":""},{"location":"applications/N2V/2D_SEM/#visualize-training-data","title":"Visualize training data\u00b6","text":""},{"location":"applications/N2V/2D_SEM/#visualize-validation-data","title":"Visualize validation data\u00b6","text":""},{"location":"applications/N2V/2D_SEM/#initialize-the-engine","title":"Initialize the Engine\u00b6","text":"<p>Engine contains the dataloading pipeline and the model training logic. We'll initialize the engine with the config file, but it can also be initialized from a pre-trained checkpoint.</p> <p>Please take as look at the documentation to see the full list of parameters and configuration options</p>"},{"location":"applications/N2V/2D_SEM/#visualize-training-configuration","title":"Visualize training configuration\u00b6","text":""},{"location":"applications/N2V/2D_SEM/#run-training","title":"Run training\u00b6","text":"<p>We need to specify the paths to training and validation data</p>"},{"location":"applications/N2V/2D_SEM/#visualize-statistics","title":"Visualize statistics\u00b6","text":""},{"location":"applications/N2V/2D_SEM/#run-prediction","title":"Run prediction\u00b6","text":"<p>We need to specify the path to the data we want to denoise</p>"},{"location":"applications/N2V/2D_SEM/#visualize-the-prediction","title":"Visualize the prediction\u00b6","text":""},{"location":"applications/N2V/2D_SEM/#export-to-bioimageio","title":"Export to bioimage.io\u00b6","text":""},{"location":"guides/","title":"Guides","text":"<p>In this section, we provide a few key examples on how to use CAREamics. The general API is the following:</p> <pre><code># Create or modify a configuration\nmy_config = Configuration(\"path/to/config.yml\")\n\n# Instantiate an Engine to train a model\nengine = Engine(config=my_config)\n\n# Train using your data\nengine.train(\n    train_path=\"path/to/training/folder\", \n    val_path=\"path/to/validation/folder\"\n)\n\n# Save your model as a Bioimage Model Zoo model\nengine.save_as_bioimage(\"path/to/model.bioimage.io.zip\")\n\n# After training, you can predict on new data\nprediction = engine.predict(input=my_array)\n</code></pre>"},{"location":"guides/#categories","title":"Categories","text":"<ul> <li>Configuration: how to configure CAREamics.</li> <li>Engine: how to train and predict with CAREamics.</li> <li>Bioimage.io export: export and import CAREamics models.</li> </ul>"},{"location":"guides/bmz/","title":"BioImage.io","text":"<p>(More to come)</p>"},{"location":"guides/configuration/","title":"Configuration","text":"<p>CAREamics relies on a configuration, either a Python object or a <code>.yml</code> file. The configuration holds all the information necessary to train a CAREamics model.</p>"},{"location":"guides/configuration/#minimum-configuration","title":"Minimum configuration","text":"Minimum <code>.yml</code> file example <pre><code>working_directory: .\nexperiment_name: ConfigTest\n\nalgorithm:\n    is_3D: false\n    loss: n2v\n    model: UNet\n\ndata:\n    axes: SYX\n    data_format: tif\n    in_memory: true\n\ntraining:\n    augmentation: true\n    batch_size: 16\n    lr_scheduler:\n        name: ReduceLROnPlateau\n    num_epochs: 100\n    optimizer:\n        name: Adam\n    patch_size: [64,64]\n</code></pre>"},{"location":"guides/configuration/#in-depth","title":"In-depth","text":"<ul> <li>Full description</li> <li>Instantiate a configuration</li> <li>Modify a configuration</li> <li>Import/export a configuration</li> </ul>"},{"location":"guides/configuration/config_description/","title":"Description","text":"<p>In this section, we take a look at the full configuration and the various parameters that can be set.</p> <p>CAREamics configuration is a Pydantic model,  that contains the following hierarchy:</p> <ul> <li>General parameters</li> <li>Algorithm</li> <li>Training</li> <li>Data</li> </ul> <p>(More to come)</p>"},{"location":"guides/engine/","title":"Engine","text":"<p>The <code>Engine</code> class is the main class of CAREamics. It is used to train and predict with CAREamics models.</p>"},{"location":"guides/engine/#create-an-engine-object","title":"Create an Engine object","text":"<p>There are three ways to create an <code>Engine</code> object:</p> <ul> <li>Provide a configuration (object)</li> <li>Provide a configuration file (path)</li> <li>Provide a model (path)</li> </ul> from a Configuration objectfrom a Configuration <code>.yaml</code>from a Model <pre><code>from careamics import Configuration, Engine\n\n# create configuration\nparameters = {...} # see Configuration section\nconfig = Configuration(**parameters)\n\n# create engine\nengine = Engine(config=config)\n</code></pre> <pre><code>from careamics import Engine\n\n# create engine\nengine = Engine(config_path=\"path/to/file\")\n</code></pre> <pre><code>from careamics import Engine\n\n# create engine\nengine = Engine(model_path=\"path/to/model\")\n</code></pre>"},{"location":"guides/engine/#usage","title":"Usage","text":"<p>Here are a few in-depth tutorials for how to use the CAREamics engine:</p> <ul> <li>Train a model</li> <li>Predict with a model</li> <li>Export a model</li> <li>Re-train a model</li> </ul>"},{"location":"guides/engine/#frequently-asked-questions","title":"Frequently asked questions","text":"<p>(coming soon)</p>"},{"location":"guides/engine/prediction/","title":"Prediction","text":"<pre><code>preds = engine.predict(input=train_path, tile_shape=[256, 256], overlaps=[48, 48])\n</code></pre>"},{"location":"guides/engine/training/","title":"Training","text":"<p>Training CAREamics is done via a single call to the <code>train</code> method of the <code>Engine</code>:</p> <pre><code># paths to the training and validation data\ntrain_path = ...\nval_path = ...\n\n# train the Engine\ntrain_stats, val_stats = engine.train(train_path=train_path, val_path=val_path)\n</code></pre>"},{"location":"guides/engine/training/#frequently-asked-questions","title":"Frequently asked questions","text":"<ul> <li>No validation data (train N2V on a single image)</li> </ul>"},{"location":"reference/","title":"Code Reference","text":"CAREamics CAREamics portfolio"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>index.md</li> <li>careamics<ul> <li>index.md</li> <li>bioimage<ul> <li>io</li> <li>rdf</li> </ul> </li> <li>config<ul> <li>algorithm</li> <li>config</li> <li>config_filter</li> <li>data</li> <li>torch_optim</li> <li>training</li> </ul> </li> <li>dataset<ul> <li>dataset_utils</li> <li>extraction_strategy</li> <li>in_memory_dataset</li> <li>patching</li> <li>prepare_dataset</li> <li>tiff_dataset</li> </ul> </li> <li>engine</li> <li>losses<ul> <li>loss_factory</li> <li>losses</li> </ul> </li> <li>manipulation<ul> <li>pixel_manipulation</li> </ul> </li> <li>models<ul> <li>layers</li> <li>model_factory</li> <li>unet</li> </ul> </li> <li>prediction<ul> <li>prediction_utils</li> </ul> </li> <li>utils<ul> <li>augment</li> <li>context</li> <li>logging</li> <li>metrics</li> <li>normalization</li> <li>torch_utils</li> <li>validators</li> <li>wandb</li> </ul> </li> </ul> </li> <li>careamics_portfolio<ul> <li>index.md</li> <li>denoiseg_datasets</li> <li>denoising_datasets</li> <li>portfolio</li> <li>portfolio_entry</li> <li>utils<ul> <li>download_utils</li> <li>pale_blue_dot</li> <li>pale_blue_dot_zip</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/careamics/","title":"CAREamics","text":"<p>Use the navigation index on the left to explore the documentation.</p>"},{"location":"reference/careamics/engine/","title":"engine","text":"<p>Engine module.</p> <p>This module contains the main CAREamics class, the Engine. The Engine allows training a model and using it for prediction.</p>"},{"location":"reference/careamics/engine/#careamics.engine.Engine","title":"<code>Engine</code>","text":"<p>Class allowing training of a model and subsequent prediction.</p> <p>There are three ways to instantiate an Engine: 1. With a CAREamics model (.pth), by passing a path. 2. With a configuration object. 3. With a configuration file, by passing a path.</p> <p>In each case, the parameter name must be provided explicitly. For example:</p> <p>engine = Engine(config_path=\"path/to/config.yaml\")</p> <p>Note that only one of these options can be used at a time, in the order listed above.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Optional[Configuration]</code> <p>Configuration object, by default None.</p> <code>None</code> <code>config_path</code> <code>Optional[Union[str, Path]]</code> <p>Path to configuration file, by default None.</p> <code>None</code> <code>model_path</code> <code>Optional[Union[str, Path]]</code> <p>Path to model file, by default None.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Seed for reproducibility, by default 42.</p> <code>42</code> <p>Attributes:</p> Name Type Description <code>cfg</code> <code>Configuration</code> <p>Configuration.</p> <code>device</code> <code>device</code> <p>Device (CPU or GPU).</p> <code>model</code> <code>Module</code> <p>Model.</p> <code>optimizer</code> <code>Optimizer</code> <p>Optimizer.</p> <code>lr_scheduler</code> <code>_LRScheduler</code> <p>Learning rate scheduler.</p> <code>scaler</code> <code>GradScaler</code> <p>Gradient scaler.</p> <code>loss_func</code> <code>Callable</code> <p>Loss function.</p> <code>logger</code> <code>Logger</code> <p>Logger.</p> <code>use_wandb</code> <code>bool</code> <p>Whether to use wandb.</p> Source code in <code>src/careamics/engine.py</code> <pre><code>class Engine:\n    \"\"\"\n    Class allowing training of a model and subsequent prediction.\n\n    There are three ways to instantiate an Engine:\n    1. With a CAREamics model (.pth), by passing a path.\n    2. With a configuration object.\n    3. With a configuration file, by passing a path.\n\n    In each case, the parameter name must be provided explicitly. For example:\n    &gt;&gt;&gt; engine = Engine(config_path=\"path/to/config.yaml\")\n\n    Note that only one of these options can be used at a time, in the order listed\n    above.\n\n    Parameters\n    ----------\n    config : Optional[Configuration], optional\n        Configuration object, by default None.\n    config_path : Optional[Union[str, Path]], optional\n        Path to configuration file, by default None.\n    model_path : Optional[Union[str, Path]], optional\n        Path to model file, by default None.\n    seed : int, optional\n        Seed for reproducibility, by default 42.\n\n    Attributes\n    ----------\n    cfg : Configuration\n        Configuration.\n    device : torch.device\n        Device (CPU or GPU).\n    model : torch.nn.Module\n        Model.\n    optimizer : torch.optim.Optimizer\n        Optimizer.\n    lr_scheduler : torch.optim.lr_scheduler._LRScheduler\n        Learning rate scheduler.\n    scaler : torch.cuda.amp.GradScaler\n        Gradient scaler.\n    loss_func : Callable\n        Loss function.\n    logger : logging.Logger\n        Logger.\n    use_wandb : bool\n        Whether to use wandb.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        config: Optional[Configuration] = None,\n        config_path: Optional[Union[str, Path]] = None,\n        model_path: Optional[Union[str, Path]] = None,\n        seed: Optional[int] = 42,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        To disable the seed, set it to None.\n\n        Parameters\n        ----------\n        config : Optional[Configuration], optional\n            Configuration object, by default None.\n        config_path : Optional[Union[str, Path]], optional\n            Path to configuration file, by default None.\n        model_path : Optional[Union[str, Path]], optional\n            Path to model file, by default None.\n        seed : int, optional\n            Seed for reproducibility, by default 42.\n\n        Raises\n        ------\n        ValueError\n            If all three parameters are None.\n        FileNotFoundError\n            If the model or configuration path is provided but does not exist.\n        TypeError\n            If the configuration is not a Configuration object.\n        UsageError\n            If wandb is not correctly installed.\n        ModuleNotFoundError\n            If wandb is not installed.\n        ValueError\n            If the configuration failed to configure.\n        \"\"\"\n        if model_path is not None:\n            if not Path(model_path).exists():\n                raise FileNotFoundError(\n                    f\"Model path {model_path} is incorrect or\"\n                    f\" does not exist. Current working directory is: {Path.cwd()!s}\"\n                )\n\n            # Ensure that config is None\n            self.cfg = None\n\n        elif config is not None:\n            # Check that config is a Configuration object\n            if not isinstance(config, Configuration):\n                raise TypeError(\n                    f\"config must be a Configuration object, got {type(config)}\"\n                )\n            self.cfg = config\n        elif config_path is not None:\n            self.cfg = load_configuration(config_path)\n        else:\n            raise ValueError(\n                \"No configuration or path provided. One of configuration \"\n                \"object, configuration path or model path must be provided.\"\n            )\n\n        # get device, CPU or GPU\n        self.device = get_device()\n\n        # Create model, optimizer, lr scheduler and gradient scaler and load everything\n        # to the specified device\n        (\n            self.model,\n            self.optimizer,\n            self.lr_scheduler,\n            self.scaler,\n            self.cfg,\n        ) = create_model(config=self.cfg, model_path=model_path, device=self.device)\n        assert self.cfg is not None\n\n        # create loss function\n        self.loss_func = create_loss_function(self.cfg)\n\n        # Set logging\n        log_path = self.cfg.working_directory / \"log.txt\"\n        self.logger = get_logger(__name__, log_path=log_path)\n\n        # wandb\n        self.use_wandb = self.cfg.training.use_wandb\n\n        if self.use_wandb:\n            try:\n                from wandb.errors import UsageError\n\n                from careamics.utils.wandb import WandBLogging\n\n                try:\n                    self.wandb = WandBLogging(\n                        experiment_name=self.cfg.experiment_name,\n                        log_path=self.cfg.working_directory,\n                        config=self.cfg,\n                        model_to_watch=self.model,\n                    )\n                except UsageError as e:\n                    self.logger.warning(\n                        f\"Wandb usage error, using default logger. Check whether \"\n                        f\"wandb correctly configured:\\n\"\n                        f\"{e}\"\n                    )\n                    self.use_wandb = False\n\n            except ModuleNotFoundError:\n                self.logger.warning(\n                    \"Wandb not installed, using default logger. Try pip install \"\n                    \"wandb\"\n                )\n                self.use_wandb = False\n\n        # BMZ inputs/outputs placeholders, filled during validation\n        self._input = None\n        self._outputs = None\n\n        # torch version\n        self.torch_version = torch.__version__\n\n    def train(\n        self,\n        train_path: str,\n        val_path: str,\n    ) -&gt; Tuple[List[Any], List[Any]]:\n        \"\"\"\n        Train the network.\n\n        The training and validation data given by the paths must be compatible with the\n        axes and data format provided in the configuration.\n\n        Parameters\n        ----------\n        train_path : Union[str, Path]\n            Path to the training data.\n        val_path : Union[str, Path]\n            Path to the validation data.\n\n        Returns\n        -------\n        Tuple[List[Any], List[Any]]\n            Tuple of training and validation statistics.\n\n        Raises\n        ------\n        ValueError\n            Raise a ValueError if the configuration is missing.\n        \"\"\"\n        if self.cfg is None:\n            raise ValueError(\"Configuration is not defined, cannot train.\")\n\n        # General func\n        train_loader = self._get_train_dataloader(train_path)\n\n        # Set mean and std from train dataset of none\n        if self.cfg.data.mean is None or self.cfg.data.std is None:\n            self.cfg.data.set_mean_and_std(\n                train_loader.dataset.mean, train_loader.dataset.std\n            )\n\n        eval_loader = self._get_val_dataloader(val_path)\n        self.logger.info(f\"Starting training for {self.cfg.training.num_epochs} epochs\")\n\n        val_losses = []\n\n        try:\n            train_stats = []\n            eval_stats = []\n\n            # loop over the dataset multiple times\n            for epoch in range(self.cfg.training.num_epochs):\n                if hasattr(train_loader.dataset, \"__len__\"):\n                    epoch_size = train_loader.__len__()\n                else:\n                    epoch_size = None\n\n                progress_bar = ProgressBar(\n                    max_value=epoch_size,\n                    epoch=epoch,\n                    num_epochs=self.cfg.training.num_epochs,\n                    mode=\"train\",\n                )\n                # train_epoch = train_op(self._train_single_epoch,)\n                # Perform training step\n                train_outputs, epoch_size = self._train_single_epoch(\n                    train_loader,\n                    progress_bar,\n                    self.cfg.training.amp.use,\n                )\n                # Perform validation step\n                eval_outputs = self._evaluate(eval_loader)\n                val_losses.append(eval_outputs[\"loss\"])\n                learning_rate = self.optimizer.param_groups[0][\"lr\"]\n\n                progress_bar.add(\n                    1,\n                    values=[\n                        (\"train_loss\", train_outputs[\"loss\"]),\n                        (\"val loss\", eval_outputs[\"loss\"]),\n                        (\"lr\", learning_rate),\n                    ],\n                )\n                # Add update scheduler rule based on type\n                self.lr_scheduler.step(eval_outputs[\"loss\"])\n\n                if self.use_wandb:\n                    metrics = {\n                        \"train\": train_outputs,\n                        \"eval\": eval_outputs,\n                        \"lr\": learning_rate,\n                    }\n                    self.wandb.log_metrics(metrics)\n\n                train_stats.append(train_outputs)\n                eval_stats.append(eval_outputs)\n\n                checkpoint_path = self._save_checkpoint(epoch, val_losses, \"state_dict\")\n                self.logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n\n        except KeyboardInterrupt:\n            self.logger.info(\"Training interrupted\")\n\n        return train_stats, eval_stats\n\n    def _train_single_epoch(\n        self,\n        loader: torch.utils.data.DataLoader,\n        progress_bar: ProgressBar,\n        amp: bool,\n    ) -&gt; Tuple[Dict[str, float], int]:\n        \"\"\"\n        Train for a single epoch.\n\n        Parameters\n        ----------\n        loader : torch.utils.data.DataLoader\n            Training dataloader.\n        progress_bar : ProgressBar\n            Progress bar.\n        amp : bool\n            Whether to use automatic mixed precision.\n\n        Returns\n        -------\n        Tuple[Dict[str, float], int]\n            Tuple of training metrics and epoch size.\n\n        Raises\n        ------\n        ValueError\n            If the configuration is missing.\n        \"\"\"\n        if self.cfg is not None:\n            avg_loss = MetricTracker()\n            self.model.train()\n            epoch_size = 0\n\n            for i, (batch, *auxillary) in enumerate(loader):\n                self.optimizer.zero_grad(set_to_none=True)\n\n                with torch.cuda.amp.autocast(enabled=amp):\n                    outputs = self.model(batch.to(self.device))\n\n                loss = self.loss_func(\n                    outputs, *[a.to(self.device) for a in auxillary], self.device\n                )\n                self.scaler.scale(loss).backward()\n                avg_loss.update(loss.detach(), batch.shape[0])\n\n                progress_bar.update(\n                    current_step=i,\n                    batch_size=self.cfg.training.batch_size,\n                )\n\n                self.optimizer.step()\n                epoch_size += 1\n\n            return {\"loss\": avg_loss.avg.to(torch.float16).cpu().numpy()}, epoch_size\n        else:\n            raise ValueError(\"Configuration is not defined, cannot train.\")\n\n    def _evaluate(self, val_loader: torch.utils.data.DataLoader) -&gt; Dict[str, float]:\n        \"\"\"\n        Perform validation step.\n\n        Parameters\n        ----------\n        val_loader : torch.utils.data.DataLoader\n            Validation dataloader.\n\n        Returns\n        -------\n        Dict[str, float]\n            Loss value on the validation set.\n        \"\"\"\n        self.model.eval()\n        avg_loss = MetricTracker()\n\n        with torch.no_grad():\n            for patch, *auxillary in val_loader:\n                # if inputs is None, record a single patch\n                if self._input is None:\n                    # patch has dimension SC(Z)YX\n                    self._input = patch.clone().detach().cpu().numpy()\n\n                # evaluate\n                outputs = self.model(patch.to(self.device))\n                loss = self.loss_func(\n                    outputs, *[a.to(self.device) for a in auxillary], self.device\n                )\n                avg_loss.update(loss.detach(), patch.shape[0])\n        return {\"loss\": avg_loss.avg.to(torch.float16).cpu().numpy()}\n\n    def predict(\n        self,\n        input: Union[np.ndarray, str, Path],\n        *,\n        tile_shape: Optional[List[int]] = None,\n        overlaps: Optional[List[int]] = None,\n        axes: Optional[str] = None,\n        tta: bool = True,\n    ) -&gt; Union[np.ndarray, List[np.ndarray]]:\n        \"\"\"\n        Predict using the current model on an input array or a path to data.\n\n        The Engine must have previously been trained and mean/std be specified in\n        its configuration.\n\n        Data should be compatible with the axes, either from the configuration or\n        as passed using the `axes` parameter. If the batch and channel dimensions are\n        missing, then singleton dimensions are added.\n\n        To use tiling, both `tile_shape` and `overlaps` must be specified, have same\n        length, be divisible by 2 and greater than 0. Finally, the overlaps must be\n        smaller than the tiles.\n\n        By setting `tta` to `True`, the prediction is performed using test time\n        augmentation, meaning that the input is augmented and the prediction is averaged\n        over the augmentations.\n\n        Parameters\n        ----------\n        input : Union[np.ndarra, str, Path]\n            Input data, either an array or a path to the data.\n        tile_shape : Optional[List[int]], optional\n            2D or 3D shape of the tiles to be predicted, by default None.\n        overlaps : Optional[List[int]], optional\n            2D or 3D overlaps between tiles, by default None.\n        axes : Optional[str], optional\n            Axes of the input array if different from the one in the configuration, by\n            default None.\n        tta : bool, optional\n            Whether to use test time augmentation, by default True.\n\n        Returns\n        -------\n        Union[np.ndarray, List[np.ndarray]]\n            Predicted image array of the same shape as the input, or list of arrays\n            if the arrays have inconsistent shapes.\n\n        Raises\n        ------\n        ValueError\n            If the configuration is missing.\n        ValueError\n            If the mean or std are not specified in the configuration (untrained model).\n        \"\"\"\n        if self.cfg is None:\n            raise ValueError(\"Configuration is not defined, cannot predict.\")\n\n        # Check that the mean and std are there (= has been trained)\n        if not self.cfg.data.mean or not self.cfg.data.std:\n            raise ValueError(\n                \"Mean or std are not specified in the configuration, prediction cannot \"\n                \"be performed.\"\n            )\n\n        # set model to eval mode\n        self.model.to(self.device)\n        self.model.eval()\n\n        progress_bar = ProgressBar(num_epochs=1, mode=\"predict\")\n\n        # Get dataloader\n        pred_loader, tiled = self._get_predict_dataloader(\n            input=input, tile_shape=tile_shape, overlaps=overlaps, axes=axes\n        )\n\n        # Start prediction\n        self.logger.info(\"Starting prediction\")\n        if tiled:\n            self.logger.info(\"Starting tiled prediction\")\n            prediction = self._predict_tiled(pred_loader, progress_bar, tta)\n        else:\n            self.logger.info(\"Starting prediction on whole sample\")\n            prediction = self._predict_full(pred_loader, progress_bar, tta)\n\n        return prediction\n\n    def _predict_tiled(\n        self, pred_loader: DataLoader, progress_bar: ProgressBar, tta: bool = True\n    ) -&gt; Union[np.ndarray, List[np.ndarray]]:\n        \"\"\"\n        Predict using tiling.\n\n        Parameters\n        ----------\n        pred_loader : DataLoader\n            Prediction dataloader.\n        progress_bar : ProgressBar\n            Progress bar.\n        tta : bool, optional\n            Whether to use test time augmentation, by default True.\n\n        Returns\n        -------\n        Union[np.ndarray, List[np.ndarray]]\n            Predicted image, or list of predictions if the images have different sizes.\n\n        Warns\n        -----\n        UserWarning\n            If the samples have different shapes, the prediction then returns a list.\n        \"\"\"\n        # checks are done here to satisfy mypy\n        # check that configuration exists\n        if self.cfg is None:\n            raise ValueError(\"Configuration is not defined, cannot predict.\")\n\n        # Check that the mean and std are there (= has been trained)\n        if not self.cfg.data.mean or not self.cfg.data.std:\n            raise ValueError(\n                \"Mean or std are not specified in the configuration, prediction cannot \"\n                \"be performed.\"\n            )\n\n        prediction = []\n        tiles = []\n        stitching_data = []\n\n        with torch.no_grad():\n            for i, (tile, *auxillary) in enumerate(pred_loader):\n                # Unpack auxillary data into last tile indicator and data, required to\n                # stitch tiles together\n                if auxillary:\n                    last_tile, *data = auxillary\n\n                if tta:\n                    augmented_tiles = tta_forward(tile)\n                    predicted_augments = []\n                    for augmented_tile in augmented_tiles:\n                        augmented_pred = self.model(augmented_tile.to(self.device))\n                        predicted_augments.append(augmented_pred.cpu())\n                    tiles.append(tta_backward(predicted_augments).squeeze())\n                else:\n                    tiles.append(\n                        self.model(tile.to(self.device)).squeeze().cpu().numpy()\n                    )\n\n                stitching_data.append(data)\n\n                if last_tile:\n                    # Stitch tiles together if sample is finished\n                    predicted_sample = stitch_prediction(tiles, stitching_data)\n                    predicted_sample = denormalize(\n                        predicted_sample,\n                        float(self.cfg.data.mean),\n                        float(self.cfg.data.std),\n                    )\n                    prediction.append(predicted_sample)\n                    tiles.clear()\n                    stitching_data.clear()\n\n                progress_bar.update(i, 1)\n        if tta:\n            i = int(i / 8)\n        self.logger.info(f\"Predicted {len(prediction)} samples, {i} tiles in total\")\n        try:\n            return np.stack(prediction)\n        except ValueError:\n            self.logger.warning(\"Samples have different shapes, returning list.\")\n            return prediction\n\n    def _predict_full(\n        self, pred_loader: DataLoader, progress_bar: ProgressBar, tta: bool = True\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Predict whole image without tiling.\n\n        Parameters\n        ----------\n        pred_loader : DataLoader\n            Prediction dataloader.\n        progress_bar : ProgressBar\n            Progress bar.\n        tta : bool, optional\n            Whether to use test time augmentation, by default True.\n\n        Returns\n        -------\n        np.ndarray\n            Predicted image.\n        \"\"\"\n        # checks are done here to satisfy mypy\n        # check that configuration exists\n        if self.cfg is None:\n            raise ValueError(\"Configuration is not defined, cannot predict.\")\n\n        # Check that the mean and std are there (= has been trained)\n        if not self.cfg.data.mean or not self.cfg.data.std:\n            raise ValueError(\n                \"Mean or std are not specified in the configuration, prediction cannot \"\n                \"be performed.\"\n            )\n\n        prediction = []\n        with torch.no_grad():\n            for i, sample in enumerate(pred_loader):\n                if tta:\n                    augmented_preds = tta_forward(sample[0])\n                    predicted_augments = []\n                    for augmented_pred in augmented_preds:\n                        augmented_pred = self.model(augmented_pred.to(self.device))\n                        predicted_augments.append(augmented_pred.cpu())\n                    prediction.append(tta_backward(predicted_augments).squeeze())\n                else:\n                    prediction.append(\n                        self.model(sample[0].to(self.device)).squeeze().cpu().numpy()\n                    )\n                progress_bar.update(i, 1)\n        output = denormalize(\n            np.stack(prediction).squeeze(),\n            float(self.cfg.data.mean),\n            float(self.cfg.data.std),\n        )\n        return output\n\n    def _get_train_dataloader(self, train_path: str) -&gt; DataLoader:\n        \"\"\"\n        Return a training dataloader.\n\n        Parameters\n        ----------\n        train_path : str\n            Path to the training data.\n\n        Returns\n        -------\n        DataLoader\n            Training data loader.\n\n        Raises\n        ------\n        ValueError\n            If the training configuration is None.\n        \"\"\"\n        if self.cfg is None:\n            raise ValueError(\"Configuration is not defined.\")\n\n        dataset = get_train_dataset(self.cfg, train_path)\n        dataloader = DataLoader(\n            dataset,\n            batch_size=self.cfg.training.batch_size,\n            num_workers=self.cfg.training.num_workers,\n            pin_memory=True,\n        )\n        return dataloader\n\n    def _get_val_dataloader(self, val_path: str) -&gt; DataLoader:\n        \"\"\"\n        Return a validation dataloader.\n\n        Parameters\n        ----------\n        val_path : str\n            Path to the validation data.\n\n        Returns\n        -------\n        DataLoader\n            Validation data loader.\n\n        Raises\n        ------\n        ValueError\n            If the configuration is None.\n        \"\"\"\n        if self.cfg is None:\n            raise ValueError(\"Configuration is not defined.\")\n\n        dataset = get_validation_dataset(self.cfg, val_path)\n        dataloader = DataLoader(\n            dataset,\n            batch_size=self.cfg.training.batch_size,\n            num_workers=self.cfg.training.num_workers,\n            pin_memory=True,\n        )\n        return dataloader\n\n    def _get_predict_dataloader(\n        self,\n        input: Union[np.ndarray, str, Path],\n        *,\n        tile_shape: Optional[List[int]] = None,\n        overlaps: Optional[List[int]] = None,\n        axes: Optional[str] = None,\n    ) -&gt; Tuple[DataLoader, bool]:\n        \"\"\"\n        Return a prediction dataloader.\n\n        Parameters\n        ----------\n        input : Union[np.ndarray, str, Path]\n            Input array or path to data.\n        tile_shape : Optional[List[int]], optional\n            2D or 3D shape of the tiles, by default None.\n        overlaps : Optional[List[int]], optional\n            2D or 3D overlaps between tiles, by default None.\n        axes : Optional[str], optional\n            Axes of the input array if different from the one in the configuration.\n\n        Returns\n        -------\n        Tuple[DataLoader, bool]\n            Tuple of prediction data loader, and whether the data is tiled.\n\n        Raises\n        ------\n        ValueError\n            If the configuration is None.\n        ValueError\n            If the mean or std are not specified in the configuration.\n        ValueError\n            If the input is None.\n        \"\"\"\n        if self.cfg is None:\n            raise ValueError(\"Configuration is not defined.\")\n\n        if self.cfg.data.mean is None or self.cfg.data.std is None:\n            raise ValueError(\n                \"Mean or std are not specified in the configuration, prediction cannot \"\n                \"be performed. Was the model trained?\"\n            )\n\n        if input is None:\n            raise ValueError(\"Input cannot be None.\")\n\n        # Create dataset\n        if isinstance(input, np.ndarray):  # np.ndarray\n            # Validate axes and add missing dimensions (S)C if necessary\n            img_axes = self.cfg.data.axes if axes is None else axes\n            input_expanded = add_axes(input, img_axes)\n\n            # Check if tiling requested\n            tiled = tile_shape is not None and overlaps is not None\n\n            # Validate tiles and overlaps\n            if tiled:\n                raise NotImplementedError(\n                    \"Tiling with in memory array is currently not implemented.\"\n                )\n\n            # Normalize input and cast to float32\n            normalized_input = normalize(\n                img=input_expanded, mean=self.cfg.data.mean, std=self.cfg.data.std\n            )\n            normalized_input = normalized_input.astype(np.float32)\n\n            # Create dataset\n            dataset = TensorDataset(torch.from_numpy(normalized_input))\n\n        elif isinstance(input, str) or isinstance(input, Path):  # path\n            # Create dataset\n            dataset = get_prediction_dataset(\n                self.cfg,\n                pred_path=input,\n                tile_shape=tile_shape,\n                overlaps=overlaps,\n                axes=axes,\n            )\n\n            tiled = (\n                hasattr(dataset, \"patch_extraction_method\")\n                and dataset.patch_extraction_method is not None\n            )\n        return (\n            DataLoader(\n                dataset,\n                batch_size=1,\n                num_workers=0,\n                pin_memory=True,\n            ),\n            tiled,\n        )\n\n    def _save_checkpoint(\n        self, epoch: int, losses: List[float], save_method: str\n    ) -&gt; Path:\n        \"\"\"\n        Save checkpoint.\n\n        Currently only supports saving using `save_method=\"state_dict\"`.\n\n        Parameters\n        ----------\n        epoch : int\n            Last epoch.\n        losses : List[float]\n            List of losses.\n        save_method : str\n            Method to save the model. Currently only supports `state_dict`.\n\n        Returns\n        -------\n        Path\n            Path to the saved checkpoint.\n\n        Raises\n        ------\n        ValueError\n            If the configuration is None.\n        NotImplementedError\n            If the requested save method is not supported.\n        \"\"\"\n        if self.cfg is None:\n            raise ValueError(\"Configuration is not defined.\")\n\n        if epoch == 0 or losses[-1] == min(losses):\n            name = f\"{self.cfg.experiment_name}_best.pth\"\n        else:\n            name = f\"{self.cfg.experiment_name}_latest.pth\"\n        workdir = self.cfg.working_directory\n        workdir.mkdir(parents=True, exist_ok=True)\n\n        if save_method == \"state_dict\":\n            checkpoint = {\n                \"epoch\": epoch,\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"scheduler_state_dict\": self.lr_scheduler.state_dict(),\n                \"grad_scaler_state_dict\": self.scaler.state_dict(),\n                \"loss\": losses[-1],\n                \"config\": self.cfg.model_dump(),\n            }\n            torch.save(checkpoint, workdir / name)\n        else:\n            raise NotImplementedError(\"Invalid save method.\")\n\n        return self.cfg.working_directory.absolute() / name\n\n    def __del__(self) -&gt; None:\n        \"\"\"Exit logger.\"\"\"\n        if hasattr(self, \"logger\"):\n            for handler in self.logger.handlers:\n                if isinstance(handler, FileHandler):\n                    self.logger.removeHandler(handler)\n                    handler.close()\n\n    def _get_sample_io_files(\n        self,\n        input_array: Optional[np.ndarray] = None,\n        axes: Optional[str] = None,\n    ) -&gt; Tuple[List[str], List[str]]:\n        \"\"\"\n        Create numpy format for use as inputs and outputs in the bioimage.io archive.\n\n        Parameters\n        ----------\n        input_array : Optional[np.ndarray], optional\n            Input array to use for the bioimage.io model zoo, by default None.\n        axes : Optional[str], optional\n            Axes from the configuration.\n\n        Returns\n        -------\n        Tuple[List[str], List[str]]\n            Tuple of input and output file paths.\n\n        Raises\n        ------\n        ValueError\n            If the configuration is not defined.\n        \"\"\"\n        if self.cfg is not None and self._input is not None:\n            # use the input array if provided, otherwise use the first validation sample\n            if input_array is not None:\n                array_in = input_array\n\n                # add axes to be compatible with the axes declared in the RDF specs\n                add_axes(array_in, axes)\n            else:\n                array_in = self._input\n\n            # predict (no tta since BMZ does not apply it)\n            array_out = self.predict(array_in, tta=False)\n\n            # add singleton dimensions (for compatibility with model axes)\n            # indeed, BMZ applies the model but CAREamics function are meant\n            # to work on user data (potentially with no S or C axe)\n            array_out = array_out[np.newaxis, np.newaxis, ...]\n\n            # save numpy files\n            workdir = self.cfg.working_directory\n            in_file = workdir.joinpath(\"test_inputs.npy\")\n            np.save(in_file, array_in)\n            out_file = workdir.joinpath(\"test_outputs.npy\")\n            np.save(out_file, array_out)\n\n            return [str(in_file.absolute())], [str(out_file.absolute())]\n        else:\n            raise ValueError(\"Configuration is not defined or model was not trained.\")\n\n    def _generate_rdf(\n        self,\n        *,\n        model_specs: Optional[dict] = None,\n        input_array: Optional[np.ndarray] = None,\n    ) -&gt; dict:\n        \"\"\"\n        Generate rdf data for bioimage.io format export.\n\n        Parameters\n        ----------\n        model_specs : Optional[dict], optional\n            Custom specs if different than the default ones, by default None.\n        input_array : Optional[np.ndarray], optional\n            Input array to use for the bioimage.io model zoo, by default None.\n\n        Returns\n        -------\n        dict\n            RDF specs.\n\n        Raises\n        ------\n        ValueError\n            If the mean or std are not specified in the configuration.\n        ValueError\n            If the configuration is not defined.\n        \"\"\"\n        if self.cfg is not None:\n            if self.cfg.data.mean is None or self.cfg.data.std is None:\n                raise ValueError(\n                    \"Mean or std are not specified in the configuration, export to \"\n                    \"bioimage.io format is not possible.\"\n                )\n\n            # set in/out axes from config\n            axes = self.cfg.data.axes.lower().replace(\"s\", \"\")\n            if \"c\" not in axes:\n                axes = \"c\" + axes\n            if \"b\" not in axes:\n                axes = \"b\" + axes\n\n            # get in/out samples' files\n            test_inputs, test_outputs = self._get_sample_io_files(\n                input_array, self.cfg.data.axes\n            )\n\n            specs = get_default_model_specs(\n                \"Noise2Void\",\n                self.cfg.data.mean,\n                self.cfg.data.std,\n                self.cfg.algorithm.is_3D,\n            )\n            if model_specs is not None:\n                specs.update(model_specs)\n\n            specs.update(\n                {\n                    \"test_inputs\": test_inputs,\n                    \"test_outputs\": test_outputs,\n                    \"input_axes\": [axes],\n                    \"output_axes\": [axes],\n                }\n            )\n            return specs\n        else:\n            raise ValueError(\"Configuration is not defined or model was not trained.\")\n\n    def save_as_bioimage(\n        self,\n        output_zip: Union[Path, str],\n        model_specs: Optional[dict] = None,\n        input_array: Optional[np.ndarray] = None,\n    ) -&gt; None:\n        \"\"\"\n        Export the current model to BioImage.io model zoo format.\n\n        Custom specs can be passed in `model_specs (e.g. maintainers). For a description\n        of the model RDF, refer to\n        github.com/bioimage-io/spec-bioimage-io/blob/gh-pages/model_spec_latest.md.\n\n        Parameters\n        ----------\n        output_zip : Union[Path, str]\n            Where to save the model zip file.\n        model_specs : Optional[dict]\n            A dictionary with keys being the bioimage-core build_model parameters. If\n            None then it will be populated by the model default specs.\n        input_array : Optional[np.ndarray]\n            An array to use as input for the bioimage.io model zoo. If None then the\n            first validation sample will be used. Note that the array must have S and\n            C dimensions (e.g. SCYX), even if only singleton dimensions.\n\n        Raises\n        ------\n        ValueError\n            If the configuration is not defined.\n        \"\"\"\n        if self.cfg is not None:\n            # Generate specs\n            specs = self._generate_rdf(model_specs=model_specs, input_array=input_array)\n\n            # Build model\n            save_bioimage_model(\n                path=output_zip,\n                config=self.cfg,\n                specs=specs,\n            )\n        else:\n            raise ValueError(\"Configuration is not defined.\")\n</code></pre>"},{"location":"reference/careamics/engine/#careamics.engine.Engine.__del__","title":"<code>__del__()</code>","text":"<p>Exit logger.</p> Source code in <code>src/careamics/engine.py</code> <pre><code>def __del__(self) -&gt; None:\n    \"\"\"Exit logger.\"\"\"\n    if hasattr(self, \"logger\"):\n        for handler in self.logger.handlers:\n            if isinstance(handler, FileHandler):\n                self.logger.removeHandler(handler)\n                handler.close()\n</code></pre>"},{"location":"reference/careamics/engine/#careamics.engine.Engine.__init__","title":"<code>__init__(*, config=None, config_path=None, model_path=None, seed=42)</code>","text":"<p>Constructor.</p> <p>To disable the seed, set it to None.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Optional[Configuration]</code> <p>Configuration object, by default None.</p> <code>None</code> <code>config_path</code> <code>Optional[Union[str, Path]]</code> <p>Path to configuration file, by default None.</p> <code>None</code> <code>model_path</code> <code>Optional[Union[str, Path]]</code> <p>Path to model file, by default None.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Seed for reproducibility, by default 42.</p> <code>42</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If all three parameters are None.</p> <code>FileNotFoundError</code> <p>If the model or configuration path is provided but does not exist.</p> <code>TypeError</code> <p>If the configuration is not a Configuration object.</p> <code>UsageError</code> <p>If wandb is not correctly installed.</p> <code>ModuleNotFoundError</code> <p>If wandb is not installed.</p> <code>ValueError</code> <p>If the configuration failed to configure.</p> Source code in <code>src/careamics/engine.py</code> <pre><code>def __init__(\n    self,\n    *,\n    config: Optional[Configuration] = None,\n    config_path: Optional[Union[str, Path]] = None,\n    model_path: Optional[Union[str, Path]] = None,\n    seed: Optional[int] = 42,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    To disable the seed, set it to None.\n\n    Parameters\n    ----------\n    config : Optional[Configuration], optional\n        Configuration object, by default None.\n    config_path : Optional[Union[str, Path]], optional\n        Path to configuration file, by default None.\n    model_path : Optional[Union[str, Path]], optional\n        Path to model file, by default None.\n    seed : int, optional\n        Seed for reproducibility, by default 42.\n\n    Raises\n    ------\n    ValueError\n        If all three parameters are None.\n    FileNotFoundError\n        If the model or configuration path is provided but does not exist.\n    TypeError\n        If the configuration is not a Configuration object.\n    UsageError\n        If wandb is not correctly installed.\n    ModuleNotFoundError\n        If wandb is not installed.\n    ValueError\n        If the configuration failed to configure.\n    \"\"\"\n    if model_path is not None:\n        if not Path(model_path).exists():\n            raise FileNotFoundError(\n                f\"Model path {model_path} is incorrect or\"\n                f\" does not exist. Current working directory is: {Path.cwd()!s}\"\n            )\n\n        # Ensure that config is None\n        self.cfg = None\n\n    elif config is not None:\n        # Check that config is a Configuration object\n        if not isinstance(config, Configuration):\n            raise TypeError(\n                f\"config must be a Configuration object, got {type(config)}\"\n            )\n        self.cfg = config\n    elif config_path is not None:\n        self.cfg = load_configuration(config_path)\n    else:\n        raise ValueError(\n            \"No configuration or path provided. One of configuration \"\n            \"object, configuration path or model path must be provided.\"\n        )\n\n    # get device, CPU or GPU\n    self.device = get_device()\n\n    # Create model, optimizer, lr scheduler and gradient scaler and load everything\n    # to the specified device\n    (\n        self.model,\n        self.optimizer,\n        self.lr_scheduler,\n        self.scaler,\n        self.cfg,\n    ) = create_model(config=self.cfg, model_path=model_path, device=self.device)\n    assert self.cfg is not None\n\n    # create loss function\n    self.loss_func = create_loss_function(self.cfg)\n\n    # Set logging\n    log_path = self.cfg.working_directory / \"log.txt\"\n    self.logger = get_logger(__name__, log_path=log_path)\n\n    # wandb\n    self.use_wandb = self.cfg.training.use_wandb\n\n    if self.use_wandb:\n        try:\n            from wandb.errors import UsageError\n\n            from careamics.utils.wandb import WandBLogging\n\n            try:\n                self.wandb = WandBLogging(\n                    experiment_name=self.cfg.experiment_name,\n                    log_path=self.cfg.working_directory,\n                    config=self.cfg,\n                    model_to_watch=self.model,\n                )\n            except UsageError as e:\n                self.logger.warning(\n                    f\"Wandb usage error, using default logger. Check whether \"\n                    f\"wandb correctly configured:\\n\"\n                    f\"{e}\"\n                )\n                self.use_wandb = False\n\n        except ModuleNotFoundError:\n            self.logger.warning(\n                \"Wandb not installed, using default logger. Try pip install \"\n                \"wandb\"\n            )\n            self.use_wandb = False\n\n    # BMZ inputs/outputs placeholders, filled during validation\n    self._input = None\n    self._outputs = None\n\n    # torch version\n    self.torch_version = torch.__version__\n</code></pre>"},{"location":"reference/careamics/engine/#careamics.engine.Engine.predict","title":"<code>predict(input, *, tile_shape=None, overlaps=None, axes=None, tta=True)</code>","text":"<p>Predict using the current model on an input array or a path to data.</p> <p>The Engine must have previously been trained and mean/std be specified in its configuration.</p> <p>Data should be compatible with the axes, either from the configuration or as passed using the <code>axes</code> parameter. If the batch and channel dimensions are missing, then singleton dimensions are added.</p> <p>To use tiling, both <code>tile_shape</code> and <code>overlaps</code> must be specified, have same length, be divisible by 2 and greater than 0. Finally, the overlaps must be smaller than the tiles.</p> <p>By setting <code>tta</code> to <code>True</code>, the prediction is performed using test time augmentation, meaning that the input is augmented and the prediction is averaged over the augmentations.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Union[ndarra, str, Path]</code> <p>Input data, either an array or a path to the data.</p> required <code>tile_shape</code> <code>Optional[List[int]]</code> <p>2D or 3D shape of the tiles to be predicted, by default None.</p> <code>None</code> <code>overlaps</code> <code>Optional[List[int]]</code> <p>2D or 3D overlaps between tiles, by default None.</p> <code>None</code> <code>axes</code> <code>Optional[str]</code> <p>Axes of the input array if different from the one in the configuration, by default None.</p> <code>None</code> <code>tta</code> <code>bool</code> <p>Whether to use test time augmentation, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[ndarray, List[ndarray]]</code> <p>Predicted image array of the same shape as the input, or list of arrays if the arrays have inconsistent shapes.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the configuration is missing.</p> <code>ValueError</code> <p>If the mean or std are not specified in the configuration (untrained model).</p> Source code in <code>src/careamics/engine.py</code> <pre><code>def predict(\n    self,\n    input: Union[np.ndarray, str, Path],\n    *,\n    tile_shape: Optional[List[int]] = None,\n    overlaps: Optional[List[int]] = None,\n    axes: Optional[str] = None,\n    tta: bool = True,\n) -&gt; Union[np.ndarray, List[np.ndarray]]:\n    \"\"\"\n    Predict using the current model on an input array or a path to data.\n\n    The Engine must have previously been trained and mean/std be specified in\n    its configuration.\n\n    Data should be compatible with the axes, either from the configuration or\n    as passed using the `axes` parameter. If the batch and channel dimensions are\n    missing, then singleton dimensions are added.\n\n    To use tiling, both `tile_shape` and `overlaps` must be specified, have same\n    length, be divisible by 2 and greater than 0. Finally, the overlaps must be\n    smaller than the tiles.\n\n    By setting `tta` to `True`, the prediction is performed using test time\n    augmentation, meaning that the input is augmented and the prediction is averaged\n    over the augmentations.\n\n    Parameters\n    ----------\n    input : Union[np.ndarra, str, Path]\n        Input data, either an array or a path to the data.\n    tile_shape : Optional[List[int]], optional\n        2D or 3D shape of the tiles to be predicted, by default None.\n    overlaps : Optional[List[int]], optional\n        2D or 3D overlaps between tiles, by default None.\n    axes : Optional[str], optional\n        Axes of the input array if different from the one in the configuration, by\n        default None.\n    tta : bool, optional\n        Whether to use test time augmentation, by default True.\n\n    Returns\n    -------\n    Union[np.ndarray, List[np.ndarray]]\n        Predicted image array of the same shape as the input, or list of arrays\n        if the arrays have inconsistent shapes.\n\n    Raises\n    ------\n    ValueError\n        If the configuration is missing.\n    ValueError\n        If the mean or std are not specified in the configuration (untrained model).\n    \"\"\"\n    if self.cfg is None:\n        raise ValueError(\"Configuration is not defined, cannot predict.\")\n\n    # Check that the mean and std are there (= has been trained)\n    if not self.cfg.data.mean or not self.cfg.data.std:\n        raise ValueError(\n            \"Mean or std are not specified in the configuration, prediction cannot \"\n            \"be performed.\"\n        )\n\n    # set model to eval mode\n    self.model.to(self.device)\n    self.model.eval()\n\n    progress_bar = ProgressBar(num_epochs=1, mode=\"predict\")\n\n    # Get dataloader\n    pred_loader, tiled = self._get_predict_dataloader(\n        input=input, tile_shape=tile_shape, overlaps=overlaps, axes=axes\n    )\n\n    # Start prediction\n    self.logger.info(\"Starting prediction\")\n    if tiled:\n        self.logger.info(\"Starting tiled prediction\")\n        prediction = self._predict_tiled(pred_loader, progress_bar, tta)\n    else:\n        self.logger.info(\"Starting prediction on whole sample\")\n        prediction = self._predict_full(pred_loader, progress_bar, tta)\n\n    return prediction\n</code></pre>"},{"location":"reference/careamics/engine/#careamics.engine.Engine.save_as_bioimage","title":"<code>save_as_bioimage(output_zip, model_specs=None, input_array=None)</code>","text":"<p>Export the current model to BioImage.io model zoo format.</p> <p>Custom specs can be passed in `model_specs (e.g. maintainers). For a description of the model RDF, refer to github.com/bioimage-io/spec-bioimage-io/blob/gh-pages/model_spec_latest.md.</p> <p>Parameters:</p> Name Type Description Default <code>output_zip</code> <code>Union[Path, str]</code> <p>Where to save the model zip file.</p> required <code>model_specs</code> <code>Optional[dict]</code> <p>A dictionary with keys being the bioimage-core build_model parameters. If None then it will be populated by the model default specs.</p> <code>None</code> <code>input_array</code> <code>Optional[ndarray]</code> <p>An array to use as input for the bioimage.io model zoo. If None then the first validation sample will be used. Note that the array must have S and C dimensions (e.g. SCYX), even if only singleton dimensions.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the configuration is not defined.</p> Source code in <code>src/careamics/engine.py</code> <pre><code>def save_as_bioimage(\n    self,\n    output_zip: Union[Path, str],\n    model_specs: Optional[dict] = None,\n    input_array: Optional[np.ndarray] = None,\n) -&gt; None:\n    \"\"\"\n    Export the current model to BioImage.io model zoo format.\n\n    Custom specs can be passed in `model_specs (e.g. maintainers). For a description\n    of the model RDF, refer to\n    github.com/bioimage-io/spec-bioimage-io/blob/gh-pages/model_spec_latest.md.\n\n    Parameters\n    ----------\n    output_zip : Union[Path, str]\n        Where to save the model zip file.\n    model_specs : Optional[dict]\n        A dictionary with keys being the bioimage-core build_model parameters. If\n        None then it will be populated by the model default specs.\n    input_array : Optional[np.ndarray]\n        An array to use as input for the bioimage.io model zoo. If None then the\n        first validation sample will be used. Note that the array must have S and\n        C dimensions (e.g. SCYX), even if only singleton dimensions.\n\n    Raises\n    ------\n    ValueError\n        If the configuration is not defined.\n    \"\"\"\n    if self.cfg is not None:\n        # Generate specs\n        specs = self._generate_rdf(model_specs=model_specs, input_array=input_array)\n\n        # Build model\n        save_bioimage_model(\n            path=output_zip,\n            config=self.cfg,\n            specs=specs,\n        )\n    else:\n        raise ValueError(\"Configuration is not defined.\")\n</code></pre>"},{"location":"reference/careamics/engine/#careamics.engine.Engine.train","title":"<code>train(train_path, val_path)</code>","text":"<p>Train the network.</p> <p>The training and validation data given by the paths must be compatible with the axes and data format provided in the configuration.</p> <p>Parameters:</p> Name Type Description Default <code>train_path</code> <code>Union[str, Path]</code> <p>Path to the training data.</p> required <code>val_path</code> <code>Union[str, Path]</code> <p>Path to the validation data.</p> required <p>Returns:</p> Type Description <code>Tuple[List[Any], List[Any]]</code> <p>Tuple of training and validation statistics.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Raise a ValueError if the configuration is missing.</p> Source code in <code>src/careamics/engine.py</code> <pre><code>def train(\n    self,\n    train_path: str,\n    val_path: str,\n) -&gt; Tuple[List[Any], List[Any]]:\n    \"\"\"\n    Train the network.\n\n    The training and validation data given by the paths must be compatible with the\n    axes and data format provided in the configuration.\n\n    Parameters\n    ----------\n    train_path : Union[str, Path]\n        Path to the training data.\n    val_path : Union[str, Path]\n        Path to the validation data.\n\n    Returns\n    -------\n    Tuple[List[Any], List[Any]]\n        Tuple of training and validation statistics.\n\n    Raises\n    ------\n    ValueError\n        Raise a ValueError if the configuration is missing.\n    \"\"\"\n    if self.cfg is None:\n        raise ValueError(\"Configuration is not defined, cannot train.\")\n\n    # General func\n    train_loader = self._get_train_dataloader(train_path)\n\n    # Set mean and std from train dataset of none\n    if self.cfg.data.mean is None or self.cfg.data.std is None:\n        self.cfg.data.set_mean_and_std(\n            train_loader.dataset.mean, train_loader.dataset.std\n        )\n\n    eval_loader = self._get_val_dataloader(val_path)\n    self.logger.info(f\"Starting training for {self.cfg.training.num_epochs} epochs\")\n\n    val_losses = []\n\n    try:\n        train_stats = []\n        eval_stats = []\n\n        # loop over the dataset multiple times\n        for epoch in range(self.cfg.training.num_epochs):\n            if hasattr(train_loader.dataset, \"__len__\"):\n                epoch_size = train_loader.__len__()\n            else:\n                epoch_size = None\n\n            progress_bar = ProgressBar(\n                max_value=epoch_size,\n                epoch=epoch,\n                num_epochs=self.cfg.training.num_epochs,\n                mode=\"train\",\n            )\n            # train_epoch = train_op(self._train_single_epoch,)\n            # Perform training step\n            train_outputs, epoch_size = self._train_single_epoch(\n                train_loader,\n                progress_bar,\n                self.cfg.training.amp.use,\n            )\n            # Perform validation step\n            eval_outputs = self._evaluate(eval_loader)\n            val_losses.append(eval_outputs[\"loss\"])\n            learning_rate = self.optimizer.param_groups[0][\"lr\"]\n\n            progress_bar.add(\n                1,\n                values=[\n                    (\"train_loss\", train_outputs[\"loss\"]),\n                    (\"val loss\", eval_outputs[\"loss\"]),\n                    (\"lr\", learning_rate),\n                ],\n            )\n            # Add update scheduler rule based on type\n            self.lr_scheduler.step(eval_outputs[\"loss\"])\n\n            if self.use_wandb:\n                metrics = {\n                    \"train\": train_outputs,\n                    \"eval\": eval_outputs,\n                    \"lr\": learning_rate,\n                }\n                self.wandb.log_metrics(metrics)\n\n            train_stats.append(train_outputs)\n            eval_stats.append(eval_outputs)\n\n            checkpoint_path = self._save_checkpoint(epoch, val_losses, \"state_dict\")\n            self.logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n\n    except KeyboardInterrupt:\n        self.logger.info(\"Training interrupted\")\n\n    return train_stats, eval_stats\n</code></pre>"},{"location":"reference/careamics/bioimage/io/","title":"io","text":"<p>Export to bioimage.io format.</p>"},{"location":"reference/careamics/bioimage/io/#careamics.bioimage.io.import_bioimage_model","title":"<code>import_bioimage_model(model_path)</code>","text":"<p>Load configuration and weights from a bioimage zip model.</p> <p>Parameters:</p> Name Type Description Default <code>model_path</code> <code>Union[str, Path]</code> <p>Path to the bioimage.io archive.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the checkpoint.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model format is invalid.</p> <code>FileNotFoundError</code> <p>If the checkpoint file was not found.</p> Source code in <code>src/careamics/bioimage/io.py</code> <pre><code>def import_bioimage_model(model_path: Union[str, Path]) -&gt; Path:\n    \"\"\"\n    Load configuration and weights from a bioimage zip model.\n\n    Parameters\n    ----------\n    model_path : Union[str, Path]\n        Path to the bioimage.io archive.\n\n    Returns\n    -------\n    Path\n        Path to the checkpoint.\n\n    Raises\n    ------\n    ValueError\n        If the model format is invalid.\n    FileNotFoundError\n        If the checkpoint file was not found.\n    \"\"\"\n    model_path = Path(model_path)\n\n    # check the model extension (should be a zip file).\n    if model_path.suffix != \".zip\":\n        raise ValueError(\"Invalid model format. Expected bioimage model zip file.\")\n\n    # load the model\n    rdf = load_resource_description(model_path)\n\n    # create a valid checkpoint file from weights and attached files\n    basedir = model_path.parent.joinpath(\"rdf_model\")\n    basedir.mkdir(exist_ok=True)\n    optim_path = None\n    scheduler_path = None\n    grad_path = None\n    config_path = None\n    weight_path = None\n\n    if rdf.weights.get(PYTORCH_STATE_DICT) is not None:\n        weight_path = rdf.weights.get(PYTORCH_STATE_DICT).source\n\n    for file in rdf.attachments.files:\n        if file.name.endswith(\"optim.pth\"):\n            optim_path = file\n        elif file.name.endswith(\"scheduler.pth\"):\n            scheduler_path = file\n        elif file.name.endswith(\"grad.pth\"):\n            grad_path = file\n        elif file.name.endswith(\"config.pth\"):\n            config_path = file\n\n    if (\n        weight_path is None\n        or optim_path is None\n        or scheduler_path is None\n        or grad_path is None\n        or config_path is None\n    ):\n        raise FileNotFoundError(f\"No valid checkpoint file was found in {model_path}.\")\n\n    checkpoint = {\n        \"model_state_dict\": torch.load(weight_path, map_location=\"cpu\"),\n        \"optimizer_state_dict\": torch.load(optim_path, map_location=\"cpu\"),\n        \"scheduler_state_dict\": torch.load(scheduler_path, map_location=\"cpu\"),\n        \"grad_scaler_state_dict\": torch.load(grad_path, map_location=\"cpu\"),\n        \"config\": torch.load(config_path, map_location=\"cpu\"),\n    }\n    checkpoint_path = basedir.joinpath(\"checkpoint.pth\")\n    torch.save(checkpoint, checkpoint_path)\n\n    return checkpoint_path\n</code></pre>"},{"location":"reference/careamics/bioimage/io/#careamics.bioimage.io.save_bioimage_model","title":"<code>save_bioimage_model(path, config, specs)</code>","text":"<p>Build bioimage model zip file from model RDF data.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the model zip file.</p> required <code>config</code> <code>Configuration</code> <p>Configuration object.</p> required <code>specs</code> <code>dict</code> <p>Model RDF dict.</p> required Source code in <code>src/careamics/bioimage/io.py</code> <pre><code>def save_bioimage_model(\n    path: Union[str, Path],\n    config: Configuration,\n    specs: dict,\n) -&gt; None:\n    \"\"\"\n    Build bioimage model zip file from model RDF data.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to the model zip file.\n    config : Configuration\n        Configuration object.\n    specs : dict\n        Model RDF dict.\n    \"\"\"\n    workdir = config.working_directory\n\n    # temporary folder\n    temp_folder = Path.home().joinpath(\".careamics\", \"bmz_tmp\")\n    temp_folder.mkdir(exist_ok=True, parents=True)\n\n    # change working directory to the temp folder\n    with cwd(temp_folder):\n        # load best checkpoint\n        checkpoint_path = workdir.joinpath(\n            f\"{config.experiment_name}_best.pth\"\n        ).absolute()\n        checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n\n        # save chekpoint entries in separate files\n        weight_path = Path(\"model_weights.pth\")\n        torch.save(checkpoint[\"model_state_dict\"], weight_path)\n\n        optim_path = Path(\"optim.pth\")\n        torch.save(checkpoint[\"optimizer_state_dict\"], optim_path)\n\n        scheduler_path = Path(\"scheduler.pth\")\n        torch.save(checkpoint[\"scheduler_state_dict\"], scheduler_path)\n\n        grad_path = Path(\"grad.pth\")\n        torch.save(checkpoint[\"grad_scaler_state_dict\"], grad_path)\n\n        config_path = Path(\"config.pth\")\n        torch.save(config.model_dump(), config_path)\n\n        # create attachments\n        attachments = [\n            str(optim_path),\n            str(scheduler_path),\n            str(grad_path),\n            str(config_path),\n        ]\n\n        # create requirements file\n        requirements = Path(\"requirements.txt\")\n        with open(requirements, \"w\") as f:\n            f.write(\"git+https://github.com/CAREamics/careamics.git\")\n\n        algo_config = config.algorithm\n        specs.update(\n            {\n                \"weight_type\": PYTORCH_STATE_DICT,\n                \"weight_uri\": str(weight_path),\n                \"architecture\": \"careamics.models.unet.UNet\",\n                \"pytorch_version\": torch.__version__,\n                \"model_kwargs\": {\n                    \"conv_dim\": algo_config.get_conv_dim(),\n                    \"depth\": algo_config.model_parameters.depth,\n                    \"num_channels_init\": algo_config.model_parameters.num_channels_init,\n                },\n                \"dependencies\": \"pip:\" + str(requirements),\n                \"attachments\": {\"files\": attachments},\n            }\n        )\n\n        if config.algorithm.is_3D:\n            specs[\"tags\"].append(\"3D\")\n        else:\n            specs[\"tags\"].append(\"2D\")\n\n        # build model zip\n        build_model(\n            output_path=Path(path).absolute(),\n            **specs,\n        )\n\n        # remove temporary files\n        for file in temp_folder.glob(\"*\"):\n            file.unlink()\n\n    # delete temporary folder\n    temp_folder.rmdir()\n</code></pre>"},{"location":"reference/careamics/bioimage/rdf/","title":"rdf","text":"<p>RDF related methods.</p>"},{"location":"reference/careamics/bioimage/rdf/#careamics.bioimage.rdf.get_default_model_specs","title":"<code>get_default_model_specs(name, mean, std, is_3D=False)</code>","text":"<p>Return the default bioimage.io specs for the provided model's name.</p> <p>Currently only supports <code>Noise2Void</code> model.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Algorithm's name.</p> required <code>mean</code> <code>float</code> <p>Mean of the dataset.</p> required <code>std</code> <code>float</code> <p>Std of the dataset.</p> required <code>is_3D</code> <code>bool</code> <p>Whether the model is 3D or not, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Model specs compatible with bioimage.io export.</p> Source code in <code>src/careamics/bioimage/rdf.py</code> <pre><code>def get_default_model_specs(\n    name: str, mean: float, std: float, is_3D: bool = False\n) -&gt; dict:\n    \"\"\"\n    Return the default bioimage.io specs for the provided model's name.\n\n    Currently only supports `Noise2Void` model.\n\n    Parameters\n    ----------\n    name : str\n        Algorithm's name.\n    mean : float\n        Mean of the dataset.\n    std : float\n        Std of the dataset.\n    is_3D : bool, optional\n        Whether the model is 3D or not, by default False.\n\n    Returns\n    -------\n    dict\n        Model specs compatible with bioimage.io export.\n    \"\"\"\n    rdf = {\n        \"name\": \"Noise2Void\",\n        \"description\": \"Self-supervised denoising.\",\n        \"license\": \"BSD-3-Clause\",\n        \"authors\": [\n            {\"name\": \"Alexander Krull\"},\n            {\"name\": \"Tim-Oliver Buchholz\"},\n            {\"name\": \"Florian Jug\"},\n        ],\n        \"cite\": [\n            {\n                \"doi\": \"10.48550/arXiv.1811.10980\",\n                \"text\": 'A. Krull, T.-O. Buchholz and F. Jug, \"Noise2Void - Learning '\n                'Denoising From Single Noisy Images,\" 2019 IEEE/CVF '\n                \"Conference on Computer Vision and Pattern Recognition \"\n                \"(CVPR), 2019, pp. 2124-2132\",\n            }\n        ],\n        # \"input_axes\": [\"bcyx\"], &lt;- overriden in save_as_bioimage\n        \"preprocessing\": [  # for multiple inputs\n            [  # multiple processes per input\n                {\n                    \"kwargs\": {\n                        \"axes\": \"zyx\" if is_3D else \"yx\",\n                        \"mean\": [mean],\n                        \"mode\": \"fixed\",\n                        \"std\": [std],\n                    },\n                    \"name\": \"zero_mean_unit_variance\",\n                }\n            ]\n        ],\n        # \"output_axes\": [\"bcyx\"], &lt;- overriden in save_as_bioimage\n        \"postprocessing\": [  # for multiple outputs\n            [  # multiple processes per input\n                {\n                    \"kwargs\": {\n                        \"axes\": \"zyx\" if is_3D else \"yx\",\n                        \"gain\": [std],\n                        \"offset\": [mean],\n                    },\n                    \"name\": \"scale_linear\",\n                }\n            ]\n        ],\n        \"tags\": [\"unet\", \"denoising\", \"Noise2Void\", \"tensorflow\", \"napari\"],\n    }\n\n    rdf[\"documentation\"] = _get_model_doc(name)\n\n    return rdf\n</code></pre>"},{"location":"reference/careamics/config/algorithm/","title":"algorithm","text":"<p>Algorithm configuration.</p>"},{"location":"reference/careamics/config/algorithm/#careamics.config.algorithm.Algorithm","title":"<code>Algorithm</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Algorithm configuration.</p> <p>The minimum algorithm configuration is composed of the following fields:     - loss:         Loss to use, currently only supports n2v.     - model:         Model to use, currently only supports UNet.     - is_3D:         Whether to use a 3D model or not, this should be coherent with the         data configuration (axes).</p> <p>Other optional fields are:     - masking_strategy:         Masking strategy to use, currently only supports default masking.     - masked_pixel_percentage:         Percentage of pixels to be masked in each patch.     - roi_size:         Size of the region of interest to use in the masking algorithm.     - model_parameters:         Model parameters, see ModelParameters for more details.</p> <p>Attributes:</p> Name Type Description <code>loss</code> <code>List[Losses]</code> <p>List of losses to use, currently only supports n2v.</p> <code>model</code> <code>Models</code> <p>Model to use, currently only supports UNet.</p> <code>is_3D</code> <code>bool</code> <p>Whether to use a 3D model or not.</p> <code>masking_strategy</code> <code>MaskingStrategies</code> <p>Masking strategy to use, currently only supports default masking.</p> <code>masked_pixel_percentage</code> <code>float</code> <p>Percentage of pixels to be masked in each patch.</p> <code>roi_size</code> <code>int</code> <p>Size of the region of interest used in the masking scheme.</p> <code>model_parameters</code> <code>ModelParameters</code> <p>Model parameters, see ModelParameters for more details.</p> Source code in <code>src/careamics/config/algorithm.py</code> <pre><code>class Algorithm(BaseModel):\n    \"\"\"\n    Algorithm configuration.\n\n    The minimum algorithm configuration is composed of the following fields:\n        - loss:\n            Loss to use, currently only supports n2v.\n        - model:\n            Model to use, currently only supports UNet.\n        - is_3D:\n            Whether to use a 3D model or not, this should be coherent with the\n            data configuration (axes).\n\n    Other optional fields are:\n        - masking_strategy:\n            Masking strategy to use, currently only supports default masking.\n        - masked_pixel_percentage:\n            Percentage of pixels to be masked in each patch.\n        - roi_size:\n            Size of the region of interest to use in the masking algorithm.\n        - model_parameters:\n            Model parameters, see ModelParameters for more details.\n\n    Attributes\n    ----------\n    loss : List[Losses]\n        List of losses to use, currently only supports n2v.\n    model : Models\n        Model to use, currently only supports UNet.\n    is_3D : bool\n        Whether to use a 3D model or not.\n    masking_strategy : MaskingStrategies\n        Masking strategy to use, currently only supports default masking.\n    masked_pixel_percentage : float\n        Percentage of pixels to be masked in each patch.\n    roi_size : int\n        Size of the region of interest used in the masking scheme.\n    model_parameters : ModelParameters\n        Model parameters, see ModelParameters for more details.\n    \"\"\"\n\n    # Pydantic class configuration\n    model_config = ConfigDict(\n        use_enum_values=True,\n        protected_namespaces=(),  # allows to use model_* as a field name\n        validate_assignment=True,\n    )\n\n    # Mandatory fields\n    loss: Loss\n    model: Models\n    is_3D: bool\n\n    # Optional fields, define a default value\n    masking_strategy: MaskingStrategy = MaskingStrategy.DEFAULT\n    masked_pixel_percentage: float = Field(default=0.2, ge=0.1, le=20)\n    roi_size: int = Field(default=11, ge=3, le=21)\n    model_parameters: ModelParameters = ModelParameters()\n\n    def get_conv_dim(self) -&gt; int:\n        \"\"\"\n        Get the convolution layers dimension (2D or 3D).\n\n        Returns\n        -------\n        int\n            Dimension (2 or 3).\n        \"\"\"\n        return 3 if self.is_3D else 2\n\n    @field_validator(\"roi_size\")\n    def even(cls, roi_size: int) -&gt; int:\n        \"\"\"\n        Validate that roi_size is odd.\n\n        Parameters\n        ----------\n        roi_size : int\n            Size of the region of interest in the masking scheme.\n\n        Returns\n        -------\n        int\n            Validated size of the region of interest.\n\n        Raises\n        ------\n        ValueError\n            If the size of the region of interest is even.\n        \"\"\"\n        # if even\n        if roi_size % 2 == 0:\n            raise ValueError(f\"ROI size must be odd (got {roi_size}).\")\n\n        return roi_size\n\n    def model_dump(\n        self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n    ) -&gt; Dict:\n        \"\"\"\n        Override model_dump method.\n\n        The purpose is to ensure export smooth import to yaml. It includes:\n            - remove entries with None value.\n            - remove optional values if they have the default value.\n\n        Parameters\n        ----------\n        exclude_optionals : bool, optional\n            Whether to exclude optional arguments if they are default, by default True.\n        *args : List\n            Positional arguments, unused.\n        **kwargs : Dict\n            Keyword arguments, unused.\n\n        Returns\n        -------\n        Dict\n            Dictionary representation of the model.\n        \"\"\"\n        dictionary = super().model_dump(exclude_none=True)\n\n        if exclude_optionals is True:\n            # remove optional arguments if they are default\n            defaults = {\n                \"masking_strategy\": MaskingStrategy.DEFAULT.value,\n                \"masked_pixel_percentage\": 0.2,\n                \"roi_size\": 11,\n                \"model_parameters\": ModelParameters().model_dump(exclude_none=True),\n            }\n\n            remove_default_optionals(dictionary, defaults)\n\n        return dictionary\n</code></pre>"},{"location":"reference/careamics/config/algorithm/#careamics.config.algorithm.Algorithm.even","title":"<code>even(roi_size)</code>","text":"<p>Validate that roi_size is odd.</p> <p>Parameters:</p> Name Type Description Default <code>roi_size</code> <code>int</code> <p>Size of the region of interest in the masking scheme.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Validated size of the region of interest.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the size of the region of interest is even.</p> Source code in <code>src/careamics/config/algorithm.py</code> <pre><code>@field_validator(\"roi_size\")\ndef even(cls, roi_size: int) -&gt; int:\n    \"\"\"\n    Validate that roi_size is odd.\n\n    Parameters\n    ----------\n    roi_size : int\n        Size of the region of interest in the masking scheme.\n\n    Returns\n    -------\n    int\n        Validated size of the region of interest.\n\n    Raises\n    ------\n    ValueError\n        If the size of the region of interest is even.\n    \"\"\"\n    # if even\n    if roi_size % 2 == 0:\n        raise ValueError(f\"ROI size must be odd (got {roi_size}).\")\n\n    return roi_size\n</code></pre>"},{"location":"reference/careamics/config/algorithm/#careamics.config.algorithm.Algorithm.get_conv_dim","title":"<code>get_conv_dim()</code>","text":"<p>Get the convolution layers dimension (2D or 3D).</p> <p>Returns:</p> Type Description <code>int</code> <p>Dimension (2 or 3).</p> Source code in <code>src/careamics/config/algorithm.py</code> <pre><code>def get_conv_dim(self) -&gt; int:\n    \"\"\"\n    Get the convolution layers dimension (2D or 3D).\n\n    Returns\n    -------\n    int\n        Dimension (2 or 3).\n    \"\"\"\n    return 3 if self.is_3D else 2\n</code></pre>"},{"location":"reference/careamics/config/algorithm/#careamics.config.algorithm.Algorithm.model_dump","title":"<code>model_dump(exclude_optionals=True, *args, **kwargs)</code>","text":"<p>Override model_dump method.</p> <p>The purpose is to ensure export smooth import to yaml. It includes:     - remove entries with None value.     - remove optional values if they have the default value.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_optionals</code> <code>bool</code> <p>Whether to exclude optional arguments if they are default, by default True.</p> <code>True</code> <code>*args</code> <code>List</code> <p>Positional arguments, unused.</p> <code>()</code> <code>**kwargs</code> <code>Dict</code> <p>Keyword arguments, unused.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict</code> <p>Dictionary representation of the model.</p> Source code in <code>src/careamics/config/algorithm.py</code> <pre><code>def model_dump(\n    self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n) -&gt; Dict:\n    \"\"\"\n    Override model_dump method.\n\n    The purpose is to ensure export smooth import to yaml. It includes:\n        - remove entries with None value.\n        - remove optional values if they have the default value.\n\n    Parameters\n    ----------\n    exclude_optionals : bool, optional\n        Whether to exclude optional arguments if they are default, by default True.\n    *args : List\n        Positional arguments, unused.\n    **kwargs : Dict\n        Keyword arguments, unused.\n\n    Returns\n    -------\n    Dict\n        Dictionary representation of the model.\n    \"\"\"\n    dictionary = super().model_dump(exclude_none=True)\n\n    if exclude_optionals is True:\n        # remove optional arguments if they are default\n        defaults = {\n            \"masking_strategy\": MaskingStrategy.DEFAULT.value,\n            \"masked_pixel_percentage\": 0.2,\n            \"roi_size\": 11,\n            \"model_parameters\": ModelParameters().model_dump(exclude_none=True),\n        }\n\n        remove_default_optionals(dictionary, defaults)\n\n    return dictionary\n</code></pre>"},{"location":"reference/careamics/config/algorithm/#careamics.config.algorithm.Loss","title":"<code>Loss</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Available loss functions.</p> <p>Currently supported losses:</p> <pre><code>- n2v: Noise2Void loss.\n</code></pre> Source code in <code>src/careamics/config/algorithm.py</code> <pre><code>class Loss(str, Enum):\n    \"\"\"\n    Available loss functions.\n\n    Currently supported losses:\n\n        - n2v: Noise2Void loss.\n    \"\"\"\n\n    N2V = \"n2v\"\n</code></pre>"},{"location":"reference/careamics/config/algorithm/#careamics.config.algorithm.MaskingStrategy","title":"<code>MaskingStrategy</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Available masking strategy.</p> <p>Currently supported strategies:</p> <ul> <li>default: default masking strategy of Noise2Void (uniform sampling of neighbors).</li> <li>median: median masking strategy of N2V2.</li> </ul> Source code in <code>src/careamics/config/algorithm.py</code> <pre><code>class MaskingStrategy(str, Enum):\n    \"\"\"\n    Available masking strategy.\n\n    Currently supported strategies:\n\n    - default: default masking strategy of Noise2Void (uniform sampling of neighbors).\n    - median: median masking strategy of N2V2.\n    \"\"\"\n\n    DEFAULT = \"default\"\n    MEDIAN = \"median\"\n</code></pre>"},{"location":"reference/careamics/config/algorithm/#careamics.config.algorithm.ModelParameters","title":"<code>ModelParameters</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Deep-learning model parameters.</p> <p>The number of filters (base) must be even and minimum 8.</p> <p>Attributes:</p> Name Type Description <code>depth</code> <code>int</code> <p>Depth of the model, between 1 and 10 (default 2).</p> <code>num_channels_init</code> <code>int</code> <p>Number of filters of the first level of the network, should be even and minimum 8 (default 96).</p> Source code in <code>src/careamics/config/algorithm.py</code> <pre><code>class ModelParameters(BaseModel):\n    \"\"\"\n    Deep-learning model parameters.\n\n    The number of filters (base) must be even and minimum 8.\n\n    Attributes\n    ----------\n    depth : int\n        Depth of the model, between 1 and 10 (default 2).\n    num_channels_init : int\n        Number of filters of the first level of the network, should be even\n        and minimum 8 (default 96).\n    \"\"\"\n\n    model_config = ConfigDict(validate_assignment=True)\n\n    depth: int = Field(default=2, ge=1, le=10)\n    num_channels_init: int = Field(default=32, ge=8)\n\n    # TODO revisit the constraints on num_channels_init\n    @field_validator(\"num_channels_init\")\n    def even(cls, num_channels: int) -&gt; int:\n        \"\"\"\n        Validate that num_channels_init is even.\n\n        Parameters\n        ----------\n        num_channels : int\n            Number of channels.\n\n        Returns\n        -------\n        int\n            Validated number of channels.\n\n        Raises\n        ------\n        ValueError\n            If the number of channels is odd.\n        \"\"\"\n        # if odd\n        if num_channels % 2 != 0:\n            raise ValueError(\n                f\"Number of channels (init) must be even (got {num_channels}).\"\n            )\n\n        return num_channels\n</code></pre>"},{"location":"reference/careamics/config/algorithm/#careamics.config.algorithm.ModelParameters.even","title":"<code>even(num_channels)</code>","text":"<p>Validate that num_channels_init is even.</p> <p>Parameters:</p> Name Type Description Default <code>num_channels</code> <code>int</code> <p>Number of channels.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Validated number of channels.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of channels is odd.</p> Source code in <code>src/careamics/config/algorithm.py</code> <pre><code>@field_validator(\"num_channels_init\")\ndef even(cls, num_channels: int) -&gt; int:\n    \"\"\"\n    Validate that num_channels_init is even.\n\n    Parameters\n    ----------\n    num_channels : int\n        Number of channels.\n\n    Returns\n    -------\n    int\n        Validated number of channels.\n\n    Raises\n    ------\n    ValueError\n        If the number of channels is odd.\n    \"\"\"\n    # if odd\n    if num_channels % 2 != 0:\n        raise ValueError(\n            f\"Number of channels (init) must be even (got {num_channels}).\"\n        )\n\n    return num_channels\n</code></pre>"},{"location":"reference/careamics/config/algorithm/#careamics.config.algorithm.Models","title":"<code>Models</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Available models.</p> <p>Currently supported models:     - UNet: U-Net model.</p> Source code in <code>src/careamics/config/algorithm.py</code> <pre><code>class Models(str, Enum):\n    \"\"\"\n    Available models.\n\n    Currently supported models:\n        - UNet: U-Net model.\n    \"\"\"\n\n    UNET = \"UNet\"\n</code></pre>"},{"location":"reference/careamics/config/config/","title":"config","text":"<p>Pydantic CAREamics configuration.</p>"},{"location":"reference/careamics/config/config/#careamics.config.config.Configuration","title":"<code>Configuration</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>CAREamics configuration.</p> <p>To change the configuration from 2D to 3D, we recommend using the following method:</p> <p>set_3D(is_3D, axes)</p> <p>Attributes:</p> Name Type Description <code>experiment_name</code> <code>str</code> <p>Name of the experiment.</p> <code>working_directory</code> <code>Union[str, Path]</code> <p>Path to the working directory.</p> <code>algorithm</code> <code>Algorithm</code> <p>Algorithm configuration.</p> <code>training</code> <code>Training</code> <p>Training configuration.</p> Source code in <code>src/careamics/config/config.py</code> <pre><code>class Configuration(BaseModel):\n    \"\"\"\n    CAREamics configuration.\n\n    To change the configuration from 2D to 3D, we recommend using the following method:\n    &gt;&gt;&gt; set_3D(is_3D, axes)\n\n    Attributes\n    ----------\n    experiment_name : str\n        Name of the experiment.\n    working_directory : Union[str, Path]\n        Path to the working directory.\n    algorithm : Algorithm\n        Algorithm configuration.\n    training : Training\n        Training configuration.\n    \"\"\"\n\n    model_config = ConfigDict(validate_assignment=True)\n\n    # required parameters\n    experiment_name: str\n    working_directory: Path\n\n    # Sub-configurations\n    algorithm: Algorithm\n    data: Data\n    training: Training\n\n    def set_3D(self, is_3D: bool, axes: str) -&gt; None:\n        \"\"\"\n        Set 3D flag and axes.\n\n        Parameters\n        ----------\n        is_3D : bool\n            Whether the algorithm is 3D or not.\n        axes : str\n            Axes of the data.\n        \"\"\"\n        # set the flag and axes (this will not trigger validation at the config level)\n        self.algorithm.is_3D = is_3D\n        self.data.axes = axes\n\n        # cheap hack: trigger validation\n        self.algorithm = self.algorithm\n\n    @field_validator(\"experiment_name\")\n    def no_symbol(cls, name: str) -&gt; str:\n        \"\"\"\n        Validate experiment name.\n\n        A valid experiment name is a non-empty string with only contains letters,\n        numbers, underscores, dashes and spaces.\n\n        Parameters\n        ----------\n        name : str\n            Name to validate.\n\n        Returns\n        -------\n        str\n            Validated name.\n\n        Raises\n        ------\n        ValueError\n            If the name is empty or contains invalid characters.\n        \"\"\"\n        if len(name) == 0 or name.isspace():\n            raise ValueError(\"Experiment name is empty.\")\n\n        # Validate using a regex that it contains only letters, numbers, underscores,\n        # dashes and spaces\n        if not re.match(r\"^[a-zA-Z0-9_\\- ]*$\", name):\n            raise ValueError(\n                f\"Experiment name contains invalid characters (got {name}). \"\n                f\"Only letters, numbers, underscores, dashes and spaces are allowed.\"\n            )\n\n        return name\n\n    @field_validator(\"working_directory\")\n    def parent_directory_exists(cls, workdir: Union[str, Path]) -&gt; Path:\n        \"\"\"\n        Validate working directory.\n\n        A valid working directory is a directory whose parent directory exists. If the\n        working directory does not exist itself, it is then created.\n\n        Parameters\n        ----------\n        workdir : Union[str, Path]\n            Working directory to validate.\n\n        Returns\n        -------\n        Path\n            Validated working directory.\n\n        Raises\n        ------\n        ValueError\n            If the working directory is not a directory, or if the parent directory does\n            not exist.\n        \"\"\"\n        path = Path(workdir)\n\n        # check if it is a directory\n        if path.exists() and not path.is_dir():\n            raise ValueError(f\"Working directory is not a directory (got {workdir}).\")\n\n        # check if parent directory exists\n        if not path.parent.exists():\n            raise ValueError(\n                f\"Parent directory of working directory does not exist (got {workdir}).\"\n            )\n\n        # create directory if it does not exist already\n        path.mkdir(exist_ok=True)\n\n        return path\n\n    @model_validator(mode=\"after\")\n    def validate_3D(cls, config: Configuration) -&gt; Configuration:\n        \"\"\"\n        Check 3D flag validity.\n\n        Check that the algorithm is_3D flag is compatible with the axes in the\n        data configuration.\n\n        Parameters\n        ----------\n        config : Configuration\n            Configuration to validate.\n\n        Returns\n        -------\n        Configuration\n            Validated configuration.\n\n        Raises\n        ------\n        ValueError\n            If the algorithm is 3D but the data axes are not, or if the algorithm is\n            not 3D but the data axes are.\n        \"\"\"\n        # check that is_3D and axes are compatible\n        if config.algorithm.is_3D and \"Z\" not in config.data.axes:\n            raise ValueError(\n                f\"Algorithm is 3D but data axes are not (got axes {config.data.axes}).\"\n            )\n        elif not config.algorithm.is_3D and \"Z\" in config.data.axes:\n            raise ValueError(\n                f\"Algorithm is not 3D but data axes are (got axes {config.data.axes}).\"\n            )\n\n        return config\n\n    def model_dump(\n        self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n    ) -&gt; Dict:\n        \"\"\"\n        Override model_dump method.\n\n        The purpose is to ensure export smooth import to yaml. It includes:\n            - remove entries with None value.\n            - remove optional values if they have the default value.\n\n        Parameters\n        ----------\n        exclude_optionals : bool, optional\n            Whether to exclude optional fields with default values or not, by default\n            True.\n        *args : List\n            Positional arguments, unused.\n        **kwargs : Dict\n            Keyword arguments, unused.\n\n        Returns\n        -------\n        dict\n            Dictionary containing the model parameters.\n        \"\"\"\n        dictionary = super().model_dump(exclude_none=True)\n\n        # remove paths\n        dictionary = paths_to_str(dictionary)\n\n        dictionary[\"algorithm\"] = self.algorithm.model_dump(\n            exclude_optionals=exclude_optionals\n        )\n        dictionary[\"data\"] = self.data.model_dump()\n\n        dictionary[\"training\"] = self.training.model_dump(\n            exclude_optionals=exclude_optionals\n        )\n\n        return dictionary\n</code></pre>"},{"location":"reference/careamics/config/config/#careamics.config.config.Configuration.model_dump","title":"<code>model_dump(exclude_optionals=True, *args, **kwargs)</code>","text":"<p>Override model_dump method.</p> <p>The purpose is to ensure export smooth import to yaml. It includes:     - remove entries with None value.     - remove optional values if they have the default value.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_optionals</code> <code>bool</code> <p>Whether to exclude optional fields with default values or not, by default True.</p> <code>True</code> <code>*args</code> <code>List</code> <p>Positional arguments, unused.</p> <code>()</code> <code>**kwargs</code> <code>Dict</code> <p>Keyword arguments, unused.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the model parameters.</p> Source code in <code>src/careamics/config/config.py</code> <pre><code>def model_dump(\n    self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n) -&gt; Dict:\n    \"\"\"\n    Override model_dump method.\n\n    The purpose is to ensure export smooth import to yaml. It includes:\n        - remove entries with None value.\n        - remove optional values if they have the default value.\n\n    Parameters\n    ----------\n    exclude_optionals : bool, optional\n        Whether to exclude optional fields with default values or not, by default\n        True.\n    *args : List\n        Positional arguments, unused.\n    **kwargs : Dict\n        Keyword arguments, unused.\n\n    Returns\n    -------\n    dict\n        Dictionary containing the model parameters.\n    \"\"\"\n    dictionary = super().model_dump(exclude_none=True)\n\n    # remove paths\n    dictionary = paths_to_str(dictionary)\n\n    dictionary[\"algorithm\"] = self.algorithm.model_dump(\n        exclude_optionals=exclude_optionals\n    )\n    dictionary[\"data\"] = self.data.model_dump()\n\n    dictionary[\"training\"] = self.training.model_dump(\n        exclude_optionals=exclude_optionals\n    )\n\n    return dictionary\n</code></pre>"},{"location":"reference/careamics/config/config/#careamics.config.config.Configuration.no_symbol","title":"<code>no_symbol(name)</code>","text":"<p>Validate experiment name.</p> <p>A valid experiment name is a non-empty string with only contains letters, numbers, underscores, dashes and spaces.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name to validate.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Validated name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the name is empty or contains invalid characters.</p> Source code in <code>src/careamics/config/config.py</code> <pre><code>@field_validator(\"experiment_name\")\ndef no_symbol(cls, name: str) -&gt; str:\n    \"\"\"\n    Validate experiment name.\n\n    A valid experiment name is a non-empty string with only contains letters,\n    numbers, underscores, dashes and spaces.\n\n    Parameters\n    ----------\n    name : str\n        Name to validate.\n\n    Returns\n    -------\n    str\n        Validated name.\n\n    Raises\n    ------\n    ValueError\n        If the name is empty or contains invalid characters.\n    \"\"\"\n    if len(name) == 0 or name.isspace():\n        raise ValueError(\"Experiment name is empty.\")\n\n    # Validate using a regex that it contains only letters, numbers, underscores,\n    # dashes and spaces\n    if not re.match(r\"^[a-zA-Z0-9_\\- ]*$\", name):\n        raise ValueError(\n            f\"Experiment name contains invalid characters (got {name}). \"\n            f\"Only letters, numbers, underscores, dashes and spaces are allowed.\"\n        )\n\n    return name\n</code></pre>"},{"location":"reference/careamics/config/config/#careamics.config.config.Configuration.parent_directory_exists","title":"<code>parent_directory_exists(workdir)</code>","text":"<p>Validate working directory.</p> <p>A valid working directory is a directory whose parent directory exists. If the working directory does not exist itself, it is then created.</p> <p>Parameters:</p> Name Type Description Default <code>workdir</code> <code>Union[str, Path]</code> <p>Working directory to validate.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Validated working directory.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the working directory is not a directory, or if the parent directory does not exist.</p> Source code in <code>src/careamics/config/config.py</code> <pre><code>@field_validator(\"working_directory\")\ndef parent_directory_exists(cls, workdir: Union[str, Path]) -&gt; Path:\n    \"\"\"\n    Validate working directory.\n\n    A valid working directory is a directory whose parent directory exists. If the\n    working directory does not exist itself, it is then created.\n\n    Parameters\n    ----------\n    workdir : Union[str, Path]\n        Working directory to validate.\n\n    Returns\n    -------\n    Path\n        Validated working directory.\n\n    Raises\n    ------\n    ValueError\n        If the working directory is not a directory, or if the parent directory does\n        not exist.\n    \"\"\"\n    path = Path(workdir)\n\n    # check if it is a directory\n    if path.exists() and not path.is_dir():\n        raise ValueError(f\"Working directory is not a directory (got {workdir}).\")\n\n    # check if parent directory exists\n    if not path.parent.exists():\n        raise ValueError(\n            f\"Parent directory of working directory does not exist (got {workdir}).\"\n        )\n\n    # create directory if it does not exist already\n    path.mkdir(exist_ok=True)\n\n    return path\n</code></pre>"},{"location":"reference/careamics/config/config/#careamics.config.config.Configuration.set_3D","title":"<code>set_3D(is_3D, axes)</code>","text":"<p>Set 3D flag and axes.</p> <p>Parameters:</p> Name Type Description Default <code>is_3D</code> <code>bool</code> <p>Whether the algorithm is 3D or not.</p> required <code>axes</code> <code>str</code> <p>Axes of the data.</p> required Source code in <code>src/careamics/config/config.py</code> <pre><code>def set_3D(self, is_3D: bool, axes: str) -&gt; None:\n    \"\"\"\n    Set 3D flag and axes.\n\n    Parameters\n    ----------\n    is_3D : bool\n        Whether the algorithm is 3D or not.\n    axes : str\n        Axes of the data.\n    \"\"\"\n    # set the flag and axes (this will not trigger validation at the config level)\n    self.algorithm.is_3D = is_3D\n    self.data.axes = axes\n\n    # cheap hack: trigger validation\n    self.algorithm = self.algorithm\n</code></pre>"},{"location":"reference/careamics/config/config/#careamics.config.config.Configuration.validate_3D","title":"<code>validate_3D(config)</code>","text":"<p>Check 3D flag validity.</p> <p>Check that the algorithm is_3D flag is compatible with the axes in the data configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>Configuration to validate.</p> required <p>Returns:</p> Type Description <code>Configuration</code> <p>Validated configuration.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the algorithm is 3D but the data axes are not, or if the algorithm is not 3D but the data axes are.</p> Source code in <code>src/careamics/config/config.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_3D(cls, config: Configuration) -&gt; Configuration:\n    \"\"\"\n    Check 3D flag validity.\n\n    Check that the algorithm is_3D flag is compatible with the axes in the\n    data configuration.\n\n    Parameters\n    ----------\n    config : Configuration\n        Configuration to validate.\n\n    Returns\n    -------\n    Configuration\n        Validated configuration.\n\n    Raises\n    ------\n    ValueError\n        If the algorithm is 3D but the data axes are not, or if the algorithm is\n        not 3D but the data axes are.\n    \"\"\"\n    # check that is_3D and axes are compatible\n    if config.algorithm.is_3D and \"Z\" not in config.data.axes:\n        raise ValueError(\n            f\"Algorithm is 3D but data axes are not (got axes {config.data.axes}).\"\n        )\n    elif not config.algorithm.is_3D and \"Z\" in config.data.axes:\n        raise ValueError(\n            f\"Algorithm is not 3D but data axes are (got axes {config.data.axes}).\"\n        )\n\n    return config\n</code></pre>"},{"location":"reference/careamics/config/config/#careamics.config.config.load_configuration","title":"<code>load_configuration(path)</code>","text":"<p>Load configuration from a yaml file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the configuration.</p> required <p>Returns:</p> Type Description <code>Configuration</code> <p>Configuration.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the configuration file does not exist.</p> Source code in <code>src/careamics/config/config.py</code> <pre><code>def load_configuration(path: Union[str, Path]) -&gt; Configuration:\n    \"\"\"\n    Load configuration from a yaml file.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to the configuration.\n\n    Returns\n    -------\n    Configuration\n        Configuration.\n\n    Raises\n    ------\n    FileNotFoundError\n        If the configuration file does not exist.\n    \"\"\"\n    # load dictionary from yaml\n    if not Path(path).exists():\n        raise FileNotFoundError(\n            f\"Configuration file {path} does not exist in \" f\" {Path.cwd()!s}\"\n        )\n\n    dictionary = yaml.load(Path(path).open(\"r\"), Loader=yaml.SafeLoader)\n\n    return Configuration(**dictionary)\n</code></pre>"},{"location":"reference/careamics/config/config/#careamics.config.config.save_configuration","title":"<code>save_configuration(config, path)</code>","text":"<p>Save configuration to path.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>Configuration to save.</p> required <code>path</code> <code>Union[str, Path]</code> <p>Path to a existing folder in which to save the configuration or to an existing configuration file.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path object representing the configuration.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the path does not point to an existing directory or .yml file.</p> Source code in <code>src/careamics/config/config.py</code> <pre><code>def save_configuration(config: Configuration, path: Union[str, Path]) -&gt; Path:\n    \"\"\"\n    Save configuration to path.\n\n    Parameters\n    ----------\n    config : Configuration\n        Configuration to save.\n    path : Union[str, Path]\n        Path to a existing folder in which to save the configuration or to an existing\n        configuration file.\n\n    Returns\n    -------\n    Path\n        Path object representing the configuration.\n\n    Raises\n    ------\n    ValueError\n        If the path does not point to an existing directory or .yml file.\n    \"\"\"\n    # make sure path is a Path object\n    config_path = Path(path)\n\n    # check if path is pointing to an existing directory or .yml file\n    if config_path.exists():\n        if config_path.is_dir():\n            config_path = Path(config_path, \"config.yml\")\n        elif config_path.suffix != \".yml\":\n            raise ValueError(\n                f\"Path must be a directory or .yml file (got {config_path}).\"\n            )\n    else:\n        if config_path.suffix != \".yml\":\n            raise ValueError(f\"Path must be a .yml file (got {config_path}).\")\n\n    # save configuration as dictionary to yaml\n    with open(config_path, \"w\") as f:\n        yaml.dump(config.model_dump(), f, default_flow_style=False)\n\n    return config_path\n</code></pre>"},{"location":"reference/careamics/config/config_filter/","title":"config_filter","text":"<p>Convenience functions to filter dictionaries resulting from a Pydantic export.</p>"},{"location":"reference/careamics/config/config_filter/#careamics.config.config_filter.paths_to_str","title":"<code>paths_to_str(dictionary)</code>","text":"<p>Replace Path objects in a dictionary by str.</p> <p>Parameters:</p> Name Type Description Default <code>dictionary</code> <code>dict</code> <p>Dictionary to modify.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Modified dictionary.</p> Source code in <code>src/careamics/config/config_filter.py</code> <pre><code>def paths_to_str(dictionary: dict) -&gt; dict:\n    \"\"\"\n    Replace Path objects in a dictionary by str.\n\n    Parameters\n    ----------\n    dictionary : dict\n        Dictionary to modify.\n\n    Returns\n    -------\n    dict\n        Modified dictionary.\n    \"\"\"\n    for k in dictionary.keys():\n        if isinstance(dictionary[k], Path):\n            dictionary[k] = str(dictionary[k])\n\n    return dictionary\n</code></pre>"},{"location":"reference/careamics/config/config_filter/#careamics.config.config_filter.remove_default_optionals","title":"<code>remove_default_optionals(dictionary, default)</code>","text":"<p>Remove default arguments from a dictionary.</p> <p>The method removes arguments if they are equal to the provided default ones.</p> <p>Parameters:</p> Name Type Description Default <code>dictionary</code> <code>dict</code> <p>Dictionary to modify.</p> required <code>default</code> <code>dict</code> <p>Dictionary containing the default values.</p> required Source code in <code>src/careamics/config/config_filter.py</code> <pre><code>def remove_default_optionals(dictionary: Dict, default: Dict) -&gt; None:\n    \"\"\"\n    Remove default arguments from a dictionary.\n\n    The method removes arguments if they are equal to the provided default ones.\n\n    Parameters\n    ----------\n    dictionary : dict\n        Dictionary to modify.\n    default : dict\n        Dictionary containing the default values.\n    \"\"\"\n    dict_copy = dictionary.copy()\n    for k in dict_copy.keys():\n        if k in default.keys():\n            if dict_copy[k] == default[k]:\n                del dictionary[k]\n</code></pre>"},{"location":"reference/careamics/config/data/","title":"data","text":"<p>Data configuration.</p>"},{"location":"reference/careamics/config/data/#careamics.config.data.Data","title":"<code>Data</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Data configuration.</p> <p>If std is specified, mean must be specified as well. Note that setting the std first and then the mean (if they were both <code>None</code> before) will raise a validation error. Prefer instead the following:</p> <p>set_mean_and_std(mean, std)</p> <p>Attributes:</p> Name Type Description <code>in_memory</code> <code>bool</code> <p>Whether to load the data in memory or not.</p> <code>data_format</code> <code>SupportedExtension</code> <p>Extension of the data, without period.</p> <code>axes</code> <code>str</code> <p>Axes of the data.</p> <code>mean</code> <code>Optional[float]</code> <p>Expected data mean.</p> <code>std</code> <code>Optional[float]</code> <p>Expected data standard deviation.</p> Source code in <code>src/careamics/config/data.py</code> <pre><code>class Data(BaseModel):\n    \"\"\"\n    Data configuration.\n\n    If std is specified, mean must be specified as well. Note that setting the std first\n    and then the mean (if they were both `None` before) will raise a validation error.\n    Prefer instead the following:\n    &gt;&gt;&gt; set_mean_and_std(mean, std)\n\n    Attributes\n    ----------\n    in_memory : bool\n        Whether to load the data in memory or not.\n    data_format : SupportedExtension\n        Extension of the data, without period.\n    axes : str\n        Axes of the data.\n    mean: Optional[float]\n        Expected data mean.\n    std: Optional[float]\n        Expected data standard deviation.\n    \"\"\"\n\n    # Pydantic class configuration\n    model_config = ConfigDict(\n        use_enum_values=True,\n        validate_assignment=True,\n    )\n\n    # Mandatory fields\n    in_memory: bool\n    data_format: SupportedExtension\n    axes: str\n\n    # Optional fields\n    mean: Optional[float] = Field(default=None, ge=0)\n    std: Optional[float] = Field(default=None, gt=0)\n\n    def set_mean_and_std(self, mean: float, std: float) -&gt; None:\n        \"\"\"\n        Set mean and standard deviation of the data.\n\n        This method is preferred to setting the fields directly, as it ensures that the\n        mean is set first, then the std; thus avoiding a validation error to be thrown.\n\n        Parameters\n        ----------\n        mean : float\n            Mean of the data.\n        std : float\n            Standard deviation of the data.\n        \"\"\"\n        self.mean = mean\n        self.std = std\n\n    @field_validator(\"axes\")\n    def valid_axes(cls, axes: str) -&gt; str:\n        \"\"\"\n        Validate axes.\n\n        Axes must be a subset of STZYX, must contain YX, be in the right order\n        and not contain both S and T.\n\n        Parameters\n        ----------\n        axes : str\n            Axes of the training data.\n\n        Returns\n        -------\n        str\n            Validated axes of the training data.\n\n        Raises\n        ------\n        ValueError\n            If axes are not valid.\n        \"\"\"\n        # validate axes\n        check_axes_validity(axes)\n\n        return axes\n\n    @model_validator(mode=\"after\")\n    def std_only_with_mean(cls, data_model: Data) -&gt; Data:\n        \"\"\"\n        Check that mean and std are either both None, or both specified.\n\n        If we enforce both None or both specified, we cannot set the values one by one\n        due to the ConfDict enforcing the validation on assignment. Therefore, we check\n        only when the std is not None and the mean is None.\n\n        Parameters\n        ----------\n        data_model : Data\n            Data model.\n\n        Returns\n        -------\n        Data\n            Validated data model.\n\n        Raises\n        ------\n        ValueError\n            If std is not None and mean is None.\n        \"\"\"\n        if data_model.std is not None and data_model.mean is None:\n            raise ValueError(\"Cannot have std non None if mean is None.\")\n\n        return data_model\n\n    def model_dump(self, *args: List, **kwargs: Dict) -&gt; dict:\n        \"\"\"\n        Override model_dump method.\n\n        The purpose is to ensure export smooth import to yaml. It includes:\n            - remove entries with None value.\n\n        Parameters\n        ----------\n        *args : List\n            Positional arguments, unused.\n        **kwargs : Dict\n            Keyword arguments, unused.\n\n        Returns\n        -------\n        dict\n            Dictionary containing the model parameters.\n        \"\"\"\n        return super().model_dump(exclude_none=True)\n</code></pre>"},{"location":"reference/careamics/config/data/#careamics.config.data.Data.model_dump","title":"<code>model_dump(*args, **kwargs)</code>","text":"<p>Override model_dump method.</p> <p>The purpose is to ensure export smooth import to yaml. It includes:     - remove entries with None value.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>List</code> <p>Positional arguments, unused.</p> <code>()</code> <code>**kwargs</code> <code>Dict</code> <p>Keyword arguments, unused.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the model parameters.</p> Source code in <code>src/careamics/config/data.py</code> <pre><code>def model_dump(self, *args: List, **kwargs: Dict) -&gt; dict:\n    \"\"\"\n    Override model_dump method.\n\n    The purpose is to ensure export smooth import to yaml. It includes:\n        - remove entries with None value.\n\n    Parameters\n    ----------\n    *args : List\n        Positional arguments, unused.\n    **kwargs : Dict\n        Keyword arguments, unused.\n\n    Returns\n    -------\n    dict\n        Dictionary containing the model parameters.\n    \"\"\"\n    return super().model_dump(exclude_none=True)\n</code></pre>"},{"location":"reference/careamics/config/data/#careamics.config.data.Data.set_mean_and_std","title":"<code>set_mean_and_std(mean, std)</code>","text":"<p>Set mean and standard deviation of the data.</p> <p>This method is preferred to setting the fields directly, as it ensures that the mean is set first, then the std; thus avoiding a validation error to be thrown.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>Mean of the data.</p> required <code>std</code> <code>float</code> <p>Standard deviation of the data.</p> required Source code in <code>src/careamics/config/data.py</code> <pre><code>def set_mean_and_std(self, mean: float, std: float) -&gt; None:\n    \"\"\"\n    Set mean and standard deviation of the data.\n\n    This method is preferred to setting the fields directly, as it ensures that the\n    mean is set first, then the std; thus avoiding a validation error to be thrown.\n\n    Parameters\n    ----------\n    mean : float\n        Mean of the data.\n    std : float\n        Standard deviation of the data.\n    \"\"\"\n    self.mean = mean\n    self.std = std\n</code></pre>"},{"location":"reference/careamics/config/data/#careamics.config.data.Data.std_only_with_mean","title":"<code>std_only_with_mean(data_model)</code>","text":"<p>Check that mean and std are either both None, or both specified.</p> <p>If we enforce both None or both specified, we cannot set the values one by one due to the ConfDict enforcing the validation on assignment. Therefore, we check only when the std is not None and the mean is None.</p> <p>Parameters:</p> Name Type Description Default <code>data_model</code> <code>Data</code> <p>Data model.</p> required <p>Returns:</p> Type Description <code>Data</code> <p>Validated data model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If std is not None and mean is None.</p> Source code in <code>src/careamics/config/data.py</code> <pre><code>@model_validator(mode=\"after\")\ndef std_only_with_mean(cls, data_model: Data) -&gt; Data:\n    \"\"\"\n    Check that mean and std are either both None, or both specified.\n\n    If we enforce both None or both specified, we cannot set the values one by one\n    due to the ConfDict enforcing the validation on assignment. Therefore, we check\n    only when the std is not None and the mean is None.\n\n    Parameters\n    ----------\n    data_model : Data\n        Data model.\n\n    Returns\n    -------\n    Data\n        Validated data model.\n\n    Raises\n    ------\n    ValueError\n        If std is not None and mean is None.\n    \"\"\"\n    if data_model.std is not None and data_model.mean is None:\n        raise ValueError(\"Cannot have std non None if mean is None.\")\n\n    return data_model\n</code></pre>"},{"location":"reference/careamics/config/data/#careamics.config.data.Data.valid_axes","title":"<code>valid_axes(axes)</code>","text":"<p>Validate axes.</p> <p>Axes must be a subset of STZYX, must contain YX, be in the right order and not contain both S and T.</p> <p>Parameters:</p> Name Type Description Default <code>axes</code> <code>str</code> <p>Axes of the training data.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Validated axes of the training data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If axes are not valid.</p> Source code in <code>src/careamics/config/data.py</code> <pre><code>@field_validator(\"axes\")\ndef valid_axes(cls, axes: str) -&gt; str:\n    \"\"\"\n    Validate axes.\n\n    Axes must be a subset of STZYX, must contain YX, be in the right order\n    and not contain both S and T.\n\n    Parameters\n    ----------\n    axes : str\n        Axes of the training data.\n\n    Returns\n    -------\n    str\n        Validated axes of the training data.\n\n    Raises\n    ------\n    ValueError\n        If axes are not valid.\n    \"\"\"\n    # validate axes\n    check_axes_validity(axes)\n\n    return axes\n</code></pre>"},{"location":"reference/careamics/config/data/#careamics.config.data.SupportedExtension","title":"<code>SupportedExtension</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Supported extensions for input data.</p> <p>Currently supported:     - tif/tiff: .tiff files.</p> Source code in <code>src/careamics/config/data.py</code> <pre><code>class SupportedExtension(str, Enum):\n    \"\"\"\n    Supported extensions for input data.\n\n    Currently supported:\n        - tif/tiff: .tiff files.\n    \"\"\"\n\n    TIFF = \"tiff\"  # TODO these should be a single one\n    TIF = \"tif\"\n\n    @classmethod\n    def _missing_(cls, value: object) -&gt; str:\n        \"\"\"\n        Override default behaviour for missing values.\n\n        This method is called when `value` is not found in the enum values. It converts\n        `value` to lowercase, removes \".\" if it is the first character and tries to\n        match it with enum values.\n\n        Parameters\n        ----------\n        value : object\n            Value to be matched with enum values.\n\n        Returns\n        -------\n        str\n            Matched enum value.\n        \"\"\"\n        if isinstance(value, str):\n            lower_value = value.lower()\n\n            if lower_value.startswith(\".\"):\n                lower_value = lower_value[1:]\n\n            # attempt to match lowercase value with enum values\n            for member in cls:\n                if member.value == lower_value:\n                    return member\n\n        # still missing\n        return super()._missing_(value)\n</code></pre>"},{"location":"reference/careamics/config/torch_optim/","title":"torch_optim","text":"<p>Convenience functions to instantiate torch.optim optimizers and schedulers.</p>"},{"location":"reference/careamics/config/torch_optim/#careamics.config.torch_optim.TorchLRScheduler","title":"<code>TorchLRScheduler</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Supported learning rate schedulers.</p> <p>Currently only supports ReduceLROnPlateau and StepLR.</p> Source code in <code>src/careamics/config/torch_optim.py</code> <pre><code>class TorchLRScheduler(str, Enum):\n    \"\"\"\n    Supported learning rate schedulers.\n\n    Currently only supports ReduceLROnPlateau and StepLR.\n    \"\"\"\n\n    # ChainedScheduler = \"ChainedScheduler\"\n    # ConstantLR = \"ConstantLR\"\n    # CosineAnnealingLR = \"CosineAnnealingLR\"\n    # CosineAnnealingWarmRestarts = \"CosineAnnealingWarmRestarts\"\n    # CyclicLR = \"CyclicLR\"\n    # ExponentialLR = \"ExponentialLR\"\n    # LambdaLR = \"LambdaLR\"\n    # LinearLR = \"LinearLR\"\n    # MultiStepLR = \"MultiStepLR\"\n    # MultiplicativeLR = \"MultiplicativeLR\"\n    # OneCycleLR = \"OneCycleLR\"\n    # PolynomialLR = \"PolynomialLR\"\n    ReduceLROnPlateau = \"ReduceLROnPlateau\"\n    # SequentialLR = \"SequentialLR\"\n    StepLR = \"StepLR\"\n</code></pre>"},{"location":"reference/careamics/config/torch_optim/#careamics.config.torch_optim.TorchOptimizer","title":"<code>TorchOptimizer</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Supported optimizers.</p> <p>Currently only supports Adam and SGD.</p> Source code in <code>src/careamics/config/torch_optim.py</code> <pre><code>class TorchOptimizer(str, Enum):\n    \"\"\"\n    Supported optimizers.\n\n    Currently only supports Adam and SGD.\n    \"\"\"\n\n    # ASGD = \"ASGD\"\n    # Adadelta = \"Adadelta\"\n    # Adagrad = \"Adagrad\"\n    Adam = \"Adam\"\n    # AdamW = \"AdamW\"\n    # Adamax = \"Adamax\"\n    # LBFGS = \"LBFGS\"\n    # NAdam = \"NAdam\"\n    # RAdam = \"RAdam\"\n    # RMSprop = \"RMSprop\"\n    # Rprop = \"Rprop\"\n    SGD = \"SGD\"\n</code></pre>"},{"location":"reference/careamics/config/torch_optim/#careamics.config.torch_optim.get_optimizers","title":"<code>get_optimizers()</code>","text":"<p>Return the list of all optimizers available in torch.optim.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>Optimizers available in torch.optim.</p> Source code in <code>src/careamics/config/torch_optim.py</code> <pre><code>def get_optimizers() -&gt; Dict[str, str]:\n    \"\"\"\n    Return the list of all optimizers available in torch.optim.\n\n    Returns\n    -------\n    Dict\n        Optimizers available in torch.optim.\n    \"\"\"\n    optims = {}\n    for name, obj in inspect.getmembers(optim):\n        if inspect.isclass(obj) and issubclass(obj, optim.Optimizer):\n            if name != \"Optimizer\":\n                optims[name] = name\n    return optims\n</code></pre>"},{"location":"reference/careamics/config/torch_optim/#careamics.config.torch_optim.get_parameters","title":"<code>get_parameters(func, user_params)</code>","text":"<p>Filter parameters according to the function signature.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>type</code> <p>Class object.</p> required <code>user_params</code> <code>Dict</code> <p>User provided parameters.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Parameters matching <code>func</code>'s signature.</p> Source code in <code>src/careamics/config/torch_optim.py</code> <pre><code>def get_parameters(\n    func: type,\n    user_params: dict,\n) -&gt; dict:\n    \"\"\"\n    Filter parameters according to the function signature.\n\n    Parameters\n    ----------\n    func : type\n        Class object.\n    user_params : Dict\n        User provided parameters.\n\n    Returns\n    -------\n    Dict\n        Parameters matching `func`'s signature.\n    \"\"\"\n    # Get the list of all default parameters\n    default_params = list(inspect.signature(func).parameters.keys())\n\n    # Filter matching parameters\n    params_to_be_used = set(user_params.keys()) &amp; set(default_params)\n\n    return {key: user_params[key] for key in params_to_be_used}\n</code></pre>"},{"location":"reference/careamics/config/torch_optim/#careamics.config.torch_optim.get_schedulers","title":"<code>get_schedulers()</code>","text":"<p>Return the list of all schedulers available in torch.optim.lr_scheduler.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>Schedulers available in torch.optim.lr_scheduler.</p> Source code in <code>src/careamics/config/torch_optim.py</code> <pre><code>def get_schedulers() -&gt; Dict[str, str]:\n    \"\"\"\n    Return the list of all schedulers available in torch.optim.lr_scheduler.\n\n    Returns\n    -------\n    Dict\n        Schedulers available in torch.optim.lr_scheduler.\n    \"\"\"\n    schedulers = {}\n    for name, obj in inspect.getmembers(optim.lr_scheduler):\n        if inspect.isclass(obj) and issubclass(obj, optim.lr_scheduler.LRScheduler):\n            if \"LRScheduler\" not in name:\n                schedulers[name] = name\n        elif name == \"ReduceLROnPlateau\":  # somewhat not a subclass of LRScheduler\n            schedulers[name] = name\n    return schedulers\n</code></pre>"},{"location":"reference/careamics/config/training/","title":"training","text":"<p>Training configuration.</p>"},{"location":"reference/careamics/config/training/#careamics.config.training.AMP","title":"<code>AMP</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Automatic mixed precision (AMP) parameters.</p> <p>See: https://pytorch.org/docs/stable/amp.html.</p> <p>Attributes:</p> Name Type Description <code>use</code> <code>(bool, optional)</code> <p>Whether to use AMP or not, default False.</p> <code>init_scale</code> <code>(int, optional)</code> <p>Initial scale used for loss scaling, default 1024.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>class AMP(BaseModel):\n    \"\"\"\n    Automatic mixed precision (AMP) parameters.\n\n    See: https://pytorch.org/docs/stable/amp.html.\n\n    Attributes\n    ----------\n    use : bool, optional\n        Whether to use AMP or not, default False.\n    init_scale : int, optional\n        Initial scale used for loss scaling, default 1024.\n    \"\"\"\n\n    model_config = ConfigDict(\n        validate_assignment=True,\n    )\n\n    use: bool = False\n\n    # TODO review init_scale and document better\n    init_scale: int = Field(default=1024, ge=512, le=65536)\n\n    @field_validator(\"init_scale\")\n    def power_of_two(cls, scale: int) -&gt; int:\n        \"\"\"\n        Validate that init_scale is a power of two.\n\n        Parameters\n        ----------\n        scale : int\n            Initial scale used for loss scaling.\n\n        Returns\n        -------\n        int\n            Validated initial scale.\n\n        Raises\n        ------\n        ValueError\n            If the init_scale is not a power of two.\n        \"\"\"\n        if not scale &amp; (scale - 1) == 0:\n            raise ValueError(f\"Init scale must be a power of two (got {scale}).\")\n\n        return scale\n\n    def model_dump(\n        self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n    ) -&gt; Dict:\n        \"\"\"\n        Override model_dump method.\n\n        The purpose is to ensure export smooth import to yaml. It includes:\n            - remove entries with None value.\n            - remove optional values if they have the default value.\n\n        Parameters\n        ----------\n        exclude_optionals : bool, optional\n            Whether to exclude optional arguments if they are default, by default True.\n        *args : List\n            Positional arguments, unused.\n        **kwargs : Dict\n            Keyword arguments, unused.\n\n        Returns\n        -------\n        dict\n            Dictionary containing the model parameters.\n        \"\"\"\n        dictionary = super().model_dump(exclude_none=True)\n\n        if exclude_optionals:\n            # remove optional arguments if they are default\n            defaults = {\n                \"init_scale\": 1024,\n            }\n\n            remove_default_optionals(dictionary, defaults)\n\n        return dictionary\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.AMP.model_dump","title":"<code>model_dump(exclude_optionals=True, *args, **kwargs)</code>","text":"<p>Override model_dump method.</p> <p>The purpose is to ensure export smooth import to yaml. It includes:     - remove entries with None value.     - remove optional values if they have the default value.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_optionals</code> <code>bool</code> <p>Whether to exclude optional arguments if they are default, by default True.</p> <code>True</code> <code>*args</code> <code>List</code> <p>Positional arguments, unused.</p> <code>()</code> <code>**kwargs</code> <code>Dict</code> <p>Keyword arguments, unused.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the model parameters.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>def model_dump(\n    self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n) -&gt; Dict:\n    \"\"\"\n    Override model_dump method.\n\n    The purpose is to ensure export smooth import to yaml. It includes:\n        - remove entries with None value.\n        - remove optional values if they have the default value.\n\n    Parameters\n    ----------\n    exclude_optionals : bool, optional\n        Whether to exclude optional arguments if they are default, by default True.\n    *args : List\n        Positional arguments, unused.\n    **kwargs : Dict\n        Keyword arguments, unused.\n\n    Returns\n    -------\n    dict\n        Dictionary containing the model parameters.\n    \"\"\"\n    dictionary = super().model_dump(exclude_none=True)\n\n    if exclude_optionals:\n        # remove optional arguments if they are default\n        defaults = {\n            \"init_scale\": 1024,\n        }\n\n        remove_default_optionals(dictionary, defaults)\n\n    return dictionary\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.AMP.power_of_two","title":"<code>power_of_two(scale)</code>","text":"<p>Validate that init_scale is a power of two.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>int</code> <p>Initial scale used for loss scaling.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Validated initial scale.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the init_scale is not a power of two.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>@field_validator(\"init_scale\")\ndef power_of_two(cls, scale: int) -&gt; int:\n    \"\"\"\n    Validate that init_scale is a power of two.\n\n    Parameters\n    ----------\n    scale : int\n        Initial scale used for loss scaling.\n\n    Returns\n    -------\n    int\n        Validated initial scale.\n\n    Raises\n    ------\n    ValueError\n        If the init_scale is not a power of two.\n    \"\"\"\n    if not scale &amp; (scale - 1) == 0:\n        raise ValueError(f\"Init scale must be a power of two (got {scale}).\")\n\n    return scale\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.LrScheduler","title":"<code>LrScheduler</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Torch learning rate scheduler.</p> <p>Only parameters supported by the corresponding torch lr scheduler will be taken into account. For more details, check: https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate</p> <p>Note that mandatory parameters (see the specific LrScheduler signature in the link above) must be provided. For example, StepLR requires <code>step_size</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>TorchLRScheduler</code> <p>Name of the learning rate scheduler.</p> <code>parameters</code> <code>dict</code> <p>Parameters of the learning rate scheduler (see torch documentation).</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>class LrScheduler(BaseModel):\n    \"\"\"\n    Torch learning rate scheduler.\n\n    Only parameters supported by the corresponding torch lr scheduler will be taken\n    into account. For more details, check:\n    https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n\n    Note that mandatory parameters (see the specific LrScheduler signature in the\n    link above) must be provided. For example, StepLR requires `step_size`.\n\n    Attributes\n    ----------\n    name : TorchLRScheduler\n        Name of the learning rate scheduler.\n    parameters : dict\n        Parameters of the learning rate scheduler (see torch documentation).\n    \"\"\"\n\n    # Pydantic class configuration\n    model_config = ConfigDict(\n        use_enum_values=True,\n        validate_assignment=True,\n    )\n\n    # Mandatory field\n    name: TorchLRScheduler\n\n    # Optional parameters\n    parameters: dict = {}\n\n    @field_validator(\"parameters\")\n    def filter_parameters(cls, user_params: dict, values: FieldValidationInfo) -&gt; Dict:\n        \"\"\"\n        Validate lr scheduler parameters.\n\n        This method filters out unknown parameters, given the lr scheduler name.\n\n        Parameters\n        ----------\n        user_params : dict\n            Parameters passed on to the torch lr scheduler.\n        values : FieldValidationInfo\n            Pydantic field validation info, used to get the lr scheduler name.\n\n        Returns\n        -------\n        Dict\n            Filtered lr scheduler parameters.\n\n        Raises\n        ------\n        ValueError\n            If the lr scheduler name is not specified.\n        \"\"\"\n        if \"name\" in values.data:\n            lr_scheduler_name = values.data[\"name\"]\n\n            # retrieve the corresponding lr scheduler class\n            lr_scheduler_class = getattr(optim.lr_scheduler, lr_scheduler_name)\n\n            # filter the user parameters according to the lr scheduler's signature\n            return get_parameters(lr_scheduler_class, user_params)\n        else:\n            raise ValueError(\n                \"Cannot validate lr scheduler parameters without `name`, check that it \"\n                \"has correctly been specified.\"\n            )\n\n    @model_validator(mode=\"after\")\n    def step_lr_step_size_parameter(cls, lr_scheduler: LrScheduler) -&gt; LrScheduler:\n        \"\"\"\n        Check that StepLR lr scheduler has `step_size` parameter specified.\n\n        Parameters\n        ----------\n        lr_scheduler : LrScheduler\n            Lr scheduler to validate.\n\n        Returns\n        -------\n        LrScheduler\n            Validated lr scheduler.\n\n        Raises\n        ------\n        ValueError\n            If the lr scheduler is StepLR and the step_size parameter is not specified.\n        \"\"\"\n        if (\n            lr_scheduler.name == TorchLRScheduler.StepLR\n            and \"step_size\" not in lr_scheduler.parameters\n        ):\n            raise ValueError(\n                \"StepLR lr scheduler requires `step_size` parameter, check that it has \"\n                \"correctly been specified in `parameters`.\"\n            )\n\n        return lr_scheduler\n\n    def model_dump(\n        self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n    ) -&gt; Dict:\n        \"\"\"\n        Override model_dump method.\n\n        The purpose of this method is to ensure smooth export to yaml. It includes:\n            - removing entries with None value.\n            - removing optional values if they have the default value.\n\n        Parameters\n        ----------\n        exclude_optionals : bool, optional\n            Whether to exclude optional arguments if they are default, by default True.\n        *args : List\n            Positional arguments, unused.\n        **kwargs : Dict\n            Keyword arguments, unused.\n\n        Returns\n        -------\n        dict\n            Dictionary containing the model parameters.\n        \"\"\"\n        dictionary = super().model_dump(exclude_none=True)\n\n        if exclude_optionals:\n            # remove optional arguments if they are default\n            default_optionals: dict = {\"parameters\": {}}\n            remove_default_optionals(dictionary, default_optionals)\n\n        return dictionary\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.LrScheduler.filter_parameters","title":"<code>filter_parameters(user_params, values)</code>","text":"<p>Validate lr scheduler parameters.</p> <p>This method filters out unknown parameters, given the lr scheduler name.</p> <p>Parameters:</p> Name Type Description Default <code>user_params</code> <code>dict</code> <p>Parameters passed on to the torch lr scheduler.</p> required <code>values</code> <code>FieldValidationInfo</code> <p>Pydantic field validation info, used to get the lr scheduler name.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Filtered lr scheduler parameters.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the lr scheduler name is not specified.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>@field_validator(\"parameters\")\ndef filter_parameters(cls, user_params: dict, values: FieldValidationInfo) -&gt; Dict:\n    \"\"\"\n    Validate lr scheduler parameters.\n\n    This method filters out unknown parameters, given the lr scheduler name.\n\n    Parameters\n    ----------\n    user_params : dict\n        Parameters passed on to the torch lr scheduler.\n    values : FieldValidationInfo\n        Pydantic field validation info, used to get the lr scheduler name.\n\n    Returns\n    -------\n    Dict\n        Filtered lr scheduler parameters.\n\n    Raises\n    ------\n    ValueError\n        If the lr scheduler name is not specified.\n    \"\"\"\n    if \"name\" in values.data:\n        lr_scheduler_name = values.data[\"name\"]\n\n        # retrieve the corresponding lr scheduler class\n        lr_scheduler_class = getattr(optim.lr_scheduler, lr_scheduler_name)\n\n        # filter the user parameters according to the lr scheduler's signature\n        return get_parameters(lr_scheduler_class, user_params)\n    else:\n        raise ValueError(\n            \"Cannot validate lr scheduler parameters without `name`, check that it \"\n            \"has correctly been specified.\"\n        )\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.LrScheduler.model_dump","title":"<code>model_dump(exclude_optionals=True, *args, **kwargs)</code>","text":"<p>Override model_dump method.</p> <p>The purpose of this method is to ensure smooth export to yaml. It includes:     - removing entries with None value.     - removing optional values if they have the default value.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_optionals</code> <code>bool</code> <p>Whether to exclude optional arguments if they are default, by default True.</p> <code>True</code> <code>*args</code> <code>List</code> <p>Positional arguments, unused.</p> <code>()</code> <code>**kwargs</code> <code>Dict</code> <p>Keyword arguments, unused.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the model parameters.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>def model_dump(\n    self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n) -&gt; Dict:\n    \"\"\"\n    Override model_dump method.\n\n    The purpose of this method is to ensure smooth export to yaml. It includes:\n        - removing entries with None value.\n        - removing optional values if they have the default value.\n\n    Parameters\n    ----------\n    exclude_optionals : bool, optional\n        Whether to exclude optional arguments if they are default, by default True.\n    *args : List\n        Positional arguments, unused.\n    **kwargs : Dict\n        Keyword arguments, unused.\n\n    Returns\n    -------\n    dict\n        Dictionary containing the model parameters.\n    \"\"\"\n    dictionary = super().model_dump(exclude_none=True)\n\n    if exclude_optionals:\n        # remove optional arguments if they are default\n        default_optionals: dict = {\"parameters\": {}}\n        remove_default_optionals(dictionary, default_optionals)\n\n    return dictionary\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.LrScheduler.step_lr_step_size_parameter","title":"<code>step_lr_step_size_parameter(lr_scheduler)</code>","text":"<p>Check that StepLR lr scheduler has <code>step_size</code> parameter specified.</p> <p>Parameters:</p> Name Type Description Default <code>lr_scheduler</code> <code>LrScheduler</code> <p>Lr scheduler to validate.</p> required <p>Returns:</p> Type Description <code>LrScheduler</code> <p>Validated lr scheduler.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the lr scheduler is StepLR and the step_size parameter is not specified.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>@model_validator(mode=\"after\")\ndef step_lr_step_size_parameter(cls, lr_scheduler: LrScheduler) -&gt; LrScheduler:\n    \"\"\"\n    Check that StepLR lr scheduler has `step_size` parameter specified.\n\n    Parameters\n    ----------\n    lr_scheduler : LrScheduler\n        Lr scheduler to validate.\n\n    Returns\n    -------\n    LrScheduler\n        Validated lr scheduler.\n\n    Raises\n    ------\n    ValueError\n        If the lr scheduler is StepLR and the step_size parameter is not specified.\n    \"\"\"\n    if (\n        lr_scheduler.name == TorchLRScheduler.StepLR\n        and \"step_size\" not in lr_scheduler.parameters\n    ):\n        raise ValueError(\n            \"StepLR lr scheduler requires `step_size` parameter, check that it has \"\n            \"correctly been specified in `parameters`.\"\n        )\n\n    return lr_scheduler\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.Optimizer","title":"<code>Optimizer</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Torch optimizer.</p> <p>Only parameters supported by the corresponding torch optimizer will be taken into account. For more details, check: https://pytorch.org/docs/stable/optim.html#algorithms</p> <p>Note that mandatory parameters (see the specific Optimizer signature in the link above) must be provided. For example, SGD requires <code>lr</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>TorchOptimizer</code> <p>Name of the optimizer.</p> <code>parameters</code> <code>dict</code> <p>Parameters of the optimizer (see torch documentation).</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>class Optimizer(BaseModel):\n    \"\"\"\n    Torch optimizer.\n\n    Only parameters supported by the corresponding torch optimizer will be taken\n    into account. For more details, check:\n    https://pytorch.org/docs/stable/optim.html#algorithms\n\n    Note that mandatory parameters (see the specific Optimizer signature in the\n    link above) must be provided. For example, SGD requires `lr`.\n\n    Attributes\n    ----------\n    name : TorchOptimizer\n        Name of the optimizer.\n    parameters : dict\n        Parameters of the optimizer (see torch documentation).\n    \"\"\"\n\n    # Pydantic class configuration\n    model_config = ConfigDict(\n        use_enum_values=True,\n        validate_assignment=True,\n    )\n\n    # Mandatory field\n    name: TorchOptimizer\n\n    # Optional parameters\n    parameters: dict = {}\n\n    @field_validator(\"parameters\")\n    def filter_parameters(cls, user_params: dict, values: FieldValidationInfo) -&gt; Dict:\n        \"\"\"\n        Validate optimizer parameters.\n\n        This method filters out unknown parameters, given the optimizer name.\n\n        Parameters\n        ----------\n        user_params : dict\n            Parameters passed on to the torch optimizer.\n        values : FieldValidationInfo\n            Pydantic field validation info, used to get the optimizer name.\n\n        Returns\n        -------\n        Dict\n            Filtered optimizer parameters.\n\n        Raises\n        ------\n        ValueError\n            If the optimizer name is not specified.\n        \"\"\"\n        if \"name\" in values.data:\n            optimizer_name = values.data[\"name\"]\n\n            # retrieve the corresponding optimizer class\n            optimizer_class = getattr(optim, optimizer_name)\n\n            # filter the user parameters according to the optimizer's signature\n            return get_parameters(optimizer_class, user_params)\n        else:\n            raise ValueError(\n                \"Cannot validate optimizer parameters without `name`, check that it \"\n                \"has correctly been specified.\"\n            )\n\n    @model_validator(mode=\"after\")\n    def sgd_lr_parameter(cls, optimizer: Optimizer) -&gt; Optimizer:\n        \"\"\"\n        Check that SGD optimizer has the mandatory `lr` parameter specified.\n\n        Parameters\n        ----------\n        optimizer : Optimizer\n            Optimizer to validate.\n\n        Returns\n        -------\n        Optimizer\n            Validated optimizer.\n\n        Raises\n        ------\n        ValueError\n            If the optimizer is SGD and the lr parameter is not specified.\n        \"\"\"\n        if optimizer.name == TorchOptimizer.SGD and \"lr\" not in optimizer.parameters:\n            raise ValueError(\n                \"SGD optimizer requires `lr` parameter, check that it has correctly \"\n                \"been specified in `parameters`.\"\n            )\n\n        return optimizer\n\n    def model_dump(\n        self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n    ) -&gt; Dict:\n        \"\"\"\n        Override model_dump method.\n\n        The purpose of this method is to ensure smooth export to yaml. It\n        includes:\n            - removing entries with None value.\n            - removing optional values if they have the default value.\n\n        Parameters\n        ----------\n        exclude_optionals : bool, optional\n            Whether to exclude optional arguments if they are default, by default True.\n        *args : List\n            Positional arguments, unused.\n        **kwargs : Dict\n            Keyword arguments, unused.\n\n        Returns\n        -------\n        dict\n            Dictionary containing the model parameters.\n        \"\"\"\n        dictionary = super().model_dump(exclude_none=True)\n\n        if exclude_optionals:\n            # remove optional arguments if they are default\n            default_optionals: dict = {\"parameters\": {}}\n\n            remove_default_optionals(dictionary, default_optionals)\n\n        return dictionary\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.Optimizer.filter_parameters","title":"<code>filter_parameters(user_params, values)</code>","text":"<p>Validate optimizer parameters.</p> <p>This method filters out unknown parameters, given the optimizer name.</p> <p>Parameters:</p> Name Type Description Default <code>user_params</code> <code>dict</code> <p>Parameters passed on to the torch optimizer.</p> required <code>values</code> <code>FieldValidationInfo</code> <p>Pydantic field validation info, used to get the optimizer name.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Filtered optimizer parameters.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the optimizer name is not specified.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>@field_validator(\"parameters\")\ndef filter_parameters(cls, user_params: dict, values: FieldValidationInfo) -&gt; Dict:\n    \"\"\"\n    Validate optimizer parameters.\n\n    This method filters out unknown parameters, given the optimizer name.\n\n    Parameters\n    ----------\n    user_params : dict\n        Parameters passed on to the torch optimizer.\n    values : FieldValidationInfo\n        Pydantic field validation info, used to get the optimizer name.\n\n    Returns\n    -------\n    Dict\n        Filtered optimizer parameters.\n\n    Raises\n    ------\n    ValueError\n        If the optimizer name is not specified.\n    \"\"\"\n    if \"name\" in values.data:\n        optimizer_name = values.data[\"name\"]\n\n        # retrieve the corresponding optimizer class\n        optimizer_class = getattr(optim, optimizer_name)\n\n        # filter the user parameters according to the optimizer's signature\n        return get_parameters(optimizer_class, user_params)\n    else:\n        raise ValueError(\n            \"Cannot validate optimizer parameters without `name`, check that it \"\n            \"has correctly been specified.\"\n        )\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.Optimizer.model_dump","title":"<code>model_dump(exclude_optionals=True, *args, **kwargs)</code>","text":"<p>Override model_dump method.</p> <p>The purpose of this method is to ensure smooth export to yaml. It includes:     - removing entries with None value.     - removing optional values if they have the default value.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_optionals</code> <code>bool</code> <p>Whether to exclude optional arguments if they are default, by default True.</p> <code>True</code> <code>*args</code> <code>List</code> <p>Positional arguments, unused.</p> <code>()</code> <code>**kwargs</code> <code>Dict</code> <p>Keyword arguments, unused.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the model parameters.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>def model_dump(\n    self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n) -&gt; Dict:\n    \"\"\"\n    Override model_dump method.\n\n    The purpose of this method is to ensure smooth export to yaml. It\n    includes:\n        - removing entries with None value.\n        - removing optional values if they have the default value.\n\n    Parameters\n    ----------\n    exclude_optionals : bool, optional\n        Whether to exclude optional arguments if they are default, by default True.\n    *args : List\n        Positional arguments, unused.\n    **kwargs : Dict\n        Keyword arguments, unused.\n\n    Returns\n    -------\n    dict\n        Dictionary containing the model parameters.\n    \"\"\"\n    dictionary = super().model_dump(exclude_none=True)\n\n    if exclude_optionals:\n        # remove optional arguments if they are default\n        default_optionals: dict = {\"parameters\": {}}\n\n        remove_default_optionals(dictionary, default_optionals)\n\n    return dictionary\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.Optimizer.sgd_lr_parameter","title":"<code>sgd_lr_parameter(optimizer)</code>","text":"<p>Check that SGD optimizer has the mandatory <code>lr</code> parameter specified.</p> <p>Parameters:</p> Name Type Description Default <code>optimizer</code> <code>Optimizer</code> <p>Optimizer to validate.</p> required <p>Returns:</p> Type Description <code>Optimizer</code> <p>Validated optimizer.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the optimizer is SGD and the lr parameter is not specified.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>@model_validator(mode=\"after\")\ndef sgd_lr_parameter(cls, optimizer: Optimizer) -&gt; Optimizer:\n    \"\"\"\n    Check that SGD optimizer has the mandatory `lr` parameter specified.\n\n    Parameters\n    ----------\n    optimizer : Optimizer\n        Optimizer to validate.\n\n    Returns\n    -------\n    Optimizer\n        Validated optimizer.\n\n    Raises\n    ------\n    ValueError\n        If the optimizer is SGD and the lr parameter is not specified.\n    \"\"\"\n    if optimizer.name == TorchOptimizer.SGD and \"lr\" not in optimizer.parameters:\n        raise ValueError(\n            \"SGD optimizer requires `lr` parameter, check that it has correctly \"\n            \"been specified in `parameters`.\"\n        )\n\n    return optimizer\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.Training","title":"<code>Training</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Parameters related to the training.</p> <p>Mandatory parameters are:     - num_epochs: number of epochs, greater than 0.     - patch_size: patch size, 2D or 3D, non-zero and divisible by 2.     - batch_size: batch size, greater than 0.     - optimizer: optimizer, see <code>Optimizer</code>.     - lr_scheduler: learning rate scheduler, see <code>LrScheduler</code>.     - augmentation: whether to use data augmentation or not (True or False).</p> <p>The other fields are optional:     - use_wandb: whether to use wandb or not (default True).     - num_workers: number of workers (default 0).     - amp: automatic mixed precision parameters (disabled by default).</p> <p>Attributes:</p> Name Type Description <code>num_epochs</code> <code>int</code> <p>Number of epochs, greater than 0.</p> <code>patch_size</code> <code>conlist(int, min_length=2, max_length=3)</code> <p>Patch size, 2D or 3D, non-zero and divisible by 2.</p> <code>batch_size</code> <code>int</code> <p>Batch size, greater than 0.</p> <code>optimizer</code> <code>Optimizer</code> <p>Optimizer.</p> <code>lr_scheduler</code> <code>LrScheduler</code> <p>Learning rate scheduler.</p> <code>augmentation</code> <code>bool</code> <p>Whether to use data augmentation or not.</p> <code>use_wandb</code> <code>bool</code> <p>Optional, whether to use wandb or not (default True).</p> <code>num_workers</code> <code>int</code> <p>Optional, number of workers (default 0).</p> <code>amp</code> <code>AMP</code> <p>Optional, automatic mixed precision parameters (disabled by default).</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>class Training(BaseModel):\n    \"\"\"\n    Parameters related to the training.\n\n    Mandatory parameters are:\n        - num_epochs: number of epochs, greater than 0.\n        - patch_size: patch size, 2D or 3D, non-zero and divisible by 2.\n        - batch_size: batch size, greater than 0.\n        - optimizer: optimizer, see `Optimizer`.\n        - lr_scheduler: learning rate scheduler, see `LrScheduler`.\n        - augmentation: whether to use data augmentation or not (True or False).\n\n    The other fields are optional:\n        - use_wandb: whether to use wandb or not (default True).\n        - num_workers: number of workers (default 0).\n        - amp: automatic mixed precision parameters (disabled by default).\n\n    Attributes\n    ----------\n    num_epochs : int\n        Number of epochs, greater than 0.\n    patch_size : conlist(int, min_length=2, max_length=3)\n        Patch size, 2D or 3D, non-zero and divisible by 2.\n    batch_size : int\n        Batch size, greater than 0.\n    optimizer : Optimizer\n        Optimizer.\n    lr_scheduler : LrScheduler\n        Learning rate scheduler.\n    augmentation : bool\n        Whether to use data augmentation or not.\n    use_wandb : bool\n        Optional, whether to use wandb or not (default True).\n    num_workers : int\n        Optional, number of workers (default 0).\n    amp : AMP\n        Optional, automatic mixed precision parameters (disabled by default).\n    \"\"\"\n\n    # Pydantic class configuration\n    model_config = ConfigDict(\n        use_enum_values=True,\n        validate_assignment=True,\n    )\n\n    # Mandatory fields\n    num_epochs: int\n    patch_size: List[int] = Field(..., min_length=2, max_length=3)\n    batch_size: int\n\n    optimizer: Optimizer\n    lr_scheduler: LrScheduler\n\n    augmentation: bool\n\n    # Optional fields\n    use_wandb: bool = False\n    num_workers: int = Field(default=0, ge=0)\n    amp: AMP = AMP()\n\n    @field_validator(\"num_epochs\", \"batch_size\")\n    def greater_than_0(cls, val: int) -&gt; int:\n        \"\"\"\n        Validate number of epochs.\n\n        Number of epochs must be greater than 0.\n\n        Parameters\n        ----------\n        val : int\n            Number of epochs.\n\n        Returns\n        -------\n        int\n            Validated number of epochs.\n\n        Raises\n        ------\n        ValueError\n            If the number of epochs is 0.\n        \"\"\"\n        if val &lt; 1:\n            raise ValueError(f\"Number of epochs must be greater than 0 (got {val}).\")\n\n        return val\n\n    @field_validator(\"patch_size\")\n    def all_elements_non_zero_divisible_by_2(cls, patch_list: List[int]) -&gt; List[int]:\n        \"\"\"\n        Validate patch size.\n\n        Patch size must be non-zero, positive and divisible by 2.\n\n        Parameters\n        ----------\n        patch_list : List[int]\n            Patch size.\n\n        Returns\n        -------\n        List[int]\n            Validated patch size.\n\n        Raises\n        ------\n        ValueError\n            If the patch size is 0.\n        ValueError\n            If the patch size is not divisible by 2.\n        \"\"\"\n        for dim in patch_list:\n            if dim &lt; 1:\n                raise ValueError(f\"Patch size must be non-zero positive (got {dim}).\")\n\n            if dim % 2 != 0:\n                raise ValueError(f\"Patch size must be divisible by 2 (got {dim}).\")\n\n        return patch_list\n\n    def model_dump(\n        self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n    ) -&gt; Dict:\n        \"\"\"\n        Override model_dump method.\n\n        The purpose is to ensure export smooth import to yaml. It includes:\n            - remove entries with None value.\n            - remove optional values if they have the default value.\n\n        Parameters\n        ----------\n        exclude_optionals : bool, optional\n            Whether to exclude optional arguments if they are default, by default True.\n        *args : List\n            Positional arguments, unused.\n        **kwargs : Dict\n            Keyword arguments, unused.\n\n        Returns\n        -------\n        dict\n            Dictionary containing the model parameters.\n        \"\"\"\n        dictionary = super().model_dump(exclude_none=True)\n\n        dictionary[\"optimizer\"] = self.optimizer.model_dump(exclude_optionals)\n        dictionary[\"lr_scheduler\"] = self.lr_scheduler.model_dump(exclude_optionals)\n\n        if self.amp is not None:\n            dictionary[\"amp\"] = self.amp.model_dump(exclude_optionals)\n\n        if exclude_optionals:\n            # remove optional arguments if they are default\n            defaults = {\n                \"use_wandb\": False,\n                \"num_workers\": 0,\n                \"amp\": AMP().model_dump(),\n            }\n\n            remove_default_optionals(dictionary, defaults)\n\n        return dictionary\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.Training.all_elements_non_zero_divisible_by_2","title":"<code>all_elements_non_zero_divisible_by_2(patch_list)</code>","text":"<p>Validate patch size.</p> <p>Patch size must be non-zero, positive and divisible by 2.</p> <p>Parameters:</p> Name Type Description Default <code>patch_list</code> <code>List[int]</code> <p>Patch size.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>Validated patch size.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the patch size is 0.</p> <code>ValueError</code> <p>If the patch size is not divisible by 2.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>@field_validator(\"patch_size\")\ndef all_elements_non_zero_divisible_by_2(cls, patch_list: List[int]) -&gt; List[int]:\n    \"\"\"\n    Validate patch size.\n\n    Patch size must be non-zero, positive and divisible by 2.\n\n    Parameters\n    ----------\n    patch_list : List[int]\n        Patch size.\n\n    Returns\n    -------\n    List[int]\n        Validated patch size.\n\n    Raises\n    ------\n    ValueError\n        If the patch size is 0.\n    ValueError\n        If the patch size is not divisible by 2.\n    \"\"\"\n    for dim in patch_list:\n        if dim &lt; 1:\n            raise ValueError(f\"Patch size must be non-zero positive (got {dim}).\")\n\n        if dim % 2 != 0:\n            raise ValueError(f\"Patch size must be divisible by 2 (got {dim}).\")\n\n    return patch_list\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.Training.greater_than_0","title":"<code>greater_than_0(val)</code>","text":"<p>Validate number of epochs.</p> <p>Number of epochs must be greater than 0.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>int</code> <p>Number of epochs.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Validated number of epochs.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of epochs is 0.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>@field_validator(\"num_epochs\", \"batch_size\")\ndef greater_than_0(cls, val: int) -&gt; int:\n    \"\"\"\n    Validate number of epochs.\n\n    Number of epochs must be greater than 0.\n\n    Parameters\n    ----------\n    val : int\n        Number of epochs.\n\n    Returns\n    -------\n    int\n        Validated number of epochs.\n\n    Raises\n    ------\n    ValueError\n        If the number of epochs is 0.\n    \"\"\"\n    if val &lt; 1:\n        raise ValueError(f\"Number of epochs must be greater than 0 (got {val}).\")\n\n    return val\n</code></pre>"},{"location":"reference/careamics/config/training/#careamics.config.training.Training.model_dump","title":"<code>model_dump(exclude_optionals=True, *args, **kwargs)</code>","text":"<p>Override model_dump method.</p> <p>The purpose is to ensure export smooth import to yaml. It includes:     - remove entries with None value.     - remove optional values if they have the default value.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_optionals</code> <code>bool</code> <p>Whether to exclude optional arguments if they are default, by default True.</p> <code>True</code> <code>*args</code> <code>List</code> <p>Positional arguments, unused.</p> <code>()</code> <code>**kwargs</code> <code>Dict</code> <p>Keyword arguments, unused.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the model parameters.</p> Source code in <code>src/careamics/config/training.py</code> <pre><code>def model_dump(\n    self, exclude_optionals: bool = True, *args: List, **kwargs: Dict\n) -&gt; Dict:\n    \"\"\"\n    Override model_dump method.\n\n    The purpose is to ensure export smooth import to yaml. It includes:\n        - remove entries with None value.\n        - remove optional values if they have the default value.\n\n    Parameters\n    ----------\n    exclude_optionals : bool, optional\n        Whether to exclude optional arguments if they are default, by default True.\n    *args : List\n        Positional arguments, unused.\n    **kwargs : Dict\n        Keyword arguments, unused.\n\n    Returns\n    -------\n    dict\n        Dictionary containing the model parameters.\n    \"\"\"\n    dictionary = super().model_dump(exclude_none=True)\n\n    dictionary[\"optimizer\"] = self.optimizer.model_dump(exclude_optionals)\n    dictionary[\"lr_scheduler\"] = self.lr_scheduler.model_dump(exclude_optionals)\n\n    if self.amp is not None:\n        dictionary[\"amp\"] = self.amp.model_dump(exclude_optionals)\n\n    if exclude_optionals:\n        # remove optional arguments if they are default\n        defaults = {\n            \"use_wandb\": False,\n            \"num_workers\": 0,\n            \"amp\": AMP().model_dump(),\n        }\n\n        remove_default_optionals(dictionary, defaults)\n\n    return dictionary\n</code></pre>"},{"location":"reference/careamics/dataset/dataset_utils/","title":"dataset_utils","text":"<p>Convenience methods for datasets.</p>"},{"location":"reference/careamics/dataset/dataset_utils/#careamics.dataset.dataset_utils.list_files","title":"<code>list_files(data_path, data_format)</code>","text":"<p>Return a list of path to files in a directory.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>str</code> <p>Path to the folder containing the data.</p> required <code>data_format</code> <code>str</code> <p>Extension of the files to load, without period, e.g. <code>tif</code>.</p> required <p>Returns:</p> Type Description <code>List[Path]</code> <p>List of pathlib.Path objects.</p> Source code in <code>src/careamics/dataset/dataset_utils.py</code> <pre><code>def list_files(data_path: Union[str, Path], data_format: str) -&gt; List[Path]:\n    \"\"\"\n    Return a list of path to files in a directory.\n\n    Parameters\n    ----------\n    data_path : str\n        Path to the folder containing the data.\n    data_format : str\n        Extension of the files to load, without period, e.g. `tif`.\n\n    Returns\n    -------\n    List[Path]\n        List of pathlib.Path objects.\n    \"\"\"\n    files = sorted(Path(data_path).rglob(f\"*.{data_format}*\"))\n    return files\n</code></pre>"},{"location":"reference/careamics/dataset/dataset_utils/#careamics.dataset.dataset_utils.read_tiff","title":"<code>read_tiff(file_path, axes)</code>","text":"<p>Read a tiff file and return a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to a file.</p> required <code>axes</code> <code>str</code> <p>Description of axes in format STCZYX.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Resulting array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the file failed to open.</p> <code>OSError</code> <p>If the file failed to open.</p> <code>ValueError</code> <p>If the file is not a valid tiff.</p> <code>ValueError</code> <p>If the data dimensions are incorrect.</p> <code>ValueError</code> <p>If the axes length is incorrect.</p> Source code in <code>src/careamics/dataset/dataset_utils.py</code> <pre><code>def read_tiff(file_path: Path, axes: str) -&gt; np.ndarray:\n    \"\"\"\n    Read a tiff file and return a numpy array.\n\n    Parameters\n    ----------\n    file_path : Path\n        Path to a file.\n    axes : str\n        Description of axes in format STCZYX.\n\n    Returns\n    -------\n    np.ndarray\n        Resulting array.\n\n    Raises\n    ------\n    ValueError\n        If the file failed to open.\n    OSError\n        If the file failed to open.\n    ValueError\n        If the file is not a valid tiff.\n    ValueError\n        If the data dimensions are incorrect.\n    ValueError\n        If the axes length is incorrect.\n    \"\"\"\n    if file_path.suffix[:4] == \".tif\":\n        try:\n            sample = tifffile.imread(file_path)\n        except (ValueError, OSError) as e:\n            logging.exception(f\"Exception in file {file_path}: {e}, skipping it.\")\n            raise e\n    else:\n        raise ValueError(f\"File {file_path} is not a valid tiff.\")\n\n    sample = sample.squeeze()\n\n    if len(sample.shape) &lt; 2 or len(sample.shape) &gt; 4:\n        raise ValueError(\n            f\"Incorrect data dimensions. Must be 2, 3 or 4 (got {sample.shape} for\"\n            f\"file {file_path}).\"\n        )\n\n    # check number of axes\n    if len(axes) != len(sample.shape):\n        raise ValueError(f\"Incorrect axes length (got {axes} for file {file_path}).\")\n    sample = _update_axes(sample, axes)\n\n    return sample\n</code></pre>"},{"location":"reference/careamics/dataset/extraction_strategy/","title":"extraction_strategy","text":"<p>Extraction strategy module.</p> <p>This module defines the various extraction strategies available in CAREamics.</p>"},{"location":"reference/careamics/dataset/extraction_strategy/#careamics.dataset.extraction_strategy.ExtractionStrategy","title":"<code>ExtractionStrategy</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Available extraction strategies.</p> <p>Currently supported:     - random: random extraction.     - sequential: grid extraction, can miss edge values.     - tiled: tiled extraction, covers the whole image.</p> Source code in <code>src/careamics/dataset/extraction_strategy.py</code> <pre><code>class ExtractionStrategy(str, Enum):\n    \"\"\"\n    Available extraction strategies.\n\n    Currently supported:\n        - random: random extraction.\n        - sequential: grid extraction, can miss edge values.\n        - tiled: tiled extraction, covers the whole image.\n    \"\"\"\n\n    RANDOM = \"random\"\n    SEQUENTIAL = \"sequential\"\n    TILED = \"tiled\"\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/","title":"in_memory_dataset","text":"<p>In-memory dataset module.</p>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryDataset","title":"<code>InMemoryDataset</code>","text":"<p>             Bases: <code>Dataset</code></p> <p>Dataset storing data in memory and allowing generating patches from it.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Union[str, Path]</code> <p>Path to the data, must be a directory.</p> required <code>data_format</code> <code>str</code> <p>Extension of the data files, without period.</p> required <code>axes</code> <code>str</code> <p>Description of axes in format STCZYX.</p> required <code>patch_extraction_method</code> <code>ExtractionStrategies</code> <p>Patch extraction strategy, as defined in extraction_strategy.</p> required <code>patch_size</code> <code>Union[List[int], Tuple[int]]</code> <p>Size of the patches along each axis, must be of dimension 2 or 3.</p> required <code>patch_overlap</code> <code>Optional[Union[List[int], Tuple[int]]]</code> <p>Overlap of the patches, must be of dimension 2 or 3, by default None.</p> <code>None</code> <code>mean</code> <code>Optional[float]</code> <p>Expected mean of the dataset, by default None.</p> <code>None</code> <code>std</code> <code>Optional[float]</code> <p>Expected standard deviation of the dataset, by default None.</p> <code>None</code> <code>patch_transform</code> <code>Optional[Callable]</code> <p>Patch transform to apply, by default None.</p> <code>None</code> <code>patch_transform_params</code> <code>Optional[Dict]</code> <p>Patch transform parameters, by default None.</p> <code>None</code> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>class InMemoryDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Dataset storing data in memory and allowing generating patches from it.\n\n    Parameters\n    ----------\n    data_path : Union[str, Path]\n        Path to the data, must be a directory.\n    data_format : str\n        Extension of the data files, without period.\n    axes : str\n        Description of axes in format STCZYX.\n    patch_extraction_method : ExtractionStrategies\n        Patch extraction strategy, as defined in extraction_strategy.\n    patch_size : Union[List[int], Tuple[int]]\n        Size of the patches along each axis, must be of dimension 2 or 3.\n    patch_overlap : Optional[Union[List[int], Tuple[int]]], optional\n        Overlap of the patches, must be of dimension 2 or 3, by default None.\n    mean : Optional[float], optional\n        Expected mean of the dataset, by default None.\n    std : Optional[float], optional\n        Expected standard deviation of the dataset, by default None.\n    patch_transform : Optional[Callable], optional\n        Patch transform to apply, by default None.\n    patch_transform_params : Optional[Dict], optional\n        Patch transform parameters, by default None.\n    \"\"\"\n\n    def __init__(\n        self,\n        data_path: Union[str, Path],\n        data_format: str,\n        axes: str,\n        patch_extraction_method: ExtractionStrategy,\n        patch_size: Union[List[int], Tuple[int]],\n        patch_overlap: Optional[Union[List[int], Tuple[int]]] = None,\n        mean: Optional[float] = None,\n        std: Optional[float] = None,\n        patch_transform: Optional[Callable] = None,\n        patch_transform_params: Optional[Dict] = None,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        data_path : Union[str, Path]\n            Path to the data, must be a directory.\n        data_format : str\n            Extension of the data files, without period.\n        axes : str\n            Description of axes in format STCZYX.\n        patch_extraction_method : ExtractionStrategies\n            Patch extraction strategy, as defined in extraction_strategy.\n        patch_size : Union[List[int], Tuple[int]]\n            Size of the patches along each axis, must be of dimension 2 or 3.\n        patch_overlap : Optional[Union[List[int], Tuple[int]]], optional\n            Overlap of the patches, must be of dimension 2 or 3, by default None.\n        mean : Optional[float], optional\n            Expected mean of the dataset, by default None.\n        std : Optional[float], optional\n            Expected standard deviation of the dataset, by default None.\n        patch_transform : Optional[Callable], optional\n            Patch transform to apply, by default None.\n        patch_transform_params : Optional[Dict], optional\n            Patch transform parameters, by default None.\n\n        Raises\n        ------\n        ValueError\n            If data_path is not a directory.\n        \"\"\"\n        self.data_path = Path(data_path)\n        if not self.data_path.is_dir():\n            raise ValueError(\"Path to data should be an existing folder.\")\n\n        self.data_format = data_format\n        self.axes = axes\n\n        self.patch_transform = patch_transform\n\n        self.files = list_files(self.data_path, self.data_format)\n\n        self.patch_size = patch_size\n        self.patch_overlap = patch_overlap\n        self.patch_extraction_method = patch_extraction_method\n        self.patch_transform = patch_transform\n        self.patch_transform_params = patch_transform_params\n\n        self.mean = mean\n        self.std = std\n\n        # Generate patches\n        self.data, computed_mean, computed_std = self._prepare_patches()\n\n        if not mean or not std:\n            self.mean, self.std = computed_mean, computed_std\n            logger.info(f\"Computed dataset mean: {self.mean}, std: {self.std}\")\n\n        assert self.mean is not None\n        assert self.std is not None\n\n    def _prepare_patches(self) -&gt; Tuple[np.ndarray, float, float]:\n        \"\"\"\n        Iterate over data source and create an array of patches.\n\n        Returns\n        -------\n        np.ndarray\n            Array of patches.\n        \"\"\"\n        means, stds, num_samples = 0, 0, 0\n        self.all_patches = []\n        for filename in self.files:\n            sample = read_tiff(filename, self.axes)\n            means += sample.mean()\n            stds += np.std(sample)\n            num_samples += 1\n\n            # generate patches, return a generator\n            patches = generate_patches(\n                sample,\n                self.patch_extraction_method,\n                self.patch_size,\n                self.patch_overlap,\n            )\n\n            # convert generator to list and add to all_patches\n            self.all_patches.extend(list(patches))\n\n            result_mean, result_std = means / num_samples, stds / num_samples\n        return np.concatenate(self.all_patches), result_mean, result_std\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Return the length of the dataset.\n\n        Returns\n        -------\n        int\n            Length of the dataset.\n        \"\"\"\n        # convert to numpy array to convince mypy that it is not a generator\n        return sum(np.array(s).shape[0] for s in self.all_patches)\n\n    def __getitem__(self, index: int) -&gt; Tuple[np.ndarray]:\n        \"\"\"\n        Return the patch corresponding to the provided index.\n\n        Parameters\n        ----------\n        index : int\n            Index of the patch to return.\n\n        Returns\n        -------\n        Tuple[np.ndarray]\n            Patch.\n\n        Raises\n        ------\n        ValueError\n            If dataset mean and std are not set.\n        \"\"\"\n        patch = self.data[index].squeeze()\n\n        if self.mean is not None and self.std is not None:\n            if isinstance(patch, tuple):\n                patch = normalize(img=patch[0], mean=self.mean, std=self.std)\n                patch = (patch, *patch[1:])\n            else:\n                patch = normalize(img=patch, mean=self.mean, std=self.std)\n\n            if self.patch_transform is not None:\n                # replace None self.patch_transform_params with empty dict\n                if self.patch_transform_params is None:\n                    self.patch_transform_params = {}\n\n                patch = self.patch_transform(patch, **self.patch_transform_params)\n            return patch\n        else:\n            raise ValueError(\"Dataset mean and std must be set before using it.\")\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryDataset.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Return the patch corresponding to the provided index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index of the patch to return.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray]</code> <p>Patch.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If dataset mean and std are not set.</p> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>def __getitem__(self, index: int) -&gt; Tuple[np.ndarray]:\n    \"\"\"\n    Return the patch corresponding to the provided index.\n\n    Parameters\n    ----------\n    index : int\n        Index of the patch to return.\n\n    Returns\n    -------\n    Tuple[np.ndarray]\n        Patch.\n\n    Raises\n    ------\n    ValueError\n        If dataset mean and std are not set.\n    \"\"\"\n    patch = self.data[index].squeeze()\n\n    if self.mean is not None and self.std is not None:\n        if isinstance(patch, tuple):\n            patch = normalize(img=patch[0], mean=self.mean, std=self.std)\n            patch = (patch, *patch[1:])\n        else:\n            patch = normalize(img=patch, mean=self.mean, std=self.std)\n\n        if self.patch_transform is not None:\n            # replace None self.patch_transform_params with empty dict\n            if self.patch_transform_params is None:\n                self.patch_transform_params = {}\n\n            patch = self.patch_transform(patch, **self.patch_transform_params)\n        return patch\n    else:\n        raise ValueError(\"Dataset mean and std must be set before using it.\")\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryDataset.__init__","title":"<code>__init__(data_path, data_format, axes, patch_extraction_method, patch_size, patch_overlap=None, mean=None, std=None, patch_transform=None, patch_transform_params=None)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Union[str, Path]</code> <p>Path to the data, must be a directory.</p> required <code>data_format</code> <code>str</code> <p>Extension of the data files, without period.</p> required <code>axes</code> <code>str</code> <p>Description of axes in format STCZYX.</p> required <code>patch_extraction_method</code> <code>ExtractionStrategies</code> <p>Patch extraction strategy, as defined in extraction_strategy.</p> required <code>patch_size</code> <code>Union[List[int], Tuple[int]]</code> <p>Size of the patches along each axis, must be of dimension 2 or 3.</p> required <code>patch_overlap</code> <code>Optional[Union[List[int], Tuple[int]]]</code> <p>Overlap of the patches, must be of dimension 2 or 3, by default None.</p> <code>None</code> <code>mean</code> <code>Optional[float]</code> <p>Expected mean of the dataset, by default None.</p> <code>None</code> <code>std</code> <code>Optional[float]</code> <p>Expected standard deviation of the dataset, by default None.</p> <code>None</code> <code>patch_transform</code> <code>Optional[Callable]</code> <p>Patch transform to apply, by default None.</p> <code>None</code> <code>patch_transform_params</code> <code>Optional[Dict]</code> <p>Patch transform parameters, by default None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data_path is not a directory.</p> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>def __init__(\n    self,\n    data_path: Union[str, Path],\n    data_format: str,\n    axes: str,\n    patch_extraction_method: ExtractionStrategy,\n    patch_size: Union[List[int], Tuple[int]],\n    patch_overlap: Optional[Union[List[int], Tuple[int]]] = None,\n    mean: Optional[float] = None,\n    std: Optional[float] = None,\n    patch_transform: Optional[Callable] = None,\n    patch_transform_params: Optional[Dict] = None,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    data_path : Union[str, Path]\n        Path to the data, must be a directory.\n    data_format : str\n        Extension of the data files, without period.\n    axes : str\n        Description of axes in format STCZYX.\n    patch_extraction_method : ExtractionStrategies\n        Patch extraction strategy, as defined in extraction_strategy.\n    patch_size : Union[List[int], Tuple[int]]\n        Size of the patches along each axis, must be of dimension 2 or 3.\n    patch_overlap : Optional[Union[List[int], Tuple[int]]], optional\n        Overlap of the patches, must be of dimension 2 or 3, by default None.\n    mean : Optional[float], optional\n        Expected mean of the dataset, by default None.\n    std : Optional[float], optional\n        Expected standard deviation of the dataset, by default None.\n    patch_transform : Optional[Callable], optional\n        Patch transform to apply, by default None.\n    patch_transform_params : Optional[Dict], optional\n        Patch transform parameters, by default None.\n\n    Raises\n    ------\n    ValueError\n        If data_path is not a directory.\n    \"\"\"\n    self.data_path = Path(data_path)\n    if not self.data_path.is_dir():\n        raise ValueError(\"Path to data should be an existing folder.\")\n\n    self.data_format = data_format\n    self.axes = axes\n\n    self.patch_transform = patch_transform\n\n    self.files = list_files(self.data_path, self.data_format)\n\n    self.patch_size = patch_size\n    self.patch_overlap = patch_overlap\n    self.patch_extraction_method = patch_extraction_method\n    self.patch_transform = patch_transform\n    self.patch_transform_params = patch_transform_params\n\n    self.mean = mean\n    self.std = std\n\n    # Generate patches\n    self.data, computed_mean, computed_std = self._prepare_patches()\n\n    if not mean or not std:\n        self.mean, self.std = computed_mean, computed_std\n        logger.info(f\"Computed dataset mean: {self.mean}, std: {self.std}\")\n\n    assert self.mean is not None\n    assert self.std is not None\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryDataset.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the dataset.</p> <p>Returns:</p> Type Description <code>int</code> <p>Length of the dataset.</p> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Return the length of the dataset.\n\n    Returns\n    -------\n    int\n        Length of the dataset.\n    \"\"\"\n    # convert to numpy array to convince mypy that it is not a generator\n    return sum(np.array(s).shape[0] for s in self.all_patches)\n</code></pre>"},{"location":"reference/careamics/dataset/patching/","title":"patching","text":"<p>Tiling submodule.</p> <p>These functions are used to tile images into patches or tiles.</p>"},{"location":"reference/careamics/dataset/patching/#careamics.dataset.patching.generate_patches","title":"<code>generate_patches(sample, patch_extraction_method, patch_size=None, patch_overlap=None)</code>","text":"<p>Generate patches from a sample.</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>ndarray</code> <p>Input array.</p> required <code>patch_extraction_method</code> <code>ExtractionStrategies</code> <p>Patch extraction method, as defined in extraction_strategy.ExtractionStrategy.</p> required <code>patch_size</code> <code>Optional[Union[List[int], Tuple[int]]]</code> <p>Size of the patches along each dimension of the array, except the first.</p> <code>None</code> <code>patch_overlap</code> <code>Optional[Union[List[int], Tuple[int]]]</code> <p>Overlap between patches.</p> <code>None</code> <p>Returns:</p> Type Description <code>Generator[ndarray, None, None]</code> <p>Generator yielding patches/tiles.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If overlap is not specified when using tiling.</p> <code>ValueError</code> <p>If patches is None.</p> Source code in <code>src/careamics/dataset/patching.py</code> <pre><code>def generate_patches(\n    sample: np.ndarray,\n    patch_extraction_method: ExtractionStrategy,\n    patch_size: Optional[Union[List[int], Tuple[int]]] = None,\n    patch_overlap: Optional[Union[List[int], Tuple[int]]] = None,\n) -&gt; Generator[np.ndarray, None, None]:\n    \"\"\"\n    Generate patches from a sample.\n\n    Parameters\n    ----------\n    sample : np.ndarray\n        Input array.\n    patch_extraction_method : ExtractionStrategies\n        Patch extraction method, as defined in extraction_strategy.ExtractionStrategy.\n    patch_size : Optional[Union[List[int], Tuple[int]]]\n        Size of the patches along each dimension of the array, except the first.\n    patch_overlap : Optional[Union[List[int], Tuple[int]]]\n        Overlap between patches.\n\n    Returns\n    -------\n    Generator[np.ndarray, None, None]\n        Generator yielding patches/tiles.\n\n    Raises\n    ------\n    ValueError\n        If overlap is not specified when using tiling.\n    ValueError\n        If patches is None.\n    \"\"\"\n    patches = None\n\n    if patch_size is not None:\n        patches = None\n\n        if patch_extraction_method == ExtractionStrategy.TILED:\n            if patch_overlap is None:\n                raise ValueError(\n                    \"Overlaps must be specified when using tiling (got None).\"\n                )\n            patches = _extract_tiles(\n                arr=sample, tile_size=patch_size, overlaps=patch_overlap\n            )\n\n        elif patch_extraction_method == ExtractionStrategy.SEQUENTIAL:\n            patches = _extract_patches_sequential(sample, patch_size=patch_size)\n\n        else:\n            # random patching\n            patches = _extract_patches_random(sample, patch_size=patch_size)\n\n        return patches\n    else:\n        # no patching, return a generator for the sample\n        return (sample for _ in range(1))\n</code></pre>"},{"location":"reference/careamics/dataset/prepare_dataset/","title":"prepare_dataset","text":"<p>Dataset preparation module.</p> <p>Methods to set up the datasets for training, validation and prediction.</p>"},{"location":"reference/careamics/dataset/prepare_dataset/#careamics.dataset.prepare_dataset.get_prediction_dataset","title":"<code>get_prediction_dataset(config, pred_path, *, tile_shape=None, overlaps=None, axes=None)</code>","text":"<p>Create prediction dataset.</p> <p>To use tiling, both <code>tile_shape</code> and <code>overlaps</code> must be specified, have same length, be divisible by 2 and greater than 0. Finally, the overlaps must be smaller than the tiles.</p> <p>By default, axes are extracted from the configuration. To use images with different axes, set the <code>axes</code> parameter. Note that the difference between configuration and parameter axes must be S or T, but not any of the spatial dimensions (e.g. 2D vs 3D).</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>Configuration.</p> required <code>pred_path</code> <code>Union[str, Path]</code> <p>Path to prediction data.</p> required <code>tile_shape</code> <code>Optional[List[int]]</code> <p>2D or 3D shape of the tiles, by default None.</p> <code>None</code> <code>overlaps</code> <code>Optional[List[int]]</code> <p>2D or 3D overlaps between tiles, by default None.</p> <code>None</code> <code>axes</code> <code>Optional[str]</code> <p>Axes of the data, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>TiffDataset</code> <p>Dataset.</p> Source code in <code>src/careamics/dataset/prepare_dataset.py</code> <pre><code>def get_prediction_dataset(\n    config: Configuration,\n    pred_path: Union[str, Path],\n    *,\n    tile_shape: Optional[List[int]] = None,\n    overlaps: Optional[List[int]] = None,\n    axes: Optional[str] = None,\n) -&gt; TiffDataset:\n    \"\"\"\n    Create prediction dataset.\n\n    To use tiling, both `tile_shape` and `overlaps` must be specified, have same\n    length, be divisible by 2 and greater than 0. Finally, the overlaps must be\n    smaller than the tiles.\n\n    By default, axes are extracted from the configuration. To use images with\n    different axes, set the `axes` parameter. Note that the difference between\n    configuration and parameter axes must be S or T, but not any of the spatial\n    dimensions (e.g. 2D vs 3D).\n\n    Parameters\n    ----------\n    config : Configuration\n        Configuration.\n    pred_path : Union[str, Path]\n        Path to prediction data.\n    tile_shape : Optional[List[int]], optional\n        2D or 3D shape of the tiles, by default None.\n    overlaps : Optional[List[int]], optional\n        2D or 3D overlaps between tiles, by default None.\n    axes : Optional[str], optional\n        Axes of the data, by default None.\n\n    Returns\n    -------\n    TiffDataset\n        Dataset.\n    \"\"\"\n    use_tiling = False  # default value\n\n    # Validate tiles and overlaps\n    if tile_shape is not None and overlaps is not None:\n        check_tiling_validity(tile_shape, overlaps)\n\n        # Use tiling\n        use_tiling = True\n\n    # Extraction strategy\n    if use_tiling:\n        patch_extraction_method = ExtractionStrategy.TILED\n    else:\n        patch_extraction_method = None\n\n    # Create dataset\n    dataset = TiffDataset(\n        data_path=pred_path,\n        data_format=config.data.data_format,\n        axes=config.data.axes if axes is None else axes,  # supersede axes\n        mean=config.data.mean,\n        std=config.data.std,\n        patch_size=tile_shape,\n        patch_overlap=overlaps,\n        patch_extraction_method=patch_extraction_method,\n        patch_transform=None,\n    )\n\n    return dataset\n</code></pre>"},{"location":"reference/careamics/dataset/prepare_dataset/#careamics.dataset.prepare_dataset.get_train_dataset","title":"<code>get_train_dataset(config, train_path)</code>","text":"<p>Create training dataset.</p> <p>Depending on the configuration, this methods return either a TiffDataset or an InMemoryDataset.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>Configuration.</p> required <code>train_path</code> <code>Union[str, Path]</code> <p>Path to training data.</p> required <p>Returns:</p> Type Description <code>Union[TiffDataset, InMemoryDataset]</code> <p>Dataset.</p> Source code in <code>src/careamics/dataset/prepare_dataset.py</code> <pre><code>def get_train_dataset(\n    config: Configuration, train_path: str\n) -&gt; Union[TiffDataset, InMemoryDataset]:\n    \"\"\"\n    Create training dataset.\n\n    Depending on the configuration, this methods return either a TiffDataset or an\n    InMemoryDataset.\n\n    Parameters\n    ----------\n    config : Configuration\n        Configuration.\n    train_path : Union[str, Path]\n        Path to training data.\n\n    Returns\n    -------\n    Union[TiffDataset, InMemoryDataset]\n        Dataset.\n    \"\"\"\n    if config.data.in_memory:\n        dataset = InMemoryDataset(\n            data_path=train_path,\n            data_format=config.data.data_format,\n            axes=config.data.axes,\n            mean=config.data.mean,\n            std=config.data.std,\n            patch_extraction_method=ExtractionStrategy.SEQUENTIAL,\n            patch_size=config.training.patch_size,\n            patch_transform=default_manipulate,\n            patch_transform_params={\n                \"mask_pixel_percentage\": config.algorithm.masked_pixel_percentage,\n                \"roi_size\": config.algorithm.roi_size,\n            },\n        )\n    else:\n        dataset = TiffDataset(\n            data_path=train_path,\n            data_format=config.data.data_format,\n            axes=config.data.axes,\n            mean=config.data.mean,\n            std=config.data.std,\n            patch_extraction_method=ExtractionStrategy.RANDOM,\n            patch_size=config.training.patch_size,\n            patch_transform=default_manipulate,\n            patch_transform_params={\n                \"mask_pixel_percentage\": config.algorithm.masked_pixel_percentage,\n                \"roi_size\": config.algorithm.roi_size,\n            },\n        )\n    return dataset\n</code></pre>"},{"location":"reference/careamics/dataset/prepare_dataset/#careamics.dataset.prepare_dataset.get_validation_dataset","title":"<code>get_validation_dataset(config, val_path)</code>","text":"<p>Create validation dataset.</p> <p>Validation dataset is kept in memory.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>Configuration.</p> required <code>val_path</code> <code>Union[str, Path]</code> <p>Path to validation data.</p> required <p>Returns:</p> Type Description <code>TiffDataset</code> <p>In memory dataset.</p> Source code in <code>src/careamics/dataset/prepare_dataset.py</code> <pre><code>def get_validation_dataset(config: Configuration, val_path: str) -&gt; InMemoryDataset:\n    \"\"\"\n    Create validation dataset.\n\n    Validation dataset is kept in memory.\n\n    Parameters\n    ----------\n    config : Configuration\n        Configuration.\n    val_path : Union[str, Path]\n        Path to validation data.\n\n    Returns\n    -------\n    TiffDataset\n        In memory dataset.\n    \"\"\"\n    data_path = val_path\n\n    dataset = InMemoryDataset(\n        data_path=data_path,\n        data_format=config.data.data_format,\n        axes=config.data.axes,\n        mean=config.data.mean,\n        std=config.data.std,\n        patch_extraction_method=ExtractionStrategy.SEQUENTIAL,\n        patch_size=config.training.patch_size,\n        patch_transform=default_manipulate,\n        patch_transform_params={\n            \"mask_pixel_percentage\": config.algorithm.masked_pixel_percentage\n        },\n    )\n\n    return dataset\n</code></pre>"},{"location":"reference/careamics/dataset/tiff_dataset/","title":"tiff_dataset","text":"<p>Tiff dataset module.</p> <p>This module contains the implementation of the TiffDataset class, which allows loading tiff files.</p>"},{"location":"reference/careamics/dataset/tiff_dataset/#careamics.dataset.tiff_dataset.TiffDataset","title":"<code>TiffDataset</code>","text":"<p>             Bases: <code>IterableDataset</code></p> <p>Dataset allowing extracting patches from tiff images.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Union[str, Path]</code> <p>Path to the data, must be a directory.</p> required <code>data_format</code> <code>str</code> <p>Extension of the files to load, without the period.</p> required <code>axes</code> <code>str</code> <p>Description of axes in format STCZYX.</p> required <code>patch_extraction_method</code> <code>Union[ExtractionStrategies, None]</code> <p>Patch extraction strategy, as defined in extraction_strategy.</p> required <code>patch_size</code> <code>Optional[Union[List[int], Tuple[int]]]</code> <p>Size of the patches in each dimension, by default None.</p> <code>None</code> <code>patch_overlap</code> <code>Optional[Union[List[int], Tuple[int]]]</code> <p>Overlap of the patches in each dimension, by default None.</p> <code>None</code> <code>mean</code> <code>Optional[float]</code> <p>Expected mean of the dataset, by default None.</p> <code>None</code> <code>std</code> <code>Optional[float]</code> <p>Expected standard deviation of the dataset, by default None.</p> <code>None</code> <code>patch_transform</code> <code>Optional[Callable]</code> <p>Patch transform callable, by default None.</p> <code>None</code> <code>patch_transform_params</code> <code>Optional[Dict]</code> <p>Patch transform parameters, by default None.</p> <code>None</code> Source code in <code>src/careamics/dataset/tiff_dataset.py</code> <pre><code>class TiffDataset(torch.utils.data.IterableDataset):\n    \"\"\"\n    Dataset allowing extracting patches from tiff images.\n\n    Parameters\n    ----------\n    data_path : Union[str, Path]\n        Path to the data, must be a directory.\n    data_format : str\n        Extension of the files to load, without the period.\n    axes : str\n        Description of axes in format STCZYX.\n    patch_extraction_method : Union[ExtractionStrategies, None]\n        Patch extraction strategy, as defined in extraction_strategy.\n    patch_size : Optional[Union[List[int], Tuple[int]]], optional\n        Size of the patches in each dimension, by default None.\n    patch_overlap : Optional[Union[List[int], Tuple[int]]], optional\n        Overlap of the patches in each dimension, by default None.\n    mean : Optional[float], optional\n        Expected mean of the dataset, by default None.\n    std : Optional[float], optional\n        Expected standard deviation of the dataset, by default None.\n    patch_transform : Optional[Callable], optional\n        Patch transform callable, by default None.\n    patch_transform_params : Optional[Dict], optional\n        Patch transform parameters, by default None.\n    \"\"\"\n\n    def __init__(\n        self,\n        data_path: Union[str, Path],\n        data_format: str,  # TODO: TiffDataset should not know that they are tiff\n        axes: str,\n        patch_extraction_method: Union[ExtractionStrategy, None],\n        patch_size: Optional[Union[List[int], Tuple[int]]] = None,\n        patch_overlap: Optional[Union[List[int], Tuple[int]]] = None,\n        mean: Optional[float] = None,\n        std: Optional[float] = None,\n        patch_transform: Optional[Callable] = None,\n        patch_transform_params: Optional[Dict] = None,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        data_path : Union[str, Path]\n            Path to the data, must be a directory.\n        data_format : str\n            Extension of the files to load, without the period.\n        axes : str\n            Description of axes in format STCZYX.\n        patch_extraction_method : Union[ExtractionStrategies, None]\n            Patch extraction strategy, as defined in extraction_strategy.\n        patch_size : Optional[Union[List[int], Tuple[int]]], optional\n            Size of the patches in each dimension, by default None.\n        patch_overlap : Optional[Union[List[int], Tuple[int]]], optional\n            Overlap of the patches in each dimension, by default None.\n        mean : Optional[float], optional\n            Mean of the dataset, by default None.\n        std : Optional[float], optional\n            Standard deviation of the dataset, by default None.\n        patch_transform : Optional[Callable], optional\n            Patch transform callable, by default None.\n        patch_transform_params : Optional[Dict], optional\n            Patch transform parameters, by default None.\n\n        Raises\n        ------\n        ValueError\n            If data_path is not a directory.\n        \"\"\"\n        self.data_path = Path(data_path)\n        if not self.data_path.is_dir():\n            raise ValueError(\"Path to data should be an existing folder.\")\n\n        self.data_format = data_format\n        self.axes = axes\n\n        self.patch_transform = patch_transform\n\n        self.files = list_files(self.data_path, self.data_format)\n\n        self.mean = mean\n        self.std = std\n        if not mean or not std:\n            self.mean, self.std = self._calculate_mean_and_std()\n\n        self.patch_size = patch_size\n        self.patch_overlap = patch_overlap\n        self.patch_extraction_method = patch_extraction_method\n        self.patch_transform = patch_transform\n        self.patch_transform_params = patch_transform_params\n\n    def _calculate_mean_and_std(self) -&gt; Tuple[float, float]:\n        \"\"\"\n        Calculate mean and std of the dataset.\n\n        Returns\n        -------\n        Tuple[float, float]\n            Tuple containing mean and standard deviation.\n        \"\"\"\n        means, stds = 0, 0\n        num_samples = 0\n\n        for sample in self._iterate_files():\n            means += sample.mean()\n            stds += np.std(sample)\n            num_samples += 1\n\n        result_mean = means / num_samples\n        result_std = stds / num_samples\n\n        logger.info(f\"Calculated mean and std for {num_samples} images\")\n        logger.info(f\"Mean: {result_mean}, std: {result_std}\")\n        return result_mean, result_std\n\n    def _iterate_files(self) -&gt; Generator:\n        \"\"\"\n        Iterate over data source and yield whole image.\n\n        Yields\n        ------\n        np.ndarray\n            Image.\n        \"\"\"\n        # When num_workers &gt; 0, each worker process will have a different copy of the\n        # dataset object\n        # Configuring each copy independently to avoid having duplicate data returned\n        # from the workers\n        worker_info = torch.utils.data.get_worker_info()\n        worker_id = worker_info.id if worker_info is not None else 0\n        num_workers = worker_info.num_workers if worker_info is not None else 1\n\n        for i, filename in enumerate(self.files):\n            if i % num_workers == worker_id:\n                sample = read_tiff(filename, self.axes)\n                yield sample\n\n    def __iter__(self) -&gt; Generator[np.ndarray, None, None]:\n        \"\"\"\n        Iterate over data source and yield single patch.\n\n        Yields\n        ------\n        np.ndarray\n            Single patch.\n        \"\"\"\n        assert (\n            self.mean is not None and self.std is not None\n        ), \"Mean and std must be provided\"\n        for sample in self._iterate_files():\n            # TODO patch_extraction_method should never be None!\n            if self.patch_extraction_method:\n                # TODO: move S and T unpacking logic from patch generator\n                patches = generate_patches(\n                    sample,\n                    self.patch_extraction_method,\n                    self.patch_size,\n                    self.patch_overlap,\n                )\n\n                for patch in patches:\n                    if isinstance(patch, tuple):\n                        normalized_patch = normalize(\n                            img=patch[0], mean=self.mean, std=self.std\n                        )\n                        patch = (normalized_patch, *patch[1:])\n                    else:\n                        patch = normalize(img=patch, mean=self.mean, std=self.std)\n\n                    if self.patch_transform is not None:\n                        assert self.patch_transform_params is not None\n                        patch = self.patch_transform(\n                            patch, **self.patch_transform_params\n                        )\n\n                    yield patch\n\n            else:\n                # if S or T dims are not empty - assume every image is a separate\n                # sample in dim 0\n                for i in range(sample.shape[0]):\n                    item = np.expand_dims(sample[i], (0, 1))\n                    item = normalize(img=item, mean=self.mean, std=self.std)\n                    yield item\n</code></pre>"},{"location":"reference/careamics/dataset/tiff_dataset/#careamics.dataset.tiff_dataset.TiffDataset.__init__","title":"<code>__init__(data_path, data_format, axes, patch_extraction_method, patch_size=None, patch_overlap=None, mean=None, std=None, patch_transform=None, patch_transform_params=None)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Union[str, Path]</code> <p>Path to the data, must be a directory.</p> required <code>data_format</code> <code>str</code> <p>Extension of the files to load, without the period.</p> required <code>axes</code> <code>str</code> <p>Description of axes in format STCZYX.</p> required <code>patch_extraction_method</code> <code>Union[ExtractionStrategies, None]</code> <p>Patch extraction strategy, as defined in extraction_strategy.</p> required <code>patch_size</code> <code>Optional[Union[List[int], Tuple[int]]]</code> <p>Size of the patches in each dimension, by default None.</p> <code>None</code> <code>patch_overlap</code> <code>Optional[Union[List[int], Tuple[int]]]</code> <p>Overlap of the patches in each dimension, by default None.</p> <code>None</code> <code>mean</code> <code>Optional[float]</code> <p>Mean of the dataset, by default None.</p> <code>None</code> <code>std</code> <code>Optional[float]</code> <p>Standard deviation of the dataset, by default None.</p> <code>None</code> <code>patch_transform</code> <code>Optional[Callable]</code> <p>Patch transform callable, by default None.</p> <code>None</code> <code>patch_transform_params</code> <code>Optional[Dict]</code> <p>Patch transform parameters, by default None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data_path is not a directory.</p> Source code in <code>src/careamics/dataset/tiff_dataset.py</code> <pre><code>def __init__(\n    self,\n    data_path: Union[str, Path],\n    data_format: str,  # TODO: TiffDataset should not know that they are tiff\n    axes: str,\n    patch_extraction_method: Union[ExtractionStrategy, None],\n    patch_size: Optional[Union[List[int], Tuple[int]]] = None,\n    patch_overlap: Optional[Union[List[int], Tuple[int]]] = None,\n    mean: Optional[float] = None,\n    std: Optional[float] = None,\n    patch_transform: Optional[Callable] = None,\n    patch_transform_params: Optional[Dict] = None,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    data_path : Union[str, Path]\n        Path to the data, must be a directory.\n    data_format : str\n        Extension of the files to load, without the period.\n    axes : str\n        Description of axes in format STCZYX.\n    patch_extraction_method : Union[ExtractionStrategies, None]\n        Patch extraction strategy, as defined in extraction_strategy.\n    patch_size : Optional[Union[List[int], Tuple[int]]], optional\n        Size of the patches in each dimension, by default None.\n    patch_overlap : Optional[Union[List[int], Tuple[int]]], optional\n        Overlap of the patches in each dimension, by default None.\n    mean : Optional[float], optional\n        Mean of the dataset, by default None.\n    std : Optional[float], optional\n        Standard deviation of the dataset, by default None.\n    patch_transform : Optional[Callable], optional\n        Patch transform callable, by default None.\n    patch_transform_params : Optional[Dict], optional\n        Patch transform parameters, by default None.\n\n    Raises\n    ------\n    ValueError\n        If data_path is not a directory.\n    \"\"\"\n    self.data_path = Path(data_path)\n    if not self.data_path.is_dir():\n        raise ValueError(\"Path to data should be an existing folder.\")\n\n    self.data_format = data_format\n    self.axes = axes\n\n    self.patch_transform = patch_transform\n\n    self.files = list_files(self.data_path, self.data_format)\n\n    self.mean = mean\n    self.std = std\n    if not mean or not std:\n        self.mean, self.std = self._calculate_mean_and_std()\n\n    self.patch_size = patch_size\n    self.patch_overlap = patch_overlap\n    self.patch_extraction_method = patch_extraction_method\n    self.patch_transform = patch_transform\n    self.patch_transform_params = patch_transform_params\n</code></pre>"},{"location":"reference/careamics/dataset/tiff_dataset/#careamics.dataset.tiff_dataset.TiffDataset.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over data source and yield single patch.</p> <p>Yields:</p> Type Description <code>ndarray</code> <p>Single patch.</p> Source code in <code>src/careamics/dataset/tiff_dataset.py</code> <pre><code>def __iter__(self) -&gt; Generator[np.ndarray, None, None]:\n    \"\"\"\n    Iterate over data source and yield single patch.\n\n    Yields\n    ------\n    np.ndarray\n        Single patch.\n    \"\"\"\n    assert (\n        self.mean is not None and self.std is not None\n    ), \"Mean and std must be provided\"\n    for sample in self._iterate_files():\n        # TODO patch_extraction_method should never be None!\n        if self.patch_extraction_method:\n            # TODO: move S and T unpacking logic from patch generator\n            patches = generate_patches(\n                sample,\n                self.patch_extraction_method,\n                self.patch_size,\n                self.patch_overlap,\n            )\n\n            for patch in patches:\n                if isinstance(patch, tuple):\n                    normalized_patch = normalize(\n                        img=patch[0], mean=self.mean, std=self.std\n                    )\n                    patch = (normalized_patch, *patch[1:])\n                else:\n                    patch = normalize(img=patch, mean=self.mean, std=self.std)\n\n                if self.patch_transform is not None:\n                    assert self.patch_transform_params is not None\n                    patch = self.patch_transform(\n                        patch, **self.patch_transform_params\n                    )\n\n                yield patch\n\n        else:\n            # if S or T dims are not empty - assume every image is a separate\n            # sample in dim 0\n            for i in range(sample.shape[0]):\n                item = np.expand_dims(sample[i], (0, 1))\n                item = normalize(img=item, mean=self.mean, std=self.std)\n                yield item\n</code></pre>"},{"location":"reference/careamics/losses/loss_factory/","title":"loss_factory","text":"<p>Loss factory module.</p> <p>This module contains a factory function for creating loss functions.</p>"},{"location":"reference/careamics/losses/loss_factory/#careamics.losses.loss_factory.create_loss_function","title":"<code>create_loss_function(config)</code>","text":"<p>Create loss function based on Configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>Configuration.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>Loss function.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the loss is unknown.</p> Source code in <code>src/careamics/losses/loss_factory.py</code> <pre><code>def create_loss_function(config: Configuration) -&gt; Callable:\n    \"\"\"\n    Create loss function based on Configuration.\n\n    Parameters\n    ----------\n    config : Configuration\n        Configuration.\n\n    Returns\n    -------\n    Callable\n        Loss function.\n\n    Raises\n    ------\n    NotImplementedError\n        If the loss is unknown.\n    \"\"\"\n    loss_type = config.algorithm.loss\n\n    if loss_type == Loss.N2V:\n        return n2v_loss\n    else:\n        raise NotImplementedError(f\"Loss {loss_type} is not yet supported.\")\n</code></pre>"},{"location":"reference/careamics/losses/losses/","title":"losses","text":"<p>Loss submodule.</p> <p>This submodule contains the various losses used in CAREamics.</p>"},{"location":"reference/careamics/losses/losses/#careamics.losses.losses.n2v_loss","title":"<code>n2v_loss(samples, labels, masks, device)</code>","text":"<p>N2V Loss function (see Eq.7 in Krull et al).</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>Patches with manipulated pixels.</p> required <code>labels</code> <code>Tensor</code> <p>Noisy patches.</p> required <code>masks</code> <code>Tensor</code> <p>Array containing masked pixel locations.</p> required <code>device</code> <code>str</code> <p>Device to use.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Loss value.</p> Source code in <code>src/careamics/losses/losses.py</code> <pre><code>def n2v_loss(\n    samples: torch.Tensor, labels: torch.Tensor, masks: torch.Tensor, device: str\n) -&gt; torch.Tensor:\n    \"\"\"\n    N2V Loss function (see Eq.7 in Krull et al).\n\n    Parameters\n    ----------\n    samples : torch.Tensor\n        Patches with manipulated pixels.\n    labels : torch.Tensor\n        Noisy patches.\n    masks : torch.Tensor\n        Array containing masked pixel locations.\n    device : str\n        Device to use.\n\n    Returns\n    -------\n    torch.Tensor\n        Loss value.\n    \"\"\"\n    errors = (labels - samples) ** 2\n    # Average over pixels and batch\n    loss = torch.sum(errors * masks) / torch.sum(masks)\n    return loss\n</code></pre>"},{"location":"reference/careamics/manipulation/pixel_manipulation/","title":"pixel_manipulation","text":"<p>Pixel manipulation methods.</p> <p>Pixel manipulation is used in N2V and similar algorithm to replace the value of masked pixels.</p>"},{"location":"reference/careamics/manipulation/pixel_manipulation/#careamics.manipulation.pixel_manipulation.default_manipulate","title":"<code>default_manipulate(patch, mask_pixel_percentage, roi_size=11, augmentations=None)</code>","text":"<p>Manipulate pixel in a patch, i.e. replace the masked value.</p> <p>Parameters:</p> Name Type Description Default <code>patch</code> <code>ndarray</code> <p>Image patch, 2D or 3D, shape (y, x) or (z, y, x).</p> required <code>mask_pixel_percentage</code> <code>floar</code> <p>Approximate percentage of pixels to be masked.</p> required <code>roi_size</code> <code>int</code> <p>Size of the ROI the new pixel value is sampled from, by default 11.</p> <code>11</code> <code>augmentations</code> <code>Callable</code> <p>Augmentations to apply, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray]</code> <p>Tuple containing the manipulated patch, the original patch and the mask.</p> Source code in <code>src/careamics/manipulation/pixel_manipulation.py</code> <pre><code>def default_manipulate(\n    patch: np.ndarray,\n    mask_pixel_percentage: float,\n    roi_size: int = 11,\n    augmentations: Optional[Callable] = None,\n) -&gt; Tuple[np.ndarray, ...]:\n    \"\"\"\n    Manipulate pixel in a patch, i.e. replace the masked value.\n\n    Parameters\n    ----------\n    patch : np.ndarray\n        Image patch, 2D or 3D, shape (y, x) or (z, y, x).\n    mask_pixel_percentage : floar\n        Approximate percentage of pixels to be masked.\n    roi_size : int\n        Size of the ROI the new pixel value is sampled from, by default 11.\n    augmentations : Callable, optional\n        Augmentations to apply, by default None.\n\n    Returns\n    -------\n    Tuple[np.ndarray]\n        Tuple containing the manipulated patch, the original patch and the mask.\n    \"\"\"\n    original_patch = patch.copy()\n\n    # Get the coordinates of the pixels to be replaced\n    roi_centers = get_stratified_coords(mask_pixel_percentage, patch.shape)\n    rng = np.random.default_rng()\n\n    # Generate coordinate grid for ROI\n    roi_span_full = np.arange(-np.floor(roi_size / 2), np.ceil(roi_size / 2)).astype(\n        np.int32\n    )\n    # Remove the center pixel from the grid\n    roi_span_wo_center = roi_span_full[roi_span_full != 0]\n\n    # Randomly select coordinates from the grid\n    random_increment = rng.choice(roi_span_wo_center, size=roi_centers.shape)\n\n    # Clip the coordinates to the patch size\n    replacement_coords = np.clip(\n        roi_centers + random_increment,\n        0,\n        [patch.shape[i] - 1 for i in range(len(patch.shape))],\n    )\n    # Get the replacement pixels from all rois\n    replacement_pixels = patch[tuple(replacement_coords.T.tolist())]\n\n    # Replace the original pixels with the replacement pixels\n    patch[tuple(roi_centers.T.tolist())] = replacement_pixels\n    mask = np.where(patch != original_patch, 1, 0).astype(np.uint8)\n\n    patch, original_patch, mask = (\n        (patch, original_patch, mask)\n        if augmentations is None\n        else augmentations(patch, original_patch, mask)\n    )\n\n    return (\n        np.expand_dims(patch, 0),\n        np.expand_dims(original_patch, 0),\n        np.expand_dims(mask, 0),\n    )\n</code></pre>"},{"location":"reference/careamics/manipulation/pixel_manipulation/#careamics.manipulation.pixel_manipulation.get_stratified_coords","title":"<code>get_stratified_coords(mask_pixel_perc, shape)</code>","text":"<p>Generate coordinates of the pixels to mask.</p> <p>Randomly selects the coordinates of the pixels to mask in a stratified way, i.e. the distance between masked pixels is approximately the same.</p> <p>Parameters:</p> Name Type Description Default <code>mask_pixel_perc</code> <code>float</code> <p>Actual (quasi) percentage of masked pixels across the whole image. Used in calculating the distance between masked pixels across each axis.</p> required <code>shape</code> <code>Tuple[int, ...]</code> <p>Shape of the input patch.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of coordinates of the masked pixels.</p> Source code in <code>src/careamics/manipulation/pixel_manipulation.py</code> <pre><code>def get_stratified_coords(\n    mask_pixel_perc: float,\n    shape: Tuple[int, ...],\n) -&gt; np.ndarray:\n    \"\"\"\n    Generate coordinates of the pixels to mask.\n\n    Randomly selects the coordinates of the pixels to mask in a stratified way, i.e.\n    the distance between masked pixels is approximately the same.\n\n    Parameters\n    ----------\n    mask_pixel_perc : float\n        Actual (quasi) percentage of masked pixels across the whole image. Used in\n        calculating the distance between masked pixels across each axis.\n    shape : Tuple[int, ...]\n        Shape of the input patch.\n\n    Returns\n    -------\n    np.ndarray\n        Array of coordinates of the masked pixels.\n    \"\"\"\n    rng = np.random.default_rng()\n\n    # Define the approximate distance between masked pixels\n    mask_pixel_distance = np.round((100 / mask_pixel_perc) ** (1 / len(shape))).astype(\n        np.int32\n    )\n\n    # Define a grid of coordinates for each axis in the input patch and the step size\n    pixel_coords = []\n    for axis_size in shape:\n        # make sure axis size is evenly divisible by box size\n        num_pixels = int(np.ceil(axis_size / mask_pixel_distance))\n        axis_pixel_coords, step = np.linspace(\n            0, axis_size, num_pixels, dtype=np.int32, endpoint=False, retstep=True\n        )\n        # explain\n        pixel_coords.append(axis_pixel_coords.T)\n\n    # Create a meshgrid of coordinates for each axis in the input patch\n    coordinate_grid_list = np.meshgrid(*pixel_coords)\n    coordinate_grid = np.array(coordinate_grid_list).reshape(len(shape), -1).T\n\n    grid_random_increment = rng.integers(\n        _odd_jitter_func(float(step), rng)\n        * np.ones_like(coordinate_grid).astype(np.int32)\n        - 1,\n        size=coordinate_grid.shape,\n        endpoint=True,\n    )\n    coordinate_grid += grid_random_increment\n    coordinate_grid = np.clip(coordinate_grid, 0, np.array(shape) - 1)\n    return coordinate_grid\n</code></pre>"},{"location":"reference/careamics/models/layers/","title":"layers","text":"<p>Layer module.</p> <p>This submodule contains layers used in the CAREamics models.</p>"},{"location":"reference/careamics/models/layers/#careamics.models.layers.Conv_Block","title":"<code>Conv_Block</code>","text":"<p>             Bases: <code>Module</code></p> <p>Convolution block used in UNets.</p> <p>Convolution block consist of two convolution layers with optional batch norm, dropout and with a final activation function.</p> <p>The parameters are directly mapped to PyTorch Conv2D and Conv3d parameters, see PyTorch torch.nn.Conv2d and torch.nn.Conv3d for more information.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolutions, 2 or 3.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>intermediate_channel_multiplier</code> <code>int</code> <p>Multiplied for the number of output channels, by default 1.</p> <code>1</code> <code>stride</code> <code>int</code> <p>Stride of the convolutions, by default 1.</p> <code>1</code> <code>padding</code> <code>int</code> <p>Padding of the convolutions, by default 1.</p> <code>1</code> <code>bias</code> <code>bool</code> <p>Bias of the convolutions, by default True.</p> <code>True</code> <code>groups</code> <code>int</code> <p>Controls the connections between inputs and outputs, by default 1.</p> <code>1</code> <code>activation</code> <code>str</code> <p>Activation function, by default \"ReLU\".</p> <code>'ReLU'</code> <code>dropout_perc</code> <code>float</code> <p>Dropout percentage, by default 0.</p> <code>0</code> <code>use_batch_norm</code> <code>bool</code> <p>Use batch norm, by default False.</p> <code>False</code> Source code in <code>src/careamics/models/layers.py</code> <pre><code>class Conv_Block(nn.Module):\n    \"\"\"\n    Convolution block used in UNets.\n\n    Convolution block consist of two convolution layers with optional batch norm,\n    dropout and with a final activation function.\n\n    The parameters are directly mapped to PyTorch Conv2D and Conv3d parameters, see\n    PyTorch torch.nn.Conv2d and torch.nn.Conv3d for more information.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolutions, 2 or 3.\n    in_channels : int\n        Number of input channels.\n    out_channels : int\n        Number of output channels.\n    intermediate_channel_multiplier : int, optional\n        Multiplied for the number of output channels, by default 1.\n    stride : int, optional\n        Stride of the convolutions, by default 1.\n    padding : int, optional\n        Padding of the convolutions, by default 1.\n    bias : bool, optional\n        Bias of the convolutions, by default True.\n    groups : int, optional\n        Controls the connections between inputs and outputs, by default 1.\n    activation : str, optional\n        Activation function, by default \"ReLU\".\n    dropout_perc : float, optional\n        Dropout percentage, by default 0.\n    use_batch_norm : bool, optional\n        Use batch norm, by default False.\n    \"\"\"\n\n    def __init__(\n        self,\n        conv_dim: int,\n        in_channels: int,\n        out_channels: int,\n        intermediate_channel_multiplier: int = 1,\n        stride: int = 1,\n        padding: int = 1,\n        bias: bool = True,\n        groups: int = 1,\n        activation: str = \"ReLU\",\n        dropout_perc: float = 0,\n        use_batch_norm: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        conv_dim : int\n            Number of dimension of the convolutions, 2 or 3.\n        in_channels : int\n            Number of input channels.\n        out_channels : int\n            Number of output channels.\n        intermediate_channel_multiplier : int, optional\n            Multiplied for the number of output channels, by default 1.\n        stride : int, optional\n            Stride of the convolutions, by default 1.\n        padding : int, optional\n            Padding of the convolutions, by default 1.\n        bias : bool, optional\n            Bias of the convolutions, by default True.\n        groups : int, optional\n            Controls the connections between inputs and outputs, by default 1.\n        activation : str, optional\n            Activation function, by default \"ReLU\".\n        dropout_perc : float, optional\n            Dropout percentage, by default 0.\n        use_batch_norm : bool, optional\n            Use batch norm, by default False.\n        \"\"\"\n        super().__init__()\n        self.use_batch_norm = use_batch_norm\n        self.conv1 = getattr(nn, f\"Conv{conv_dim}d\")(\n            in_channels,\n            out_channels * intermediate_channel_multiplier,\n            kernel_size=3,\n            stride=stride,\n            padding=padding,\n            bias=bias,\n            groups=groups,\n        )\n\n        self.conv2 = getattr(nn, f\"Conv{conv_dim}d\")(\n            out_channels * intermediate_channel_multiplier,\n            out_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=padding,\n            bias=bias,\n            groups=groups,\n        )\n\n        self.batch_norm1 = getattr(nn, f\"BatchNorm{conv_dim}d\")(\n            out_channels * intermediate_channel_multiplier\n        )\n        self.batch_norm2 = getattr(nn, f\"BatchNorm{conv_dim}d\")(out_channels)\n\n        self.dropout = (\n            getattr(nn, f\"Dropout{conv_dim}d\")(dropout_perc)\n            if dropout_perc &gt; 0\n            else None\n        )\n        self.activation = (\n            getattr(nn, f\"{activation}\")() if activation is not None else nn.Identity()\n        )\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        torch.Tensor\n            Output tensor.\n        \"\"\"\n        if self.use_batch_norm:\n            x = self.conv1(x)\n            x = self.batch_norm1(x)\n            x = self.activation(x)\n            x = self.conv2(x)\n            x = self.batch_norm2(x)\n            x = self.activation(x)\n        else:\n            x = self.conv1(x)\n            x = self.activation(x)\n            x = self.conv2(x)\n            x = self.activation(x)\n        if self.dropout is not None:\n            x = self.dropout(x)\n        return x\n</code></pre>"},{"location":"reference/careamics/models/layers/#careamics.models.layers.Conv_Block.__init__","title":"<code>__init__(conv_dim, in_channels, out_channels, intermediate_channel_multiplier=1, stride=1, padding=1, bias=True, groups=1, activation='ReLU', dropout_perc=0, use_batch_norm=False)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolutions, 2 or 3.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>intermediate_channel_multiplier</code> <code>int</code> <p>Multiplied for the number of output channels, by default 1.</p> <code>1</code> <code>stride</code> <code>int</code> <p>Stride of the convolutions, by default 1.</p> <code>1</code> <code>padding</code> <code>int</code> <p>Padding of the convolutions, by default 1.</p> <code>1</code> <code>bias</code> <code>bool</code> <p>Bias of the convolutions, by default True.</p> <code>True</code> <code>groups</code> <code>int</code> <p>Controls the connections between inputs and outputs, by default 1.</p> <code>1</code> <code>activation</code> <code>str</code> <p>Activation function, by default \"ReLU\".</p> <code>'ReLU'</code> <code>dropout_perc</code> <code>float</code> <p>Dropout percentage, by default 0.</p> <code>0</code> <code>use_batch_norm</code> <code>bool</code> <p>Use batch norm, by default False.</p> <code>False</code> Source code in <code>src/careamics/models/layers.py</code> <pre><code>def __init__(\n    self,\n    conv_dim: int,\n    in_channels: int,\n    out_channels: int,\n    intermediate_channel_multiplier: int = 1,\n    stride: int = 1,\n    padding: int = 1,\n    bias: bool = True,\n    groups: int = 1,\n    activation: str = \"ReLU\",\n    dropout_perc: float = 0,\n    use_batch_norm: bool = False,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolutions, 2 or 3.\n    in_channels : int\n        Number of input channels.\n    out_channels : int\n        Number of output channels.\n    intermediate_channel_multiplier : int, optional\n        Multiplied for the number of output channels, by default 1.\n    stride : int, optional\n        Stride of the convolutions, by default 1.\n    padding : int, optional\n        Padding of the convolutions, by default 1.\n    bias : bool, optional\n        Bias of the convolutions, by default True.\n    groups : int, optional\n        Controls the connections between inputs and outputs, by default 1.\n    activation : str, optional\n        Activation function, by default \"ReLU\".\n    dropout_perc : float, optional\n        Dropout percentage, by default 0.\n    use_batch_norm : bool, optional\n        Use batch norm, by default False.\n    \"\"\"\n    super().__init__()\n    self.use_batch_norm = use_batch_norm\n    self.conv1 = getattr(nn, f\"Conv{conv_dim}d\")(\n        in_channels,\n        out_channels * intermediate_channel_multiplier,\n        kernel_size=3,\n        stride=stride,\n        padding=padding,\n        bias=bias,\n        groups=groups,\n    )\n\n    self.conv2 = getattr(nn, f\"Conv{conv_dim}d\")(\n        out_channels * intermediate_channel_multiplier,\n        out_channels,\n        kernel_size=3,\n        stride=stride,\n        padding=padding,\n        bias=bias,\n        groups=groups,\n    )\n\n    self.batch_norm1 = getattr(nn, f\"BatchNorm{conv_dim}d\")(\n        out_channels * intermediate_channel_multiplier\n    )\n    self.batch_norm2 = getattr(nn, f\"BatchNorm{conv_dim}d\")(out_channels)\n\n    self.dropout = (\n        getattr(nn, f\"Dropout{conv_dim}d\")(dropout_perc)\n        if dropout_perc &gt; 0\n        else None\n    )\n    self.activation = (\n        getattr(nn, f\"{activation}\")() if activation is not None else nn.Identity()\n    )\n</code></pre>"},{"location":"reference/careamics/models/layers/#careamics.models.layers.Conv_Block.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output tensor.</p> Source code in <code>src/careamics/models/layers.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor.\n\n    Returns\n    -------\n    torch.Tensor\n        Output tensor.\n    \"\"\"\n    if self.use_batch_norm:\n        x = self.conv1(x)\n        x = self.batch_norm1(x)\n        x = self.activation(x)\n        x = self.conv2(x)\n        x = self.batch_norm2(x)\n        x = self.activation(x)\n    else:\n        x = self.conv1(x)\n        x = self.activation(x)\n        x = self.conv2(x)\n        x = self.activation(x)\n    if self.dropout is not None:\n        x = self.dropout(x)\n    return x\n</code></pre>"},{"location":"reference/careamics/models/model_factory/","title":"model_factory","text":"<p>Model factory.</p> <p>Model creation factory functions.</p>"},{"location":"reference/careamics/models/model_factory/#careamics.models.model_factory.create_model","title":"<code>create_model(*, model_path=None, config=None, device=None)</code>","text":"<p>Instantiate a model from a model path or configuration.</p> <p>If both path and configuration are provided, the model path is used. The model path should point to either a checkpoint (created during training) or a model exported to the bioimage.io format.</p> <p>Parameters:</p> Name Type Description Default <code>model_path</code> <code>Optional[Union[str, Path]]</code> <p>Path to a checkpoint or bioimage.io archive, by default None.</p> <code>None</code> <code>config</code> <code>Optional[Configuration]</code> <p>Configuration, by default None.</p> <code>None</code> <code>device</code> <code>Optional[device]</code> <p>Torch device, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Module</code> <p>Instantiated model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the checkpoint path is invalid.</p> <code>ValueError</code> <p>If the checkpoint is invalid.</p> <code>ValueError</code> <p>If neither checkpoint nor configuration are provided.</p> Source code in <code>src/careamics/models/model_factory.py</code> <pre><code>def create_model(\n    *,\n    model_path: Optional[Union[str, Path]] = None,\n    config: Optional[Configuration] = None,\n    device: Optional[torch.device] = None,\n) -&gt; Tuple[\n    torch.nn.Module,\n    torch.optim.Optimizer,\n    Union[\n        torch.optim.lr_scheduler.LRScheduler,\n        torch.optim.lr_scheduler.ReduceLROnPlateau,  # not a subclass of LRScheduler\n    ],\n    torch.cuda.amp.GradScaler,\n    Configuration,\n]:\n    \"\"\"\n    Instantiate a model from a model path or configuration.\n\n    If both path and configuration are provided, the model path is used. The model\n    path should point to either a checkpoint (created during training) or a model\n    exported to the bioimage.io format.\n\n    Parameters\n    ----------\n    model_path : Optional[Union[str, Path]], optional\n        Path to a checkpoint or bioimage.io archive, by default None.\n    config : Optional[Configuration], optional\n        Configuration, by default None.\n    device : Optional[torch.device], optional\n        Torch device, by default None.\n\n    Returns\n    -------\n    torch.nn.Module\n        Instantiated model.\n\n    Raises\n    ------\n    ValueError\n        If the checkpoint path is invalid.\n    ValueError\n        If the checkpoint is invalid.\n    ValueError\n        If neither checkpoint nor configuration are provided.\n    \"\"\"\n    if model_path is not None:\n        # Create model from checkpoint\n        model_path = Path(model_path)\n        if not model_path.exists() or model_path.suffix not in [\".pth\", \".zip\"]:\n            raise ValueError(\n                f\"Invalid model path: {model_path}. Current working dir: \\\n                              {Path.cwd()!s}\"\n            )\n\n        if model_path.suffix == \".zip\":\n            model_path = import_bioimage_model(model_path)\n\n        # Load checkpoint\n        checkpoint = torch.load(model_path, map_location=device)\n\n        # Load the configuration\n        if \"config\" in checkpoint:\n            config = Configuration(**checkpoint[\"config\"])\n            algo_config = config.algorithm\n            model_config = algo_config.model_parameters\n            model_name = algo_config.model\n        else:\n            raise ValueError(\"Invalid checkpoint format, no configuration found.\")\n\n        # Create model\n        model: torch.nn.Module = model_registry(model_name)(\n            depth=model_config.depth,\n            conv_dim=algo_config.get_conv_dim(),\n            num_channels_init=model_config.num_channels_init,\n        )\n        model.to(device)\n\n        # Load the model state dict\n        if \"model_state_dict\" in checkpoint:\n            model.load_state_dict(checkpoint[\"model_state_dict\"])\n            logger.info(\"Loaded model state dict\")\n        else:\n            raise ValueError(\"Invalid checkpoint format\")\n\n        # Load the optimizer and scheduler\n        optimizer, scheduler = get_optimizer_and_scheduler(\n            config, model, state_dict=checkpoint\n        )\n        scaler = get_grad_scaler(config, state_dict=checkpoint)\n\n    elif config is not None:\n        # Create model from configuration\n        algo_config = config.algorithm\n        model_config = algo_config.model_parameters\n        model_name = algo_config.model\n\n        # Create model\n        model = model_registry(model_name)(\n            depth=model_config.depth,\n            conv_dim=algo_config.get_conv_dim(),\n            num_channels_init=model_config.num_channels_init,\n        )\n        model.to(device)\n        optimizer, scheduler = get_optimizer_and_scheduler(config, model)\n        scaler = get_grad_scaler(config)\n        logger.info(\"Engine initialized from configuration\")\n\n    else:\n        raise ValueError(\"Either config or model_path must be provided\")\n\n    return model, optimizer, scheduler, scaler, config\n</code></pre>"},{"location":"reference/careamics/models/model_factory/#careamics.models.model_factory.get_grad_scaler","title":"<code>get_grad_scaler(config, state_dict=None)</code>","text":"<p>Instantiate gradscaler.</p> <p>If a checkpoint state dictionary is provided, the scaler is instantiated to the same state as the checkpoint's scaler.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>Configuration.</p> required <code>state_dict</code> <code>Optional[Dict]</code> <p>Checkpoint state dictionary, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>GradScaler</code> <p>Instantiated gradscaler.</p> Source code in <code>src/careamics/models/model_factory.py</code> <pre><code>def get_grad_scaler(\n    config: Configuration, state_dict: Optional[Dict] = None\n) -&gt; torch.cuda.amp.GradScaler:\n    \"\"\"\n    Instantiate gradscaler.\n\n    If a checkpoint state dictionary is provided, the scaler is instantiated to the\n    same state as the checkpoint's scaler.\n\n    Parameters\n    ----------\n    config : Configuration\n        Configuration.\n    state_dict : Optional[Dict], optional\n        Checkpoint state dictionary, by default None.\n\n    Returns\n    -------\n    torch.cuda.amp.GradScaler\n        Instantiated gradscaler.\n    \"\"\"\n    use = config.training.amp.use\n    scaling = config.training.amp.init_scale\n    scaler = torch.cuda.amp.GradScaler(init_scale=scaling, enabled=use)\n    if state_dict is not None and \"scaler_state_dict\" in state_dict:\n        scaler.load_state_dict(state_dict[\"scaler_state_dict\"])\n        logger.info(\"Loaded GradScaler state dict\")\n    return scaler\n</code></pre>"},{"location":"reference/careamics/models/model_factory/#careamics.models.model_factory.get_optimizer_and_scheduler","title":"<code>get_optimizer_and_scheduler(config, model, state_dict=None)</code>","text":"<p>Create optimizer and learning rate schedulers.</p> <p>If a checkpoint state dictionary is provided, the optimizer and scheduler are instantiated to the same state as the checkpoint's optimizer and scheduler.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>Configuration.</p> required <code>model</code> <code>Module</code> <p>Model.</p> required <code>state_dict</code> <code>Optional[Dict]</code> <p>Checkpoint state dictionary, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Optimizer, LRScheduler]</code> <p>Optimizer and scheduler.</p> Source code in <code>src/careamics/models/model_factory.py</code> <pre><code>def get_optimizer_and_scheduler(\n    config: Configuration, model: torch.nn.Module, state_dict: Optional[Dict] = None\n) -&gt; Tuple[\n    torch.optim.Optimizer,\n    Union[\n        torch.optim.lr_scheduler.LRScheduler,\n        torch.optim.lr_scheduler.ReduceLROnPlateau,  # not a subclass of LRScheduler\n    ],\n]:\n    \"\"\"\n    Create optimizer and learning rate schedulers.\n\n    If a checkpoint state dictionary is provided, the optimizer and scheduler are\n    instantiated to the same state as the checkpoint's optimizer and scheduler.\n\n    Parameters\n    ----------\n    config : Configuration\n        Configuration.\n    model : torch.nn.Module\n        Model.\n    state_dict : Optional[Dict], optional\n        Checkpoint state dictionary, by default None.\n\n    Returns\n    -------\n    Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LRScheduler]\n        Optimizer and scheduler.\n    \"\"\"\n    # retrieve optimizer name and parameters from config\n    optimizer_name = config.training.optimizer.name\n    optimizer_params = config.training.optimizer.parameters\n\n    # then instantiate it\n    optimizer_func = getattr(torch.optim, optimizer_name)\n    optimizer = optimizer_func(model.parameters(), **optimizer_params)\n\n    # same for learning rate scheduler\n    scheduler_name = config.training.lr_scheduler.name\n    scheduler_params = config.training.lr_scheduler.parameters\n    scheduler_func = getattr(torch.optim.lr_scheduler, scheduler_name)\n    scheduler = scheduler_func(optimizer, **scheduler_params)\n\n    # load state from ther checkpoint if available\n    if state_dict is not None:\n        if \"optimizer_state_dict\" in state_dict:\n            optimizer.load_state_dict(state_dict[\"optimizer_state_dict\"])\n            logger.info(\"Loaded optimizer state dict\")\n        else:\n            logger.warning(\n                \"No optimizer state dict found in checkpoint. Optimizer not loaded.\"\n            )\n        if \"scheduler_state_dict\" in state_dict:\n            scheduler.load_state_dict(state_dict[\"scheduler_state_dict\"])\n            logger.info(\"Loaded LR scheduler state dict\")\n        else:\n            logger.warning(\n                \"No LR scheduler state dict found in checkpoint. \"\n                \"LR scheduler not loaded.\"\n            )\n    return optimizer, scheduler\n</code></pre>"},{"location":"reference/careamics/models/model_factory/#careamics.models.model_factory.model_registry","title":"<code>model_registry(model_name)</code>","text":"<p>Model factory.</p> <p>Supported models are defined in config.algorithm.Models.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Name of the model.</p> required <p>Returns:</p> Type Description <code>Module</code> <p>Model class.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the requested model is not implemented.</p> Source code in <code>src/careamics/models/model_factory.py</code> <pre><code>def model_registry(model_name: str) -&gt; torch.nn.Module:\n    \"\"\"\n    Model factory.\n\n    Supported models are defined in config.algorithm.Models.\n\n    Parameters\n    ----------\n    model_name : str\n        Name of the model.\n\n    Returns\n    -------\n    torch.nn.Module\n        Model class.\n\n    Raises\n    ------\n    NotImplementedError\n        If the requested model is not implemented.\n    \"\"\"\n    if model_name == Models.UNET:\n        return UNet\n    else:\n        raise NotImplementedError(f\"Model {model_name} is not implemented\")\n</code></pre>"},{"location":"reference/careamics/models/unet/","title":"unet","text":"<p>UNet model.</p> <p>A UNet encoder, decoder and complete model.</p>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UNet","title":"<code>UNet</code>","text":"<p>             Bases: <code>Module</code></p> <p>UNet model.</p> <p>Adapted for PyTorch from https://github.com/juglab/n2v/blob/main/n2v/nets/unet_blocks.py.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimensions of the convolution layers (2 or 3).</p> required <code>num_classes</code> <code>int</code> <p>Number of classes to predict, by default 1.</p> <code>1</code> <code>in_channels</code> <code>int</code> <p>Number of input channels, by default 1.</p> <code>1</code> <code>depth</code> <code>int</code> <p>Number of downsamplings, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of filters in the first convolution layer, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> <code>pool_kernel</code> <code>int</code> <p>Kernel size of the pooling layers, by default 2.</p> <code>2</code> <code>last_activation</code> <code>Optional[Callable]</code> <p>Activation function to use for the last layer, by default None.</p> <code>None</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>class UNet(nn.Module):\n    \"\"\"\n    UNet model.\n\n    Adapted for PyTorch from\n    https://github.com/juglab/n2v/blob/main/n2v/nets/unet_blocks.py.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimensions of the convolution layers (2 or 3).\n    num_classes : int, optional\n        Number of classes to predict, by default 1.\n    in_channels : int, optional\n        Number of input channels, by default 1.\n    depth : int, optional\n        Number of downsamplings, by default 3.\n    num_channels_init : int, optional\n        Number of filters in the first convolution layer, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    pool_kernel : int, optional\n        Kernel size of the pooling layers, by default 2.\n    last_activation : Optional[Callable], optional\n        Activation function to use for the last layer, by default None.\n    \"\"\"\n\n    def __init__(\n        self,\n        conv_dim: int,\n        num_classes: int = 1,\n        in_channels: int = 1,\n        depth: int = 3,\n        num_channels_init: int = 64,\n        use_batch_norm: bool = True,\n        dropout: float = 0.0,\n        pool_kernel: int = 2,\n        last_activation: Optional[Callable] = None,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        conv_dim : int\n            Number of dimensions of the convolution layers (2 or 3).\n        num_classes : int, optional\n            Number of classes to predict, by default 1.\n        in_channels : int, optional\n            Number of input channels, by default 1.\n        depth : int, optional\n            Number of downsamplings, by default 3.\n        num_channels_init : int, optional\n            Number of filters in the first convolution layer, by default 64.\n        use_batch_norm : bool, optional\n            Whether to use batch normalization, by default True.\n        dropout : float, optional\n            Dropout probability, by default 0.0.\n        pool_kernel : int, optional\n            Kernel size of the pooling layers, by default 2.\n        last_activation : Optional[Callable], optional\n            Activation function to use for the last layer, by default None.\n        \"\"\"\n        super().__init__()\n\n        self.encoder = UnetEncoder(\n            conv_dim,\n            in_channels=in_channels,\n            depth=depth,\n            num_channels_init=num_channels_init,\n            use_batch_norm=use_batch_norm,\n            dropout=dropout,\n            pool_kernel=pool_kernel,\n        )\n\n        self.decoder = UnetDecoder(\n            conv_dim,\n            depth=depth,\n            num_channels_init=num_channels_init,\n            use_batch_norm=use_batch_norm,\n            dropout=dropout,\n        )\n        self.final_conv = getattr(nn, f\"Conv{conv_dim}d\")(\n            in_channels=num_channels_init,\n            out_channels=num_classes,\n            kernel_size=1,\n        )\n        self.last_activation = last_activation if last_activation else nn.Identity()\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        x :  torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        torch.Tensor\n            Output of the model.\n        \"\"\"\n        encoder_features = self.encoder(x)\n        x = self.decoder(*encoder_features)\n        x = self.final_conv(x)\n        x = self.last_activation(x)\n        return x\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UNet.__init__","title":"<code>__init__(conv_dim, num_classes=1, in_channels=1, depth=3, num_channels_init=64, use_batch_norm=True, dropout=0.0, pool_kernel=2, last_activation=None)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimensions of the convolution layers (2 or 3).</p> required <code>num_classes</code> <code>int</code> <p>Number of classes to predict, by default 1.</p> <code>1</code> <code>in_channels</code> <code>int</code> <p>Number of input channels, by default 1.</p> <code>1</code> <code>depth</code> <code>int</code> <p>Number of downsamplings, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of filters in the first convolution layer, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> <code>pool_kernel</code> <code>int</code> <p>Kernel size of the pooling layers, by default 2.</p> <code>2</code> <code>last_activation</code> <code>Optional[Callable]</code> <p>Activation function to use for the last layer, by default None.</p> <code>None</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def __init__(\n    self,\n    conv_dim: int,\n    num_classes: int = 1,\n    in_channels: int = 1,\n    depth: int = 3,\n    num_channels_init: int = 64,\n    use_batch_norm: bool = True,\n    dropout: float = 0.0,\n    pool_kernel: int = 2,\n    last_activation: Optional[Callable] = None,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimensions of the convolution layers (2 or 3).\n    num_classes : int, optional\n        Number of classes to predict, by default 1.\n    in_channels : int, optional\n        Number of input channels, by default 1.\n    depth : int, optional\n        Number of downsamplings, by default 3.\n    num_channels_init : int, optional\n        Number of filters in the first convolution layer, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    pool_kernel : int, optional\n        Kernel size of the pooling layers, by default 2.\n    last_activation : Optional[Callable], optional\n        Activation function to use for the last layer, by default None.\n    \"\"\"\n    super().__init__()\n\n    self.encoder = UnetEncoder(\n        conv_dim,\n        in_channels=in_channels,\n        depth=depth,\n        num_channels_init=num_channels_init,\n        use_batch_norm=use_batch_norm,\n        dropout=dropout,\n        pool_kernel=pool_kernel,\n    )\n\n    self.decoder = UnetDecoder(\n        conv_dim,\n        depth=depth,\n        num_channels_init=num_channels_init,\n        use_batch_norm=use_batch_norm,\n        dropout=dropout,\n    )\n    self.final_conv = getattr(nn, f\"Conv{conv_dim}d\")(\n        in_channels=num_channels_init,\n        out_channels=num_classes,\n        kernel_size=1,\n    )\n    self.last_activation = last_activation if last_activation else nn.Identity()\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UNet.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code> torch.Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output of the model.</p> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass.\n\n    Parameters\n    ----------\n    x :  torch.Tensor\n        Input tensor.\n\n    Returns\n    -------\n    torch.Tensor\n        Output of the model.\n    \"\"\"\n    encoder_features = self.encoder(x)\n    x = self.decoder(*encoder_features)\n    x = self.final_conv(x)\n    x = self.last_activation(x)\n    return x\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetDecoder","title":"<code>UnetDecoder</code>","text":"<p>             Bases: <code>Module</code></p> <p>Unet decoder pathway.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.</p> required <code>depth</code> <code>int</code> <p>Number of decoder blocks, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of channels in the first encoder block, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>class UnetDecoder(nn.Module):\n    \"\"\"\n    Unet decoder pathway.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n    depth : int, optional\n        Number of decoder blocks, by default 3.\n    num_channels_init : int, optional\n        Number of channels in the first encoder block, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    \"\"\"\n\n    def __init__(\n        self,\n        conv_dim: int,\n        depth: int = 3,\n        num_channels_init: int = 64,\n        use_batch_norm: bool = True,\n        dropout: float = 0.0,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        conv_dim : int\n            Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n        depth : int, optional\n            Number of decoder blocks, by default 3.\n        num_channels_init : int, optional\n            Number of channels in the first encoder block, by default 64.\n        use_batch_norm : bool, optional\n            Whether to use batch normalization, by default True.\n        dropout : float, optional\n            Dropout probability, by default 0.0.\n        \"\"\"\n        super().__init__()\n\n        upsampling = nn.Upsample(\n            scale_factor=2, mode=\"bilinear\" if conv_dim == 2 else \"trilinear\"\n        )\n        in_channels = out_channels = num_channels_init * 2 ** (depth - 1)\n        self.bottleneck = Conv_Block(\n            conv_dim,\n            in_channels=in_channels,\n            out_channels=out_channels,\n            intermediate_channel_multiplier=2,\n            use_batch_norm=use_batch_norm,\n            dropout_perc=dropout,\n        )\n\n        decoder_blocks = []\n        for n in range(depth):\n            decoder_blocks.append(upsampling)\n            in_channels = num_channels_init * 2 ** (depth - n)\n            out_channels = num_channels_init\n            decoder_blocks.append(\n                Conv_Block(\n                    conv_dim,\n                    in_channels=in_channels,\n                    out_channels=out_channels,\n                    intermediate_channel_multiplier=2,\n                    dropout_perc=dropout,\n                    activation=\"ReLU\",\n                    use_batch_norm=use_batch_norm,\n                )\n            )\n\n        self.decoder_blocks = nn.ModuleList(decoder_blocks)\n\n    def forward(self, *features: List[torch.Tensor]) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        *features :  List[torch.Tensor]\n            List containing the output of each encoder block(skip connections) and final\n            output of the encoder.\n\n        Returns\n        -------\n        torch.Tensor\n            Output of the decoder.\n        \"\"\"\n        x = features[0]\n        skip_connections = features[1:][::-1]\n        x = self.bottleneck(x)\n        for i, module in enumerate(self.decoder_blocks):\n            x = module(x)\n            if isinstance(module, nn.Upsample):\n                x = torch.cat([x, skip_connections[i // 2]], axis=1)\n        return x\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetDecoder.__init__","title":"<code>__init__(conv_dim, depth=3, num_channels_init=64, use_batch_norm=True, dropout=0.0)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.</p> required <code>depth</code> <code>int</code> <p>Number of decoder blocks, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of channels in the first encoder block, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def __init__(\n    self,\n    conv_dim: int,\n    depth: int = 3,\n    num_channels_init: int = 64,\n    use_batch_norm: bool = True,\n    dropout: float = 0.0,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n    depth : int, optional\n        Number of decoder blocks, by default 3.\n    num_channels_init : int, optional\n        Number of channels in the first encoder block, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    \"\"\"\n    super().__init__()\n\n    upsampling = nn.Upsample(\n        scale_factor=2, mode=\"bilinear\" if conv_dim == 2 else \"trilinear\"\n    )\n    in_channels = out_channels = num_channels_init * 2 ** (depth - 1)\n    self.bottleneck = Conv_Block(\n        conv_dim,\n        in_channels=in_channels,\n        out_channels=out_channels,\n        intermediate_channel_multiplier=2,\n        use_batch_norm=use_batch_norm,\n        dropout_perc=dropout,\n    )\n\n    decoder_blocks = []\n    for n in range(depth):\n        decoder_blocks.append(upsampling)\n        in_channels = num_channels_init * 2 ** (depth - n)\n        out_channels = num_channels_init\n        decoder_blocks.append(\n            Conv_Block(\n                conv_dim,\n                in_channels=in_channels,\n                out_channels=out_channels,\n                intermediate_channel_multiplier=2,\n                dropout_perc=dropout,\n                activation=\"ReLU\",\n                use_batch_norm=use_batch_norm,\n            )\n        )\n\n    self.decoder_blocks = nn.ModuleList(decoder_blocks)\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetDecoder.forward","title":"<code>forward(*features)</code>","text":"<p>Forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>*features</code> <code> List[torch.Tensor]</code> <p>List containing the output of each encoder block(skip connections) and final output of the encoder.</p> <code>()</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Output of the decoder.</p> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def forward(self, *features: List[torch.Tensor]) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass.\n\n    Parameters\n    ----------\n    *features :  List[torch.Tensor]\n        List containing the output of each encoder block(skip connections) and final\n        output of the encoder.\n\n    Returns\n    -------\n    torch.Tensor\n        Output of the decoder.\n    \"\"\"\n    x = features[0]\n    skip_connections = features[1:][::-1]\n    x = self.bottleneck(x)\n    for i, module in enumerate(self.decoder_blocks):\n        x = module(x)\n        if isinstance(module, nn.Upsample):\n            x = torch.cat([x, skip_connections[i // 2]], axis=1)\n    return x\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetEncoder","title":"<code>UnetEncoder</code>","text":"<p>             Bases: <code>Module</code></p> <p>Unet encoder pathway.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels, by default 1.</p> <code>1</code> <code>depth</code> <code>int</code> <p>Number of encoder blocks, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of channels in the first encoder block, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> <code>pool_kernel</code> <code>int</code> <p>Kernel size for the max pooling layers, by default 2.</p> <code>2</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>class UnetEncoder(nn.Module):\n    \"\"\"\n    Unet encoder pathway.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n    in_channels : int, optional\n        Number of input channels, by default 1.\n    depth : int, optional\n        Number of encoder blocks, by default 3.\n    num_channels_init : int, optional\n        Number of channels in the first encoder block, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    pool_kernel : int, optional\n        Kernel size for the max pooling layers, by default 2.\n    \"\"\"\n\n    def __init__(\n        self,\n        conv_dim: int,\n        in_channels: int = 1,\n        depth: int = 3,\n        num_channels_init: int = 64,\n        use_batch_norm: bool = True,\n        dropout: float = 0.0,\n        pool_kernel: int = 2,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        conv_dim : int\n            Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n        in_channels : int, optional\n            Number of input channels, by default 1.\n        depth : int, optional\n            Number of encoder blocks, by default 3.\n        num_channels_init : int, optional\n            Number of channels in the first encoder block, by default 64.\n        use_batch_norm : bool, optional\n            Whether to use batch normalization, by default True.\n        dropout : float, optional\n            Dropout probability, by default 0.0.\n        pool_kernel : int, optional\n            Kernel size for the max pooling layers, by default 2.\n        \"\"\"\n        super().__init__()\n\n        self.pooling = getattr(nn, f\"MaxPool{conv_dim}d\")(kernel_size=pool_kernel)\n\n        encoder_blocks = []\n\n        for n in range(depth):\n            out_channels = num_channels_init * (2**n)\n            in_channels = in_channels if n == 0 else out_channels // 2\n            encoder_blocks.append(\n                Conv_Block(\n                    conv_dim,\n                    in_channels=in_channels,\n                    out_channels=out_channels,\n                    dropout_perc=dropout,\n                    use_batch_norm=use_batch_norm,\n                )\n            )\n            encoder_blocks.append(self.pooling)\n\n        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n\n    def forward(self, x: torch.Tensor) -&gt; List[torch.Tensor]:\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        List[torch.Tensor]\n            Output of each encoder block (skip connections) and final output of the\n            encoder.\n        \"\"\"\n        encoder_features = []\n        for module in self.encoder_blocks:\n            x = module(x)\n            if isinstance(module, Conv_Block):\n                encoder_features.append(x)\n        features = [x, *encoder_features]\n        return features\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetEncoder.__init__","title":"<code>__init__(conv_dim, in_channels=1, depth=3, num_channels_init=64, use_batch_norm=True, dropout=0.0, pool_kernel=2)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels, by default 1.</p> <code>1</code> <code>depth</code> <code>int</code> <p>Number of encoder blocks, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of channels in the first encoder block, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> <code>pool_kernel</code> <code>int</code> <p>Kernel size for the max pooling layers, by default 2.</p> <code>2</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def __init__(\n    self,\n    conv_dim: int,\n    in_channels: int = 1,\n    depth: int = 3,\n    num_channels_init: int = 64,\n    use_batch_norm: bool = True,\n    dropout: float = 0.0,\n    pool_kernel: int = 2,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n    in_channels : int, optional\n        Number of input channels, by default 1.\n    depth : int, optional\n        Number of encoder blocks, by default 3.\n    num_channels_init : int, optional\n        Number of channels in the first encoder block, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    pool_kernel : int, optional\n        Kernel size for the max pooling layers, by default 2.\n    \"\"\"\n    super().__init__()\n\n    self.pooling = getattr(nn, f\"MaxPool{conv_dim}d\")(kernel_size=pool_kernel)\n\n    encoder_blocks = []\n\n    for n in range(depth):\n        out_channels = num_channels_init * (2**n)\n        in_channels = in_channels if n == 0 else out_channels // 2\n        encoder_blocks.append(\n            Conv_Block(\n                conv_dim,\n                in_channels=in_channels,\n                out_channels=out_channels,\n                dropout_perc=dropout,\n                use_batch_norm=use_batch_norm,\n            )\n        )\n        encoder_blocks.append(self.pooling)\n\n    self.encoder_blocks = nn.ModuleList(encoder_blocks)\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetEncoder.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>List[Tensor]</code> <p>Output of each encoder block (skip connections) and final output of the encoder.</p> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; List[torch.Tensor]:\n    \"\"\"\n    Forward pass.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor.\n\n    Returns\n    -------\n    List[torch.Tensor]\n        Output of each encoder block (skip connections) and final output of the\n        encoder.\n    \"\"\"\n    encoder_features = []\n    for module in self.encoder_blocks:\n        x = module(x)\n        if isinstance(module, Conv_Block):\n            encoder_features.append(x)\n    features = [x, *encoder_features]\n    return features\n</code></pre>"},{"location":"reference/careamics/prediction/prediction_utils/","title":"prediction_utils","text":"<p>Prediction convenience functions.</p> <p>These functions are used during prediction.</p>"},{"location":"reference/careamics/prediction/prediction_utils/#careamics.prediction.prediction_utils.stitch_prediction","title":"<code>stitch_prediction(tiles, stitching_data)</code>","text":"<p>Stitch tiles back together to form a full image.</p> <p>Parameters:</p> Name Type Description Default <code>tiles</code> <code>List[Tuple[ndarray, List[int]]]</code> <p>Cropped tiles and their respective stitching coordinates.</p> required <code>stitching_data</code> <code>List</code> <p>List of coordinates obtained from dataset.tiling.compute_crop_and_stitch_coords_1d.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Full image.</p> Source code in <code>src/careamics/prediction/prediction_utils.py</code> <pre><code>def stitch_prediction(\n    tiles: List[np.ndarray],\n    stitching_data: List,\n) -&gt; np.ndarray:\n    \"\"\"\n    Stitch tiles back together to form a full image.\n\n    Parameters\n    ----------\n    tiles : List[Tuple[np.ndarray, List[int]]]\n        Cropped tiles and their respective stitching coordinates.\n    stitching_data : List\n        List of coordinates obtained from\n        dataset.tiling.compute_crop_and_stitch_coords_1d.\n\n    Returns\n    -------\n    np.ndarray\n        Full image.\n    \"\"\"\n    # Get whole sample shape\n    input_shape = stitching_data[0][0]\n    predicted_image = np.zeros(input_shape, dtype=np.float32)\n    for tile, (_, overlap_crop_coords, stitch_coords) in zip(tiles, stitching_data):\n        # Compute coordinates for cropping predicted tile\n        slices = tuple([slice(c[0], c[1]) for c in overlap_crop_coords])\n\n        # Crop predited tile according to overlap coordinates\n        cropped_tile = tile.squeeze()[slices]\n\n        # Insert cropped tile into predicted image using stitch coordinates\n        predicted_image[\n            (..., *[slice(c[0], c[1]) for c in stitch_coords])\n        ] = cropped_tile\n    return predicted_image\n</code></pre>"},{"location":"reference/careamics/prediction/prediction_utils/#careamics.prediction.prediction_utils.tta_backward","title":"<code>tta_backward(x_aug)</code>","text":"<p>Invert <code>tta_forward</code> and average the 8 images.</p> <p>The function takes a list of torch tensors and returns a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>x_aug</code> <code>List[Tensor]</code> <p>Stack of 8-fold augmented images.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Average of de-augmented x_aug.</p> Source code in <code>src/careamics/prediction/prediction_utils.py</code> <pre><code>def tta_backward(x_aug: List[torch.Tensor]) -&gt; np.ndarray:\n    \"\"\"\n    Invert `tta_forward` and average the 8 images.\n\n    The function takes a list of torch tensors and returns a numpy array.\n\n    Parameters\n    ----------\n    x_aug : List[torch.Tensor]\n        Stack of 8-fold augmented images.\n\n    Returns\n    -------\n    np.ndarray\n        Average of de-augmented x_aug.\n    \"\"\"\n    x_deaug = [\n        x_aug[0].numpy(),\n        np.rot90(x_aug[1], -1, axes=(2, 3)),\n        np.rot90(x_aug[2], -2, axes=(2, 3)),\n        np.rot90(x_aug[3], -3, axes=(2, 3)),\n        np.flip(x_aug[4].numpy(), axis=(1, 3)),\n        np.rot90(np.flip(x_aug[5].numpy(), axis=(1, 3)), -1, axes=(2, 3)),\n        np.rot90(np.flip(x_aug[6].numpy(), axis=(1, 3)), -2, axes=(2, 3)),\n        np.rot90(np.flip(x_aug[7].numpy(), axis=(1, 3)), -3, axes=(2, 3)),\n    ]\n    return np.mean(x_deaug, 0)\n</code></pre>"},{"location":"reference/careamics/prediction/prediction_utils/#careamics.prediction.prediction_utils.tta_forward","title":"<code>tta_forward(x)</code>","text":"<p>Augment 8-fold an array.</p> <p>The augmentation is performed using all 90 deg rotations and their flipped version, as well as the original image flipped.</p> <p>Tensors should be of shape SC(Z)YX, with S and C potentially singleton dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Data to augment.</p> required <p>Returns:</p> Type Description <code>List</code> <p>Stack of augmented images.</p> Source code in <code>src/careamics/prediction/prediction_utils.py</code> <pre><code>def tta_forward(x: torch.Tensor) -&gt; List[torch.Tensor]:\n    \"\"\"\n    Augment 8-fold an array.\n\n    The augmentation is performed using all 90 deg rotations and their flipped version,\n    as well as the original image flipped.\n\n    Tensors should be of shape SC(Z)YX, with S and C potentially singleton dimensions.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Data to augment.\n\n    Returns\n    -------\n    List\n        Stack of augmented images.\n    \"\"\"\n    x_aug = [\n        x,\n        torch.rot90(x, 1, dims=(2, 3)),\n        torch.rot90(x, 2, dims=(2, 3)),\n        torch.rot90(x, 3, dims=(2, 3)),\n    ]\n    x_aug_flip = x_aug.copy()\n    for x_ in x_aug:\n        x_aug_flip.append(torch.flip(x_, dims=(1, 3)))\n    return x_aug_flip\n</code></pre>"},{"location":"reference/careamics/utils/augment/","title":"augment","text":"<p>Augmentation module.</p>"},{"location":"reference/careamics/utils/augment/#careamics.utils.augment.augment_batch","title":"<code>augment_batch(patch, original_image, mask, seed=42)</code>","text":"<p>Apply augmentation function to patches and masks.</p> <p>Parameters:</p> Name Type Description Default <code>patch</code> <code>ndarray</code> <p>Array containing single image or patch, 2D or 3D with masked pixels.</p> required <code>original_image</code> <code>ndarray</code> <p>Array containing original image or patch, 2D or 3D.</p> required <code>mask</code> <code>ndarray</code> <p>Array containing only masked pixels, 2D or 3D.</p> required <code>seed</code> <code>int</code> <p>Seed for random number generator, controls the rotation and falipping.</p> <code>42</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ...]</code> <p>Tuple of augmented arrays.</p> Source code in <code>src/careamics/utils/augment.py</code> <pre><code>def augment_batch(\n    patch: np.ndarray,\n    original_image: np.ndarray,\n    mask: np.ndarray,\n    seed: int = 42,\n) -&gt; Tuple[np.ndarray, ...]:\n    \"\"\"\n    Apply augmentation function to patches and masks.\n\n    Parameters\n    ----------\n    patch : np.ndarray\n        Array containing single image or patch, 2D or 3D with masked pixels.\n    original_image : np.ndarray\n        Array containing original image or patch, 2D or 3D.\n    mask : np.ndarray\n        Array containing only masked pixels, 2D or 3D.\n    seed : int, optional\n        Seed for random number generator, controls the rotation and falipping.\n\n    Returns\n    -------\n    Tuple[np.ndarray, ...]\n        Tuple of augmented arrays.\n    \"\"\"\n    rng = np.random.default_rng(seed=seed)\n    rotate_state = rng.integers(0, 4)\n    flip_state = rng.integers(0, 2)\n    return (\n        _flip_and_rotate(patch, rotate_state, flip_state),\n        _flip_and_rotate(original_image, rotate_state, flip_state),\n        _flip_and_rotate(mask, rotate_state, flip_state),\n    )\n</code></pre>"},{"location":"reference/careamics/utils/context/","title":"context","text":"<p>Context submodule.</p> <p>A convenience function to change the working directory in order to save data.</p>"},{"location":"reference/careamics/utils/context/#careamics.utils.context.cwd","title":"<code>cwd(path)</code>","text":"<p>Change the current working directory to the given path.</p> <p>This method can be used to generate files in a specific directory, once out of the context, the working directory is set back to the original one.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>New working directory path.</p> required <p>Returns:</p> Type Description <code>Iterator[None]</code> <p>None values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; with cwd(path):\n...     pass\n</code></pre> Source code in <code>src/careamics/utils/context.py</code> <pre><code>@contextmanager\ndef cwd(path: Union[str, Path]) -&gt; Iterator[None]:\n    \"\"\"\n    Change the current working directory to the given path.\n\n    This method can be used to generate files in a specific directory, once out of the\n    context, the working directory is set back to the original one.\n\n    Parameters\n    ----------\n    path : Union[str,Path]\n        New working directory path.\n\n    Returns\n    -------\n    Iterator[None]\n        None values.\n\n    Examples\n    --------\n    &gt;&gt;&gt; with cwd(path):\n    ...     pass\n    \"\"\"\n    path = Path(path)\n\n    if not path.exists():\n        path.mkdir(parents=True, exist_ok=True)\n\n    old_pwd = Path(\".\").absolute()\n    os.chdir(path)\n    try:\n        yield\n    finally:\n        os.chdir(old_pwd)\n</code></pre>"},{"location":"reference/careamics/utils/logging/","title":"logging","text":"<p>Logging submodule.</p> <p>The methods are responsible for the in-console logger.</p>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.ProgressBar","title":"<code>ProgressBar</code>","text":"<p>Keras style progress bar.</p> <p>Adapted from https://github.com/yueyericardo/pkbar.</p> <p>Parameters:</p> Name Type Description Default <code>max_value</code> <code>Optional[int]</code> <p>Maximum progress bar value, by default None.</p> <code>None</code> <code>epoch</code> <code>Optional[int]</code> <p>Zero-indexed current epoch, by default None.</p> <code>None</code> <code>num_epochs</code> <code>Optional[int]</code> <p>Total number of epochs, by default None.</p> <code>None</code> <code>stateful_metrics</code> <code>Optional[List]</code> <p>Iterable of string names of metrics that should not be averaged over time. Metrics in this list will be displayed as-is. All others will be averaged by the progress bar before display, by default None.</p> <code>None</code> <code>always_stateful</code> <code>bool</code> <pre><code>Whether to set all metrics to be stateful, by default False.\n</code></pre> <code>False</code> <code>mode</code> <code>str</code> <p>Mode, one of \"train\", \"val\", or \"predict\", by default \"train\".</p> <code>'train'</code> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>class ProgressBar:\n    \"\"\"\n    Keras style progress bar.\n\n    Adapted from https://github.com/yueyericardo/pkbar.\n\n    Parameters\n    ----------\n    max_value : Optional[int], optional\n        Maximum progress bar value, by default None.\n    epoch : Optional[int], optional\n        Zero-indexed current epoch, by default None.\n    num_epochs : Optional[int], optional\n        Total number of epochs, by default None.\n    stateful_metrics : Optional[List], optional\n        Iterable of string names of metrics that should *not* be averaged over time.\n        Metrics in this list will be displayed as-is. All others will be averaged by\n        the progress bar before display, by default None.\n    always_stateful : bool, optional\n            Whether to set all metrics to be stateful, by default False.\n    mode : str, optional\n        Mode, one of \"train\", \"val\", or \"predict\", by default \"train\".\n    \"\"\"\n\n    def __init__(\n        self,\n        max_value: Optional[int] = None,\n        epoch: Optional[int] = None,\n        num_epochs: Optional[int] = None,\n        stateful_metrics: Optional[List] = None,\n        always_stateful: bool = False,\n        mode: str = \"train\",\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        max_value : Optional[int], optional\n            Maximum progress bar value, by default None.\n        epoch : Optional[int], optional\n            Zero-indexed current epoch, by default None.\n        num_epochs : Optional[int], optional\n            Total number of epochs, by default None.\n        stateful_metrics : Optional[List], optional\n            Iterable of string names of metrics that should *not* be averaged over time.\n            Metrics in this list will be displayed as-is. All others will be averaged by\n            the progress bar before display, by default None.\n        always_stateful : bool, optional\n             Whether to set all metrics to be stateful, by default False.\n        mode : str, optional\n            Mode, one of \"train\", \"val\", or \"predict\", by default \"train\".\n        \"\"\"\n        self.max_value = max_value\n        # Width of the progress bar\n        self.width = 30\n        self.always_stateful = always_stateful\n\n        if (epoch is not None) and (num_epochs is not None):\n            print(f\"Epoch: {epoch + 1}/{num_epochs}\")\n\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()\n\n        self._dynamic_display = (\n            (hasattr(sys.stdout, \"isatty\") and sys.stdout.isatty())\n            or \"ipykernel\" in sys.modules\n            or \"posix\" in sys.modules\n        )\n        self._total_width = 0\n        self._seen_so_far = 0\n        # We use a dict + list to avoid garbage collection\n        # issues found in OrderedDict\n        self._values: Dict[Any, Any] = {}\n        self._values_order: List[Any] = []\n        self._start = time.time()\n        self._last_update = 0.0\n        self.spin = self.spinning_cursor() if self.max_value is None else None\n        if mode == \"train\" and self.max_value is None:\n            self.message = \"Estimating dataset size\"\n        elif mode == \"val\":\n            self.message = \"Validating\"\n        elif mode == \"predict\":\n            self.message = \"Denoising\"\n\n    def update(\n        self, current_step: int, batch_size: int = 1, values: Optional[List] = None\n    ) -&gt; None:\n        \"\"\"\n        Update the progress bar.\n\n        Parameters\n        ----------\n        current_step : int\n            Index of the current step.\n        batch_size : int, optional\n            Batch size, by default 1.\n        values : Optional[List], optional\n            Updated metrics values, by default None.\n        \"\"\"\n        values = values or []\n        for k, v in values:\n            # if torch tensor, convert it to numpy\n            if str(type(v)) == \"&lt;class 'torch.Tensor'&gt;\":\n                v = v.detach().cpu().numpy()\n\n            if k not in self._values_order:\n                self._values_order.append(k)\n            if k not in self.stateful_metrics and not self.always_stateful:\n                if k not in self._values:\n                    self._values[k] = [\n                        v * (current_step - self._seen_so_far),\n                        current_step - self._seen_so_far,\n                    ]\n                else:\n                    self._values[k][0] += v * (current_step - self._seen_so_far)\n                    self._values[k][1] += current_step - self._seen_so_far\n            else:\n                # Stateful metrics output a numeric value. This representation\n                # means \"take an average from a single value\" but keeps the\n                # numeric formatting.\n                self._values[k] = [v, 1]\n\n        self._seen_so_far = current_step\n\n        now = time.time()\n        info = f\" - {(now - self._start):.0f}s\"\n\n        prev_total_width = self._total_width\n        if self._dynamic_display:\n            sys.stdout.write(\"\\b\" * prev_total_width)\n            sys.stdout.write(\"\\r\")\n        else:\n            sys.stdout.write(\"\\n\")\n\n        if self.max_value is not None:\n            bar = f\"{current_step}/{self.max_value} [\"\n            progress = float(current_step) / self.max_value\n            progress_width = int(self.width * progress)\n            if progress_width &gt; 0:\n                bar += \"=\" * (progress_width - 1)\n                if current_step &lt; self.max_value:\n                    bar += \"&gt;\"\n                else:\n                    bar += \"=\"\n            bar += \".\" * (self.width - progress_width)\n            bar += \"]\"\n        else:\n            bar = (\n                f\"{self.message} {next(self.spin)}, tile \"  # type: ignore\n                f\"No. {current_step * batch_size}\"\n            )\n\n        self._total_width = len(bar)\n        sys.stdout.write(bar)\n\n        if current_step &gt; 0:\n            time_per_unit = (now - self._start) / current_step\n        else:\n            time_per_unit = 0\n\n        if time_per_unit &gt;= 1 or time_per_unit == 0:\n            info += f\" {time_per_unit:.0f}s/step\"\n        elif time_per_unit &gt;= 1e-3:\n            info += f\" {time_per_unit * 1e3:.0f}ms/step\"\n        else:\n            info += f\" {time_per_unit * 1e6:.0f}us/step\"\n\n        for k in self._values_order:\n            info += f\" - {k}:\"\n            if isinstance(self._values[k], list):\n                avg = self._values[k][0] / max(1, self._values[k][1])\n                if abs(avg) &gt; 1e-3:\n                    info += f\" {avg:.4f}\"\n                else:\n                    info += f\" {avg:.4e}\"\n            else:\n                info += f\" {self._values[k]}s\"\n\n        self._total_width += len(info)\n        if prev_total_width &gt; self._total_width:\n            info += \" \" * (prev_total_width - self._total_width)\n\n        if self.max_value is not None and current_step &gt;= self.max_value:\n            info += \"\\n\"\n\n        sys.stdout.write(info)\n        sys.stdout.flush()\n\n        self._last_update = now\n\n    def add(self, n: int, values: Optional[List] = None) -&gt; None:\n        \"\"\"\n        Update the progress bar by n steps.\n\n        Parameters\n        ----------\n        n : int\n            Number of steps to increase the progress bar with.\n        values : Optional[List], optional\n            Updated metrics values, by default None.\n        \"\"\"\n        self.update(self._seen_so_far + n, 1, values=values)\n\n    def spinning_cursor(self) -&gt; Generator:\n        \"\"\"\n        Generate a spinning cursor animation.\n\n        Taken from https://github.com/manrajgrover/py-spinners/tree/master.\n\n        Returns\n        -------\n        Generator\n            Generator of animation frames.\n        \"\"\"\n        while True:\n            yield from [\n                \"\u2593 ----- \u2592\",\n                \"\u2593 ----- \u2592\",\n                \"\u2593 ----- \u2592\",\n                \"\u2593 -&gt;--- \u2592\",\n                \"\u2593 -&gt;--- \u2592\",\n                \"\u2593 -&gt;--- \u2592\",\n                \"\u2593 --&gt;-- \u2592\",\n                \"\u2593 --&gt;-- \u2592\",\n                \"\u2593 --&gt;-- \u2592\",\n                \"\u2593 ---&gt;- \u2592\",\n                \"\u2593 ---&gt;- \u2592\",\n                \"\u2593 ---&gt;- \u2592\",\n                \"\u2593 ----&gt; \u2592\",\n                \"\u2593 ----&gt; \u2592\",\n                \"\u2593 ----&gt; \u2592\",\n                \"\u2592 ----- \u2591\",\n                \"\u2592 ----- \u2591\",\n                \"\u2592 ----- \u2591\",\n                \"\u2592 -&gt;--- \u2591\",\n                \"\u2592 -&gt;--- \u2591\",\n                \"\u2592 -&gt;--- \u2591\",\n                \"\u2592 --&gt;-- \u2591\",\n                \"\u2592 --&gt;-- \u2591\",\n                \"\u2592 --&gt;-- \u2591\",\n                \"\u2592 ---&gt;- \u2591\",\n                \"\u2592 ---&gt;- \u2591\",\n                \"\u2592 ---&gt;- \u2591\",\n                \"\u2592 ----&gt; \u2591\",\n                \"\u2592 ----&gt; \u2591\",\n                \"\u2592 ----&gt; \u2591\",\n            ]\n</code></pre>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.ProgressBar.__init__","title":"<code>__init__(max_value=None, epoch=None, num_epochs=None, stateful_metrics=None, always_stateful=False, mode='train')</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>max_value</code> <code>Optional[int]</code> <p>Maximum progress bar value, by default None.</p> <code>None</code> <code>epoch</code> <code>Optional[int]</code> <p>Zero-indexed current epoch, by default None.</p> <code>None</code> <code>num_epochs</code> <code>Optional[int]</code> <p>Total number of epochs, by default None.</p> <code>None</code> <code>stateful_metrics</code> <code>Optional[List]</code> <p>Iterable of string names of metrics that should not be averaged over time. Metrics in this list will be displayed as-is. All others will be averaged by the progress bar before display, by default None.</p> <code>None</code> <code>always_stateful</code> <code>bool</code> <p>Whether to set all metrics to be stateful, by default False.</p> <code>False</code> <code>mode</code> <code>str</code> <p>Mode, one of \"train\", \"val\", or \"predict\", by default \"train\".</p> <code>'train'</code> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>def __init__(\n    self,\n    max_value: Optional[int] = None,\n    epoch: Optional[int] = None,\n    num_epochs: Optional[int] = None,\n    stateful_metrics: Optional[List] = None,\n    always_stateful: bool = False,\n    mode: str = \"train\",\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    max_value : Optional[int], optional\n        Maximum progress bar value, by default None.\n    epoch : Optional[int], optional\n        Zero-indexed current epoch, by default None.\n    num_epochs : Optional[int], optional\n        Total number of epochs, by default None.\n    stateful_metrics : Optional[List], optional\n        Iterable of string names of metrics that should *not* be averaged over time.\n        Metrics in this list will be displayed as-is. All others will be averaged by\n        the progress bar before display, by default None.\n    always_stateful : bool, optional\n         Whether to set all metrics to be stateful, by default False.\n    mode : str, optional\n        Mode, one of \"train\", \"val\", or \"predict\", by default \"train\".\n    \"\"\"\n    self.max_value = max_value\n    # Width of the progress bar\n    self.width = 30\n    self.always_stateful = always_stateful\n\n    if (epoch is not None) and (num_epochs is not None):\n        print(f\"Epoch: {epoch + 1}/{num_epochs}\")\n\n    if stateful_metrics:\n        self.stateful_metrics = set(stateful_metrics)\n    else:\n        self.stateful_metrics = set()\n\n    self._dynamic_display = (\n        (hasattr(sys.stdout, \"isatty\") and sys.stdout.isatty())\n        or \"ipykernel\" in sys.modules\n        or \"posix\" in sys.modules\n    )\n    self._total_width = 0\n    self._seen_so_far = 0\n    # We use a dict + list to avoid garbage collection\n    # issues found in OrderedDict\n    self._values: Dict[Any, Any] = {}\n    self._values_order: List[Any] = []\n    self._start = time.time()\n    self._last_update = 0.0\n    self.spin = self.spinning_cursor() if self.max_value is None else None\n    if mode == \"train\" and self.max_value is None:\n        self.message = \"Estimating dataset size\"\n    elif mode == \"val\":\n        self.message = \"Validating\"\n    elif mode == \"predict\":\n        self.message = \"Denoising\"\n</code></pre>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.ProgressBar.add","title":"<code>add(n, values=None)</code>","text":"<p>Update the progress bar by n steps.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of steps to increase the progress bar with.</p> required <code>values</code> <code>Optional[List]</code> <p>Updated metrics values, by default None.</p> <code>None</code> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>def add(self, n: int, values: Optional[List] = None) -&gt; None:\n    \"\"\"\n    Update the progress bar by n steps.\n\n    Parameters\n    ----------\n    n : int\n        Number of steps to increase the progress bar with.\n    values : Optional[List], optional\n        Updated metrics values, by default None.\n    \"\"\"\n    self.update(self._seen_so_far + n, 1, values=values)\n</code></pre>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.ProgressBar.spinning_cursor","title":"<code>spinning_cursor()</code>","text":"<p>Generate a spinning cursor animation.</p> <p>Taken from https://github.com/manrajgrover/py-spinners/tree/master.</p> <p>Returns:</p> Type Description <code>Generator</code> <p>Generator of animation frames.</p> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>def spinning_cursor(self) -&gt; Generator:\n    \"\"\"\n    Generate a spinning cursor animation.\n\n    Taken from https://github.com/manrajgrover/py-spinners/tree/master.\n\n    Returns\n    -------\n    Generator\n        Generator of animation frames.\n    \"\"\"\n    while True:\n        yield from [\n            \"\u2593 ----- \u2592\",\n            \"\u2593 ----- \u2592\",\n            \"\u2593 ----- \u2592\",\n            \"\u2593 -&gt;--- \u2592\",\n            \"\u2593 -&gt;--- \u2592\",\n            \"\u2593 -&gt;--- \u2592\",\n            \"\u2593 --&gt;-- \u2592\",\n            \"\u2593 --&gt;-- \u2592\",\n            \"\u2593 --&gt;-- \u2592\",\n            \"\u2593 ---&gt;- \u2592\",\n            \"\u2593 ---&gt;- \u2592\",\n            \"\u2593 ---&gt;- \u2592\",\n            \"\u2593 ----&gt; \u2592\",\n            \"\u2593 ----&gt; \u2592\",\n            \"\u2593 ----&gt; \u2592\",\n            \"\u2592 ----- \u2591\",\n            \"\u2592 ----- \u2591\",\n            \"\u2592 ----- \u2591\",\n            \"\u2592 -&gt;--- \u2591\",\n            \"\u2592 -&gt;--- \u2591\",\n            \"\u2592 -&gt;--- \u2591\",\n            \"\u2592 --&gt;-- \u2591\",\n            \"\u2592 --&gt;-- \u2591\",\n            \"\u2592 --&gt;-- \u2591\",\n            \"\u2592 ---&gt;- \u2591\",\n            \"\u2592 ---&gt;- \u2591\",\n            \"\u2592 ---&gt;- \u2591\",\n            \"\u2592 ----&gt; \u2591\",\n            \"\u2592 ----&gt; \u2591\",\n            \"\u2592 ----&gt; \u2591\",\n        ]\n</code></pre>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.ProgressBar.update","title":"<code>update(current_step, batch_size=1, values=None)</code>","text":"<p>Update the progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>current_step</code> <code>int</code> <p>Index of the current step.</p> required <code>batch_size</code> <code>int</code> <p>Batch size, by default 1.</p> <code>1</code> <code>values</code> <code>Optional[List]</code> <p>Updated metrics values, by default None.</p> <code>None</code> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>def update(\n    self, current_step: int, batch_size: int = 1, values: Optional[List] = None\n) -&gt; None:\n    \"\"\"\n    Update the progress bar.\n\n    Parameters\n    ----------\n    current_step : int\n        Index of the current step.\n    batch_size : int, optional\n        Batch size, by default 1.\n    values : Optional[List], optional\n        Updated metrics values, by default None.\n    \"\"\"\n    values = values or []\n    for k, v in values:\n        # if torch tensor, convert it to numpy\n        if str(type(v)) == \"&lt;class 'torch.Tensor'&gt;\":\n            v = v.detach().cpu().numpy()\n\n        if k not in self._values_order:\n            self._values_order.append(k)\n        if k not in self.stateful_metrics and not self.always_stateful:\n            if k not in self._values:\n                self._values[k] = [\n                    v * (current_step - self._seen_so_far),\n                    current_step - self._seen_so_far,\n                ]\n            else:\n                self._values[k][0] += v * (current_step - self._seen_so_far)\n                self._values[k][1] += current_step - self._seen_so_far\n        else:\n            # Stateful metrics output a numeric value. This representation\n            # means \"take an average from a single value\" but keeps the\n            # numeric formatting.\n            self._values[k] = [v, 1]\n\n    self._seen_so_far = current_step\n\n    now = time.time()\n    info = f\" - {(now - self._start):.0f}s\"\n\n    prev_total_width = self._total_width\n    if self._dynamic_display:\n        sys.stdout.write(\"\\b\" * prev_total_width)\n        sys.stdout.write(\"\\r\")\n    else:\n        sys.stdout.write(\"\\n\")\n\n    if self.max_value is not None:\n        bar = f\"{current_step}/{self.max_value} [\"\n        progress = float(current_step) / self.max_value\n        progress_width = int(self.width * progress)\n        if progress_width &gt; 0:\n            bar += \"=\" * (progress_width - 1)\n            if current_step &lt; self.max_value:\n                bar += \"&gt;\"\n            else:\n                bar += \"=\"\n        bar += \".\" * (self.width - progress_width)\n        bar += \"]\"\n    else:\n        bar = (\n            f\"{self.message} {next(self.spin)}, tile \"  # type: ignore\n            f\"No. {current_step * batch_size}\"\n        )\n\n    self._total_width = len(bar)\n    sys.stdout.write(bar)\n\n    if current_step &gt; 0:\n        time_per_unit = (now - self._start) / current_step\n    else:\n        time_per_unit = 0\n\n    if time_per_unit &gt;= 1 or time_per_unit == 0:\n        info += f\" {time_per_unit:.0f}s/step\"\n    elif time_per_unit &gt;= 1e-3:\n        info += f\" {time_per_unit * 1e3:.0f}ms/step\"\n    else:\n        info += f\" {time_per_unit * 1e6:.0f}us/step\"\n\n    for k in self._values_order:\n        info += f\" - {k}:\"\n        if isinstance(self._values[k], list):\n            avg = self._values[k][0] / max(1, self._values[k][1])\n            if abs(avg) &gt; 1e-3:\n                info += f\" {avg:.4f}\"\n            else:\n                info += f\" {avg:.4e}\"\n        else:\n            info += f\" {self._values[k]}s\"\n\n    self._total_width += len(info)\n    if prev_total_width &gt; self._total_width:\n        info += \" \" * (prev_total_width - self._total_width)\n\n    if self.max_value is not None and current_step &gt;= self.max_value:\n        info += \"\\n\"\n\n    sys.stdout.write(info)\n    sys.stdout.flush()\n\n    self._last_update = now\n</code></pre>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.get_logger","title":"<code>get_logger(name, log_level=logging.INFO, log_path=None)</code>","text":"<p>Create a python logger instance with configured handlers.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the logger.</p> required <code>log_level</code> <code>int</code> <p>Log level (info, error etc.), by default logging.INFO.</p> <code>INFO</code> <code>log_path</code> <code>Optional[Union[str, Path]]</code> <p>Path in which to save the log, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Logger</code> <p>Logger.</p> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>def get_logger(\n    name: str,\n    log_level: int = logging.INFO,\n    log_path: Optional[Union[str, Path]] = None,\n) -&gt; logging.Logger:\n    \"\"\"\n    Create a python logger instance with configured handlers.\n\n    Parameters\n    ----------\n    name : str\n        Name of the logger.\n    log_level : int, optional\n        Log level (info, error etc.), by default logging.INFO.\n    log_path : Optional[Union[str, Path]], optional\n        Path in which to save the log, by default None.\n\n    Returns\n    -------\n    logging.Logger\n        Logger.\n    \"\"\"\n    logger = logging.getLogger(name)\n    logger.propagate = False\n\n    if name in LOGGERS:\n        return logger\n\n    for logger_name in LOGGERS:\n        if name.startswith(logger_name):\n            return logger\n\n    logger.propagate = False\n\n    if log_path:\n        handlers = [\n            logging.StreamHandler(),\n            logging.FileHandler(log_path),\n        ]\n    else:\n        handlers = [logging.StreamHandler()]\n\n    formatter = logging.Formatter(\"%(message)s\")\n\n    for handler in handlers:\n        handler.setFormatter(formatter)  # type: ignore\n        handler.setLevel(log_level)  # type: ignore\n        logger.addHandler(handler)  # type: ignore\n\n    logger.setLevel(log_level)\n    LOGGERS[name] = True\n\n    logger.propagate = False\n\n    return logger\n</code></pre>"},{"location":"reference/careamics/utils/metrics/","title":"metrics","text":"<p>Metrics submodule.</p> <p>This module contains various metrics and a metrics tracking class.</p>"},{"location":"reference/careamics/utils/metrics/#careamics.utils.metrics.MetricTracker","title":"<code>MetricTracker</code>","text":"<p>Metric tracker class.</p> <p>This class is used to track values, sum, count and average of a metric over time.</p> <p>Attributes:</p> Name Type Description <code>val</code> <code>int</code> <p>Last value of the metric.</p> <code>avg</code> <code>float</code> <p>Average value of the metric.</p> <code>sum</code> <code>int</code> <p>Sum of the metric values (times number of values).</p> <code>count</code> <code>int</code> <p>Number of values.</p> Source code in <code>src/careamics/utils/metrics.py</code> <pre><code>class MetricTracker:\n    \"\"\"\n    Metric tracker class.\n\n    This class is used to track values, sum, count and average of a metric over time.\n\n    Attributes\n    ----------\n    val : int\n        Last value of the metric.\n    avg : torch.Tensor.float\n        Average value of the metric.\n    sum : int\n        Sum of the metric values (times number of values).\n    count : int\n        Number of values.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Constructor.\"\"\"\n        self.reset()\n\n    def reset(self) -&gt; None:\n        \"\"\"Reset the metric tracker state.\"\"\"\n        self.val = 0.0\n        self.avg: torch.Tensor.float = 0.0\n        self.sum = 0.0\n        self.count = 0.0\n\n    def update(self, value: int, n: int = 1) -&gt; None:\n        \"\"\"\n        Update the metric tracker state.\n\n        Parameters\n        ----------\n        value : int\n            Value to update the metric tracker with.\n        n : int\n            Number of values, equals to batch size.\n        \"\"\"\n        self.val = value\n        self.sum += value * n\n        self.count += n\n        self.avg = self.sum / self.count\n</code></pre>"},{"location":"reference/careamics/utils/metrics/#careamics.utils.metrics.MetricTracker.__init__","title":"<code>__init__()</code>","text":"<p>Constructor.</p> Source code in <code>src/careamics/utils/metrics.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Constructor.\"\"\"\n    self.reset()\n</code></pre>"},{"location":"reference/careamics/utils/metrics/#careamics.utils.metrics.MetricTracker.reset","title":"<code>reset()</code>","text":"<p>Reset the metric tracker state.</p> Source code in <code>src/careamics/utils/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"Reset the metric tracker state.\"\"\"\n    self.val = 0.0\n    self.avg: torch.Tensor.float = 0.0\n    self.sum = 0.0\n    self.count = 0.0\n</code></pre>"},{"location":"reference/careamics/utils/metrics/#careamics.utils.metrics.MetricTracker.update","title":"<code>update(value, n=1)</code>","text":"<p>Update the metric tracker state.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>Value to update the metric tracker with.</p> required <code>n</code> <code>int</code> <p>Number of values, equals to batch size.</p> <code>1</code> Source code in <code>src/careamics/utils/metrics.py</code> <pre><code>def update(self, value: int, n: int = 1) -&gt; None:\n    \"\"\"\n    Update the metric tracker state.\n\n    Parameters\n    ----------\n    value : int\n        Value to update the metric tracker with.\n    n : int\n        Number of values, equals to batch size.\n    \"\"\"\n    self.val = value\n    self.sum += value * n\n    self.count += n\n    self.avg = self.sum / self.count\n</code></pre>"},{"location":"reference/careamics/utils/metrics/#careamics.utils.metrics.psnr","title":"<code>psnr(gt, pred, range=255.0)</code>","text":"<p>Peak Signal to Noise Ratio.</p> <p>This method calls skimage.metrics.peak_signal_noise_ratio. See: https://scikit-image.org/docs/dev/api/skimage.metrics.html.</p> <p>Parameters:</p> Name Type Description Default <code>gt</code> <code>NumPy array</code> <p>Ground truth image.</p> required <code>pred</code> <code>NumPy array</code> <p>Predicted image.</p> required <code>range</code> <code>float</code> <p>The images pixel range, by default 255.0.</p> <code>255.0</code> <p>Returns:</p> Type Description <code>float</code> <p>PSNR value.</p> Source code in <code>src/careamics/utils/metrics.py</code> <pre><code>def psnr(gt: np.ndarray, pred: np.ndarray, range: float = 255.0) -&gt; float:\n    \"\"\"\n    Peak Signal to Noise Ratio.\n\n    This method calls skimage.metrics.peak_signal_noise_ratio. See:\n    https://scikit-image.org/docs/dev/api/skimage.metrics.html.\n\n    Parameters\n    ----------\n    gt : NumPy array\n        Ground truth image.\n    pred : NumPy array\n        Predicted image.\n    range : float, optional\n        The images pixel range, by default 255.0.\n\n    Returns\n    -------\n    float\n        PSNR value.\n    \"\"\"\n    return peak_signal_noise_ratio(gt, pred, data_range=range)\n</code></pre>"},{"location":"reference/careamics/utils/metrics/#careamics.utils.metrics.scale_invariant_psnr","title":"<code>scale_invariant_psnr(gt, pred)</code>","text":"<p>Scale invariant PSNR.</p> <p>Parameters:</p> Name Type Description Default <code>gt</code> <code>ndarray</code> <p>Ground truth image.</p> required <code>pred</code> <code>ndarray</code> <p>Predicted image.</p> required <p>Returns:</p> Type Description <code>Union[float, tensor]</code> <p>Scale invariant PSNR value.</p> Source code in <code>src/careamics/utils/metrics.py</code> <pre><code>def scale_invariant_psnr(\n    gt: np.ndarray, pred: np.ndarray\n) -&gt; Union[float, torch.tensor]:\n    \"\"\"\n    Scale invariant PSNR.\n\n    Parameters\n    ----------\n    gt : np.ndarray\n        Ground truth image.\n    pred : np.ndarray\n        Predicted image.\n\n    Returns\n    -------\n    Union[float, torch.tensor]\n        Scale invariant PSNR value.\n    \"\"\"\n    range_parameter = (np.max(gt) - np.min(gt)) / np.std(gt)\n    gt_ = _zero_mean(gt) / np.std(gt)\n    return psnr(_zero_mean(gt_), _fix(gt_, pred), range_parameter)\n</code></pre>"},{"location":"reference/careamics/utils/normalization/","title":"normalization","text":"<p>Normalization submodule.</p> <p>These methods are used to normalize and denormalize images.</p>"},{"location":"reference/careamics/utils/normalization/#careamics.utils.normalization.denormalize","title":"<code>denormalize(img, mean, std)</code>","text":"<p>Denormalize an image using mean and standard deviation.</p> <p>Images are denormalised by multiplying by the standard deviation and adding the mean.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>ndarray</code> <p>Image to denormalize.</p> required <code>mean</code> <code>float</code> <p>Mean.</p> required <code>std</code> <code>float</code> <p>Standard deviation.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Denormalized array.</p> Source code in <code>src/careamics/utils/normalization.py</code> <pre><code>def denormalize(img: np.ndarray, mean: float, std: float) -&gt; np.ndarray:\n    \"\"\"\n    Denormalize an image using mean and standard deviation.\n\n    Images are denormalised by multiplying by the standard deviation and adding the\n    mean.\n\n    Parameters\n    ----------\n    img : np.ndarray\n        Image to denormalize.\n    mean : float\n        Mean.\n    std : float\n        Standard deviation.\n\n    Returns\n    -------\n    np.ndarray\n        Denormalized array.\n    \"\"\"\n    return img * std + mean\n</code></pre>"},{"location":"reference/careamics/utils/normalization/#careamics.utils.normalization.normalize","title":"<code>normalize(img, mean, std)</code>","text":"<p>Normalize an image using mean and standard deviation.</p> <p>Images are normalised by subtracting the mean and dividing by the standard deviation.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>ndarray</code> <p>Image to normalize.</p> required <code>mean</code> <code>float</code> <p>Mean.</p> required <code>std</code> <code>float</code> <p>Standard deviation.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Normalized array.</p> Source code in <code>src/careamics/utils/normalization.py</code> <pre><code>def normalize(img: np.ndarray, mean: float, std: float) -&gt; np.ndarray:\n    \"\"\"\n    Normalize an image using mean and standard deviation.\n\n    Images are normalised by subtracting the mean and dividing by the standard\n    deviation.\n\n    Parameters\n    ----------\n    img : np.ndarray\n        Image to normalize.\n    mean : float\n        Mean.\n    std : float\n        Standard deviation.\n\n    Returns\n    -------\n    np.ndarray\n        Normalized array.\n    \"\"\"\n    zero_mean = img - mean\n    return zero_mean / std\n</code></pre>"},{"location":"reference/careamics/utils/torch_utils/","title":"torch_utils","text":"<p>Convenience functions using torch.</p> <p>These functions are used to control certain aspects and behaviours of PyTorch.</p>"},{"location":"reference/careamics/utils/torch_utils/#careamics.utils.torch_utils.get_device","title":"<code>get_device()</code>","text":"<p>Select the device to use for training.</p> <p>Returns:</p> Type Description <code>device</code> <p>CUDA or CPU device, depending on availability of CUDA devices.</p> Source code in <code>src/careamics/utils/torch_utils.py</code> <pre><code>def get_device() -&gt; torch.device:\n    \"\"\"\n    Select the device to use for training.\n\n    Returns\n    -------\n    torch.device\n        CUDA or CPU device, depending on availability of CUDA devices.\n    \"\"\"\n    if torch.cuda.is_available():\n        logging.info(\"CUDA available. Using GPU.\")\n        device = torch.device(\"cuda\")\n    else:\n        logging.info(\"CUDA not available. Using CPU.\")\n        device = torch.device(\"cpu\")\n    return device\n</code></pre>"},{"location":"reference/careamics/utils/validators/","title":"validators","text":"<p>Validator functions.</p> <p>These functions are used to validate dimensions and axes of inputs.</p>"},{"location":"reference/careamics/utils/validators/#careamics.utils.validators.add_axes","title":"<code>add_axes(input_array, axes)</code>","text":"<p>Add missing axes to the input, typically batch and channel.</p> <p>This method validates the axes first. Then it inspects the input array and add missing dimensions if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>input_array</code> <code>ndarray</code> <p>Input array.</p> required <code>axes</code> <code>str</code> <p>Axes to add.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array with new singleton axes.</p> Source code in <code>src/careamics/utils/validators.py</code> <pre><code>def add_axes(input_array: np.ndarray, axes: str) -&gt; np.ndarray:\n    \"\"\"\n    Add missing axes to the input, typically batch and channel.\n\n    This method validates the axes first. Then it inspects the input array and add\n    missing dimensions if necessary.\n\n    Parameters\n    ----------\n    input_array : np.ndarray\n        Input array.\n    axes : str\n        Axes to add.\n\n    Returns\n    -------\n    np.ndarray\n        Array with new singleton axes.\n    \"\"\"\n    # validate axes\n    check_axes_validity(axes)\n\n    # is 3D\n    is_3D = \"Z\" in axes\n\n    # number of dims\n    n_dims = 5 if is_3D else 4\n\n    # array of dim 2, 3 or 4\n    if len(input_array.shape) &lt; n_dims:\n        if \"S\" not in axes and \"T\" not in axes:\n            input_array = input_array[np.newaxis, ...]\n\n        # still missing C dimension\n        if len(input_array.shape) &lt; n_dims:\n            input_array = input_array[:, np.newaxis, ...]\n\n    return input_array\n</code></pre>"},{"location":"reference/careamics/utils/validators/#careamics.utils.validators.check_axes_validity","title":"<code>check_axes_validity(axes)</code>","text":"<p>Sanity check on axes.</p> <p>The constraints on the axes are the following: - must be a combination of 'STCZYX' - must not contain duplicates - must contain at least 2 contiguous axes: X and Y - must contain at most 4 axes - cannot contain both S and T axes - C is currently not allowed</p> <p>Parameters:</p> Name Type Description Default <code>axes</code> <code>str</code> <p>Axes to validate.</p> required Source code in <code>src/careamics/utils/validators.py</code> <pre><code>def check_axes_validity(axes: str) -&gt; None:\n    \"\"\"\n    Sanity check on axes.\n\n    The constraints on the axes are the following:\n    - must be a combination of 'STCZYX'\n    - must not contain duplicates\n    - must contain at least 2 contiguous axes: X and Y\n    - must contain at most 4 axes\n    - cannot contain both S and T axes\n    - C is currently not allowed\n\n    Parameters\n    ----------\n    axes : str\n        Axes to validate.\n    \"\"\"\n    _axes = axes.upper()\n\n    # Minimum is 2 (XY) and maximum is 4 (TZYX)\n    if len(_axes) &lt; 2 or len(_axes) &gt; 4:\n        raise ValueError(\n            f\"Invalid axes {axes}. Must contain at least 2 and at most 4 axes.\"\n        )\n\n    # all characters must be in REF_AXES = 'STCZYX'\n    if not all(s in AXES for s in _axes):\n        raise ValueError(f\"Invalid axes {axes}. Must be a combination of {AXES}.\")\n\n    # check for repeating characters\n    for i, s in enumerate(_axes):\n        if i != _axes.rfind(s):\n            raise ValueError(\n                f\"Invalid axes {axes}. Cannot contain duplicate axes\"\n                f\" (got multiple {axes[i]}).\"\n            )\n\n    # currently no implementation for C\n    if \"C\" in _axes:\n        raise NotImplementedError(\"Currently, C axis is not supported.\")\n\n    # prevent S and T axes at the same time\n    if \"T\" in _axes and \"S\" in _axes:\n        raise NotImplementedError(\n            f\"Invalid axes {axes}. Cannot contain both S and T axes.\"\n        )\n\n    # prior: X and Y contiguous (#FancyComments)\n    # right now the next check is invalidating this, but in the future, we might\n    # allow random order of axes (or at least XY and YX)\n    if \"XY\" not in _axes and \"YX\" not in _axes:\n        raise ValueError(f\"Invalid axes {axes}. X and Y must be contiguous.\")\n\n    # check that the axes are in the right order\n    for i, s in enumerate(_axes):\n        if i &lt; len(_axes) - 1:\n            index_s = AXES.find(s)\n            index_next = AXES.find(_axes[i + 1])\n\n            if index_s &gt; index_next:\n                raise ValueError(\n                    f\"Invalid axes {axes}. Axes must be in the order {AXES}.\"\n                )\n</code></pre>"},{"location":"reference/careamics/utils/validators/#careamics.utils.validators.check_tiling_validity","title":"<code>check_tiling_validity(tile_shape, overlaps)</code>","text":"<p>Check that the tiling parameters are valid.</p> <p>Parameters:</p> Name Type Description Default <code>tile_shape</code> <code>List[int]</code> <p>Shape of the tiles.</p> required <code>overlaps</code> <code>List[int]</code> <p>Overlap between tiles.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If one of the parameters is None.</p> <code>ValueError</code> <p>If one of the element is zero.</p> <code>ValueError</code> <p>If one of the element is non-divisible by 2.</p> <code>ValueError</code> <p>If the number of elements in <code>overlaps</code> and <code>tile_shape</code> is different.</p> <code>ValueError</code> <p>If one of the overlaps is larger than the corresponding tile shape.</p> Source code in <code>src/careamics/utils/validators.py</code> <pre><code>def check_tiling_validity(tile_shape: List[int], overlaps: List[int]) -&gt; None:\n    \"\"\"\n    Check that the tiling parameters are valid.\n\n    Parameters\n    ----------\n    tile_shape : List[int]\n        Shape of the tiles.\n    overlaps : List[int]\n        Overlap between tiles.\n\n    Raises\n    ------\n    ValueError\n        If one of the parameters is None.\n    ValueError\n        If one of the element is zero.\n    ValueError\n        If one of the element is non-divisible by 2.\n    ValueError\n        If the number of elements in `overlaps` and `tile_shape` is different.\n    ValueError\n        If one of the overlaps is larger than the corresponding tile shape.\n    \"\"\"\n    # cannot be None\n    if tile_shape is None or overlaps is None:\n        raise ValueError(\n            \"Cannot use tiling without specifying `tile_shape` and \"\n            \"`overlaps`, make sure they have been correctly specified.\"\n        )\n\n    # non-zero and divisible by two\n    for dims_list in [tile_shape, overlaps]:\n        for dim in dims_list:\n            if dim &lt; 1:\n                raise ValueError(f\"Entry must be non-null positive (got {dim}).\")\n\n            if dim % 2 != 0:\n                raise ValueError(f\"Entry must be divisible by 2 (got {dim}).\")\n\n    # same length\n    if len(overlaps) != len(tile_shape):\n        raise ValueError(\n            f\"Overlaps ({len(overlaps)}) and tile shape ({len(tile_shape)}) must \"\n            f\"have the same number of dimensions.\"\n        )\n\n    # overlaps smaller than tile shape\n    for overlap, tile_dim in zip(overlaps, tile_shape):\n        if overlap &gt;= tile_dim:\n            raise ValueError(\n                f\"Overlap ({overlap}) must be smaller than tile shape ({tile_dim}).\"\n            )\n</code></pre>"},{"location":"reference/careamics/utils/wandb/","title":"wandb","text":"<p>A WandB logger for CAREamics.</p> <p>Implements a WandB class for use within the Engine.</p>"},{"location":"reference/careamics/utils/wandb/#careamics.utils.wandb.WandBLogging","title":"<code>WandBLogging</code>","text":"<p>WandB logging class.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_name</code> <code>str</code> <p>Name of the experiment.</p> required <code>log_path</code> <code>Path</code> <p>Path in which to save the WandB log.</p> required <code>config</code> <code>Configuration</code> <p>Configuration of the model.</p> required <code>model_to_watch</code> <code>Module</code> <p>Model.</p> required <code>save_code</code> <code>bool</code> <p>Whether to save the code, by default True.</p> <code>True</code> Source code in <code>src/careamics/utils/wandb.py</code> <pre><code>class WandBLogging:\n    \"\"\"\n    WandB logging class.\n\n    Parameters\n    ----------\n    experiment_name : str\n        Name of the experiment.\n    log_path : Path\n        Path in which to save the WandB log.\n    config : Configuration\n        Configuration of the model.\n    model_to_watch : torch.nn.Module\n        Model.\n    save_code : bool, optional\n        Whether to save the code, by default True.\n    \"\"\"\n\n    def __init__(\n        self,\n        experiment_name: str,\n        log_path: Path,\n        config: Configuration,\n        model_to_watch: torch.nn.Module,\n        save_code: bool = True,\n    ):\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        experiment_name : str\n            Name of the experiment.\n        log_path : Path\n            Path in which to save the WandB log.\n        config : Configuration\n            Configuration of the model.\n        model_to_watch : torch.nn.Module\n            Model.\n        save_code : bool, optional\n            Whether to save the code, by default True.\n        \"\"\"\n        self.run = wandb.init(\n            project=\"careamics-restoration\",\n            dir=log_path,\n            name=experiment_name,\n            config=config.model_dump() if config else None,\n            # save_code=save_code,\n        )\n        if model_to_watch:\n            wandb.watch(model_to_watch, log=\"all\", log_freq=1)\n        if save_code:\n            if is_notebook():\n                # Get all sys path and select the root\n                code_path = Path([p for p in sys.path if \"caremics\" in p][-1]).parent\n            else:\n                code_path = Path(\"../\")\n            self.log_code(code_path)\n\n    def log_metrics(self, metric_dict: Dict) -&gt; None:\n        \"\"\"\n        Log metrics to wandb.\n\n        Parameters\n        ----------\n        metric_dict : Dict\n            New metrics entry.\n        \"\"\"\n        self.run.log(metric_dict, commit=True)\n\n    def log_code(self, code_path: Union[str, Path]) -&gt; None:\n        \"\"\"\n        Log code to wandb.\n\n        Parameters\n        ----------\n        code_path : Union[str, Path]\n            Path to the code.\n        \"\"\"\n        self.run.log_code(\n            root=code_path,\n            include_fn=lambda path: path.endswith(\".py\")\n            or path.endswith(\".yml\")\n            or path.endswith(\".yaml\"),\n        )\n</code></pre>"},{"location":"reference/careamics/utils/wandb/#careamics.utils.wandb.WandBLogging.__init__","title":"<code>__init__(experiment_name, log_path, config, model_to_watch, save_code=True)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_name</code> <code>str</code> <p>Name of the experiment.</p> required <code>log_path</code> <code>Path</code> <p>Path in which to save the WandB log.</p> required <code>config</code> <code>Configuration</code> <p>Configuration of the model.</p> required <code>model_to_watch</code> <code>Module</code> <p>Model.</p> required <code>save_code</code> <code>bool</code> <p>Whether to save the code, by default True.</p> <code>True</code> Source code in <code>src/careamics/utils/wandb.py</code> <pre><code>def __init__(\n    self,\n    experiment_name: str,\n    log_path: Path,\n    config: Configuration,\n    model_to_watch: torch.nn.Module,\n    save_code: bool = True,\n):\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    experiment_name : str\n        Name of the experiment.\n    log_path : Path\n        Path in which to save the WandB log.\n    config : Configuration\n        Configuration of the model.\n    model_to_watch : torch.nn.Module\n        Model.\n    save_code : bool, optional\n        Whether to save the code, by default True.\n    \"\"\"\n    self.run = wandb.init(\n        project=\"careamics-restoration\",\n        dir=log_path,\n        name=experiment_name,\n        config=config.model_dump() if config else None,\n        # save_code=save_code,\n    )\n    if model_to_watch:\n        wandb.watch(model_to_watch, log=\"all\", log_freq=1)\n    if save_code:\n        if is_notebook():\n            # Get all sys path and select the root\n            code_path = Path([p for p in sys.path if \"caremics\" in p][-1]).parent\n        else:\n            code_path = Path(\"../\")\n        self.log_code(code_path)\n</code></pre>"},{"location":"reference/careamics/utils/wandb/#careamics.utils.wandb.WandBLogging.log_code","title":"<code>log_code(code_path)</code>","text":"<p>Log code to wandb.</p> <p>Parameters:</p> Name Type Description Default <code>code_path</code> <code>Union[str, Path]</code> <p>Path to the code.</p> required Source code in <code>src/careamics/utils/wandb.py</code> <pre><code>def log_code(self, code_path: Union[str, Path]) -&gt; None:\n    \"\"\"\n    Log code to wandb.\n\n    Parameters\n    ----------\n    code_path : Union[str, Path]\n        Path to the code.\n    \"\"\"\n    self.run.log_code(\n        root=code_path,\n        include_fn=lambda path: path.endswith(\".py\")\n        or path.endswith(\".yml\")\n        or path.endswith(\".yaml\"),\n    )\n</code></pre>"},{"location":"reference/careamics/utils/wandb/#careamics.utils.wandb.WandBLogging.log_metrics","title":"<code>log_metrics(metric_dict)</code>","text":"<p>Log metrics to wandb.</p> <p>Parameters:</p> Name Type Description Default <code>metric_dict</code> <code>Dict</code> <p>New metrics entry.</p> required Source code in <code>src/careamics/utils/wandb.py</code> <pre><code>def log_metrics(self, metric_dict: Dict) -&gt; None:\n    \"\"\"\n    Log metrics to wandb.\n\n    Parameters\n    ----------\n    metric_dict : Dict\n        New metrics entry.\n    \"\"\"\n    self.run.log(metric_dict, commit=True)\n</code></pre>"},{"location":"reference/careamics/utils/wandb/#careamics.utils.wandb.is_notebook","title":"<code>is_notebook()</code>","text":"<p>Check if the code is executed from a notebook or a qtconsole.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the code is executed from a notebooks, False otherwise.</p> Source code in <code>src/careamics/utils/wandb.py</code> <pre><code>def is_notebook() -&gt; bool:\n    \"\"\"\n    Check if the code is executed from a notebook or a qtconsole.\n\n    Returns\n    -------\n    bool\n        True if the code is executed from a notebooks, False otherwise.\n    \"\"\"\n    try:\n        from IPython import get_ipython\n\n        shell = get_ipython().__class__.__name__\n        if shell == \"ZMQInteractiveShell\":\n            return True  # Jupyter notebook or qtconsole\n        else:\n            return False\n    except (NameError, ModuleNotFoundError):\n        return False\n</code></pre>"},{"location":"reference/careamics_portfolio/","title":"CAREamics portfolio","text":"<p>Use the navigation index on the left to explore the documentation.</p>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/","title":"denoiseg_datasets","text":""},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.DSB2018","title":"<code>DSB2018</code>","text":"<p>             Bases: <code>PortfolioEntry</code>, <code>NoisyObject</code></p> <p>The 2018 Data Science Bowl dataset used by DenoiSeg.</p> <p>The dataset is available in three different noise levels: N0, N10 and N20.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>noise_level (NoiseLevel): Noise level of the dataset. name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. files (list[str]): List of files in the dataset. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>class DSB2018(PortfolioEntry, NoisyObject):\n    \"\"\"The 2018 Data Science Bowl dataset used by DenoiSeg.\n\n    The dataset is available in three different noise levels: N0, N10 and N20.\n\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        noise_level (NoiseLevel): Noise level of the dataset.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        files (list[str]): List of files in the dataset.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n        \"\"\"Initialize a DSB2018 instance.\n\n        Parameters\n        ----------\n        noise_level : NoiseLevel, optional\n            Noise level of the dataset, by default NoiseLevel.N0\n        \"\"\"\n        super().__init__(\n            portfolio=DENOISEG,\n            noise_level=noise_level,\n            name=f\"DSB2018_n{noise_level.value}\",\n            url=self._get_url(noise_level),\n            file_name=f\"DSB2018_n{noise_level.value}.zip\",\n            sha256=self._get_hash(noise_level),\n            description=\"From the Kaggle 2018 Data Science Bowl challenge, the \"\n            \"training and validation sets consist of 3800 and 670 patches \"\n            \"respectively, while the test set counts 50 images.\\n\"\n            \"Original data: \"\n            \"https://www.kaggle.com/competitions/data-science-bowl-2018/data\",\n            license=\"GPL-3.0\",\n            citation=\"Caicedo, J.C., Goodman, A., Karhohs, K.W. et al. Nucleus \"\n            \"segmentation across imaging experiments: the 2018 Data Science \"\n            \"Bowl. Nat Methods 16, 1247-1253 (2019). \"\n            \"https://doi.org/10.1038/s41592-019-0612-7\",\n            files=[\n                f\"DSB2018_n{noise_level.value}/train/train_data.npz\",\n                f\"DSB2018_n{noise_level.value}/test/test_data.npz\",\n            ],\n            size=self._get_size(noise_level),\n            tags=[\"denoising\", \"segmentation\", \"nuclei\", \"fluorescence\"],\n        )\n\n    @staticmethod\n    def _get_url(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"https://zenodo.org/record/5156969/files/DSB2018_n0.zip?download=1\"\n        elif noise == NoiseLevel.N10:\n            return \"https://zenodo.org/record/5156977/files/DSB2018_n10.zip?download=1\"\n        else:\n            return \"https://zenodo.org/record/5156983/files/DSB2018_n20.zip?download=1\"\n\n    @staticmethod\n    def _get_hash(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"729d7683ccfa1ad437f666256b23e73b3b3b3da6a8e47bb37303f0c64376a299\"\n        elif noise == NoiseLevel.N10:\n            return \"a4cf731aa0652f8198275f8ce29fb98e0c76c391a96b6092d0792fe447e4103a\"\n        else:\n            return \"6a732a12bf18fecc590230b1cd4df5e32acfa1b35ef2fca42db811cb8277c67c\"\n\n    @staticmethod\n    def _get_size(noise: NoiseLevel) -&gt; float:\n        if noise == NoiseLevel.N0:\n            return 40.2\n        elif noise == NoiseLevel.N10:\n            return 366.0\n        else:\n            return 368.0\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.DSB2018.__init__","title":"<code>__init__(noise_level=NoiseLevel.N0)</code>","text":"<p>Initialize a DSB2018 instance.</p> <p>Parameters:</p> Name Type Description Default <code>noise_level</code> <code>NoiseLevel</code> <p>Noise level of the dataset, by default NoiseLevel.N0</p> <code>N0</code> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n    \"\"\"Initialize a DSB2018 instance.\n\n    Parameters\n    ----------\n    noise_level : NoiseLevel, optional\n        Noise level of the dataset, by default NoiseLevel.N0\n    \"\"\"\n    super().__init__(\n        portfolio=DENOISEG,\n        noise_level=noise_level,\n        name=f\"DSB2018_n{noise_level.value}\",\n        url=self._get_url(noise_level),\n        file_name=f\"DSB2018_n{noise_level.value}.zip\",\n        sha256=self._get_hash(noise_level),\n        description=\"From the Kaggle 2018 Data Science Bowl challenge, the \"\n        \"training and validation sets consist of 3800 and 670 patches \"\n        \"respectively, while the test set counts 50 images.\\n\"\n        \"Original data: \"\n        \"https://www.kaggle.com/competitions/data-science-bowl-2018/data\",\n        license=\"GPL-3.0\",\n        citation=\"Caicedo, J.C., Goodman, A., Karhohs, K.W. et al. Nucleus \"\n        \"segmentation across imaging experiments: the 2018 Data Science \"\n        \"Bowl. Nat Methods 16, 1247-1253 (2019). \"\n        \"https://doi.org/10.1038/s41592-019-0612-7\",\n        files=[\n            f\"DSB2018_n{noise_level.value}/train/train_data.npz\",\n            f\"DSB2018_n{noise_level.value}/test/test_data.npz\",\n        ],\n        size=self._get_size(noise_level),\n        tags=[\"denoising\", \"segmentation\", \"nuclei\", \"fluorescence\"],\n    )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.MouseNuclei","title":"<code>MouseNuclei</code>","text":"<p>             Bases: <code>PortfolioEntry</code>, <code>NoisyObject</code></p> <p>Mouse nuclei dataset used by DenoiSeg.</p> <p>The dataset is available in three different noise levels: N0, N10 and N20.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>noise_level (NoiseLevel): Noise level of the dataset. name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. files (list[str]): List of files in the dataset. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>class MouseNuclei(PortfolioEntry, NoisyObject):\n    \"\"\"Mouse nuclei dataset used by DenoiSeg.\n\n    The dataset is available in three different noise levels: N0, N10 and N20.\n\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        noise_level (NoiseLevel): Noise level of the dataset.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        files (list[str]): List of files in the dataset.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n        \"\"\"Initialize a MouseNuclei instance.\n\n        Parameters\n        ----------\n        noise_level : NoiseLevel, optional\n            Noise level of the dataset, by default NoiseLevel.N0\n        \"\"\"\n        super().__init__(\n            portfolio=DENOISEG,\n            noise_level=noise_level,\n            name=f\"MouseNuclei_n{noise_level.value}\",\n            url=self._get_url(noise_level),\n            file_name=f\"MouseNuclei_n{noise_level.value}.zip\",\n            sha256=self._get_hash(noise_level),\n            description=\"A dataset depicting diverse and non-uniformly \"\n            \"clustered nuclei in the mouse skull, consisting of 908 training \"\n            \"and 160 validation patches. The test set counts 67 additional images\",\n            license=\"CC BY-SA 4.0\",\n            citation=\"Buchholz, T.O., Prakash, M., Schmidt, D., Krull, A., Jug, \"\n            \"F.: Denoiseg: joint denoising and segmentation. In: European \"\n            \"Conference on Computer Vision (ECCV). pp. 324-337. Springer (2020) 8, 9\",\n            files=[\n                f\"Mouse_n{noise_level.value}/train/train_data.npz\",\n                f\"Mouse_n{noise_level.value}/test/test_data.npz\",\n            ],\n            size=self._get_size(noise_level),\n            tags=[\"denoising\", \"segmentation\", \"nuclei\", \"fluorescence\"],\n        )\n\n    @staticmethod\n    def _get_url(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"https://zenodo.org/record/5157001/files/Mouse_n0.zip?download=1\"\n        elif noise == NoiseLevel.N10:\n            return \"https://zenodo.org/record/5157003/files/Mouse_n10.zip?download=1\"\n        else:\n            return \"https://zenodo.org/record/5157008/files/Mouse_n20.zip?download=1\"\n\n    @staticmethod\n    def _get_hash(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"5d6fd2fc23ab991a8fde4bd0ec5e9fc9299f9a9ddc2a8acb7095f9b02ff3c9d7\"\n        elif noise == NoiseLevel.N10:\n            return \"de634496e3e46a4887907b713fe6f575e410c3006046054bce67ef9398523c2c\"\n        else:\n            return \"d3d1bf8c89bb97a673a0791874e5b75a6a516ccaaeece0244b4e1e0afe7ab3ec\"\n\n    @staticmethod\n    def _get_size(noise: NoiseLevel) -&gt; float:\n        if noise == NoiseLevel.N0:\n            return 12.4\n        elif noise == NoiseLevel.N10:\n            return 161.0\n        else:\n            return 160.0\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.MouseNuclei.__init__","title":"<code>__init__(noise_level=NoiseLevel.N0)</code>","text":"<p>Initialize a MouseNuclei instance.</p> <p>Parameters:</p> Name Type Description Default <code>noise_level</code> <code>NoiseLevel</code> <p>Noise level of the dataset, by default NoiseLevel.N0</p> <code>N0</code> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n    \"\"\"Initialize a MouseNuclei instance.\n\n    Parameters\n    ----------\n    noise_level : NoiseLevel, optional\n        Noise level of the dataset, by default NoiseLevel.N0\n    \"\"\"\n    super().__init__(\n        portfolio=DENOISEG,\n        noise_level=noise_level,\n        name=f\"MouseNuclei_n{noise_level.value}\",\n        url=self._get_url(noise_level),\n        file_name=f\"MouseNuclei_n{noise_level.value}.zip\",\n        sha256=self._get_hash(noise_level),\n        description=\"A dataset depicting diverse and non-uniformly \"\n        \"clustered nuclei in the mouse skull, consisting of 908 training \"\n        \"and 160 validation patches. The test set counts 67 additional images\",\n        license=\"CC BY-SA 4.0\",\n        citation=\"Buchholz, T.O., Prakash, M., Schmidt, D., Krull, A., Jug, \"\n        \"F.: Denoiseg: joint denoising and segmentation. In: European \"\n        \"Conference on Computer Vision (ECCV). pp. 324-337. Springer (2020) 8, 9\",\n        files=[\n            f\"Mouse_n{noise_level.value}/train/train_data.npz\",\n            f\"Mouse_n{noise_level.value}/test/test_data.npz\",\n        ],\n        size=self._get_size(noise_level),\n        tags=[\"denoising\", \"segmentation\", \"nuclei\", \"fluorescence\"],\n    )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.NoiseLevel","title":"<code>NoiseLevel</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>An IntEnum representing the noise level of a dataset.</p> <p>N0 corresponds to the noise-free version of the dataset, N10 and N20 to images corrupted with Gaussian noise with zero-mean and standard deviations of 10 and 20, respectively.</p> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>class NoiseLevel(str, Enum):\n    \"\"\"An IntEnum representing the noise level of a dataset.\n\n    N0 corresponds to the noise-free version of the dataset, N10 and N20 to\n    images corrupted with Gaussian noise with zero-mean and standard deviations\n    of 10 and 20, respectively.\n    \"\"\"\n\n    N0 = \"0\"\n    N10 = \"10\"\n    N20 = \"20\"\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.NoisyObject","title":"<code>NoisyObject</code>","text":"<p>A mixin class for datasets with different noise levels.</p> <p>Attributes:</p> Name Type Description <code>noise_level (NoiseLevel)</code> <code>Noise level of the dataset.</code> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>class NoisyObject:\n    \"\"\"A mixin class for datasets with different noise levels.\n\n    Attributes\n    ----------\n    noise_level (NoiseLevel): Noise level of the dataset.\n    \"\"\"\n\n    def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0, **kwargs: str) -&gt; None:\n        self._noise_level = noise_level\n\n    @property\n    def noise_level(self) -&gt; NoiseLevel:\n        \"\"\"Noise level of the dataset.\"\"\"\n        return self._noise_level\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.NoisyObject.noise_level","title":"<code>noise_level: NoiseLevel</code>  <code>property</code>","text":"<p>Noise level of the dataset.</p>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.SegFlywing","title":"<code>SegFlywing</code>","text":"<p>             Bases: <code>PortfolioEntry</code>, <code>NoisyObject</code></p> <p>Flywing dataset used by DenoiSeg.</p> <p>The dataset is available in three different noise levels: N0, N10 and N20.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>noise_level (NoiseLevel): Noise level of the dataset. name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. files (list[str]): List of files in the dataset. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>class SegFlywing(PortfolioEntry, NoisyObject):\n    \"\"\"Flywing dataset used by DenoiSeg.\n\n    The dataset is available in three different noise levels: N0, N10 and N20.\n\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        noise_level (NoiseLevel): Noise level of the dataset.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        files (list[str]): List of files in the dataset.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n        \"\"\"Initialize a Flywing instance.\n\n        Parameters\n        ----------\n        noise_level : NoiseLevel, optional\n            Noise level of the dataset, by default NoiseLevel.N0\n        \"\"\"\n        super().__init__(\n            portfolio=DENOISEG,\n            noise_level=noise_level,\n            name=f\"Flywing_n{noise_level.value}\",\n            url=self._get_url(noise_level),\n            file_name=f\"Flywing_n{noise_level.value}.zip\",\n            sha256=self._get_hash(noise_level),\n            description=\"This dataset consist of 1428 training and 252 \"\n            \"validation patches of a membrane labeled fly wing. The test set \"\n            \"is comprised of 50 additional images.\",\n            license=\"CC BY-SA 4.0\",\n            citation=\"Buchholz, T.O., Prakash, M., Schmidt, D., Krull, A., Jug, \"\n            \"F.: Denoiseg: joint denoising and segmentation. In: European \"\n            \"Conference on Computer Vision (ECCV). pp. 324-337. Springer (2020) 8, 9\",\n            files=[\n                f\"Flywing_n{noise_level.value}/train/train_data.npz\",\n                f\"Flywing_n{noise_level.value}/test/test_data.npz\",\n            ],\n            size=self._get_size(noise_level),\n            tags=[\"denoising\", \"segmentation\", \"membrane\", \"fluorescence\"],\n        )\n\n    @staticmethod\n    def _get_url(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"https://zenodo.org/record/5156991/files/Flywing_n0.zip?download=1\"\n        elif noise == NoiseLevel.N10:\n            return \"https://zenodo.org/record/5156993/files/Flywing_n10.zip?download=1\"\n        else:\n            return \"https://zenodo.org/record/5156995/files/Flywing_n20.zip?download=1\"\n\n    @staticmethod\n    def _get_hash(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"3fb49ba44e7e3e20b4fc3c77754f1bbff7184af7f343f23653f258d50e5d5aca\"\n        elif noise == NoiseLevel.N10:\n            return \"c599981b0900e6b43f0a742f84a5fde664373600dc5334f537b61a76a7be2a3c\"\n        else:\n            return \"604b3a3a081eaa57ee25d708bc9b76b85d05235ba09d7c2b25b171e201ea966f\"\n\n    @staticmethod\n    def _get_size(noise: NoiseLevel) -&gt; float:\n        if noise == NoiseLevel.N0:\n            return 47.0\n        elif noise == NoiseLevel.N10:\n            return 282.0\n        else:\n            return 293.0\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.SegFlywing.__init__","title":"<code>__init__(noise_level=NoiseLevel.N0)</code>","text":"<p>Initialize a Flywing instance.</p> <p>Parameters:</p> Name Type Description Default <code>noise_level</code> <code>NoiseLevel</code> <p>Noise level of the dataset, by default NoiseLevel.N0</p> <code>N0</code> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n    \"\"\"Initialize a Flywing instance.\n\n    Parameters\n    ----------\n    noise_level : NoiseLevel, optional\n        Noise level of the dataset, by default NoiseLevel.N0\n    \"\"\"\n    super().__init__(\n        portfolio=DENOISEG,\n        noise_level=noise_level,\n        name=f\"Flywing_n{noise_level.value}\",\n        url=self._get_url(noise_level),\n        file_name=f\"Flywing_n{noise_level.value}.zip\",\n        sha256=self._get_hash(noise_level),\n        description=\"This dataset consist of 1428 training and 252 \"\n        \"validation patches of a membrane labeled fly wing. The test set \"\n        \"is comprised of 50 additional images.\",\n        license=\"CC BY-SA 4.0\",\n        citation=\"Buchholz, T.O., Prakash, M., Schmidt, D., Krull, A., Jug, \"\n        \"F.: Denoiseg: joint denoising and segmentation. In: European \"\n        \"Conference on Computer Vision (ECCV). pp. 324-337. Springer (2020) 8, 9\",\n        files=[\n            f\"Flywing_n{noise_level.value}/train/train_data.npz\",\n            f\"Flywing_n{noise_level.value}/test/test_data.npz\",\n        ],\n        size=self._get_size(noise_level),\n        tags=[\"denoising\", \"segmentation\", \"membrane\", \"fluorescence\"],\n    )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/","title":"denoising_datasets","text":""},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.Convallaria","title":"<code>Convallaria</code>","text":"<p>             Bases: <code>PortfolioEntry</code></p> <p>Convallaria dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. files (list[str]): List of files in the dataset. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class Convallaria(PortfolioEntry):\n    \"\"\"Convallaria dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        files (list[str]): List of files in the dataset.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"Convallaria\",\n            url=\"https://cloud.mpi-cbg.de/index.php/s/BE8raMtHQlgLDF3/download\",\n            file_name=\"Convallaria_diaphragm.zip\",\n            sha256=\"8a2ac3e2792334c833ee8a3ca449fc14eada18145f9d56fa2cb40f462c2e8909\",\n            description=\"Image of a convallaria flower (35x692x520 pixels).\\n\"\n            \"The image also comes with a defocused image in order to allow \\n\"\n            \"estimating the noise distribution.\",\n            license=\"CC-BY-4.0\",\n            citation=\"Krull, A., Vi\u010dar, T., Prakash, M., Lalit, M., &amp; Jug, F. (2020). \"\n            \"Probabilistic noise2void: Unsupervised content-aware denoising. Frontiers\"\n            \" in Computer Science, 2, 5.\",\n            files=[\n                \"Convallaria_diaphragm/20190520_tl_25um_50msec_05pc_488_130EM_Conv.tif\",\n                \"Convallaria_diaphragm/20190726_tl_50um_500msec_wf_130EM_FD.tif\",\n            ],\n            size=344.0,\n            tags=[\"denoising\", \"membrane\", \"fluorescence\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.Flywing","title":"<code>Flywing</code>","text":"<p>             Bases: <code>PortfolioEntry</code></p> <p>Flywing dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. files (list[str]): List of files in the dataset. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class Flywing(PortfolioEntry):\n    \"\"\"Flywing dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        files (list[str]): List of files in the dataset.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"Flywing\",\n            url=\"https://download.fht.org/jug/n2v/flywing-data.zip\",\n            file_name=\"flywing-data.zip\",\n            sha256=\"01106b6dc096c423babfca47ef27059a01c2ca053769da06e8649381089a559f\",\n            description=\"Image of a membrane-labeled fly wing (35x692x520 pixels).\",\n            license=\"CC-BY-4.0\",\n            citation=\"Buchholz, T.O., Prakash, M., Schmidt, D., Krull, A., Jug, \"\n            \"F.: Denoiseg: joint denoising and segmentation. In: European \"\n            \"Conference on Computer Vision (ECCV). pp. 324-337. Springer (2020) 8, 9\",\n            files=[\n                \"flywing.tif\",\n            ],\n            size=10.2,\n            tags=[\"denoising\", \"membrane\", \"fluorescence\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.N2V_BSD68","title":"<code>N2V_BSD68</code>","text":"<p>             Bases: <code>PortfolioEntry</code></p> <p>BSD68 dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. files (list[str]): List of files in the dataset. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class N2V_BSD68(PortfolioEntry):\n    \"\"\"BSD68 dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        files (list[str]): List of files in the dataset.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"N2V_BSD68\",\n            url=\"https://download.fht.org/jug/n2v/BSD68_reproducibility_data.zip\",\n            file_name=\"BSD68_reproducibility_data.zip\",\n            sha256=\"32c66d41196c9cafff465f3c7c42730f851c24766f70383672e18b8832ea8e55\",\n            description=\"This dataset is taken from K. Zhang et al (TIP, 2017). \\n\"\n            \"It consists of 400 gray-scale 180x180 images (cropped from the \"\n            \"BSD dataset) and splitted between training and validation, and \"\n            \"68 gray-scale test images (BSD68).\\n\"\n            \"All images were corrupted with Gaussian noise with standard \"\n            \"deviation of 25 pixels. The test dataset contains the uncorrupted \"\n            \"images as well.\\n\"\n            \"Original dataset: \"\n            \"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/\",\n            license=\"Unknown\",\n            citation='D. Martin, C. Fowlkes, D. Tal and J. Malik, \"A database of '\n            \"human segmented natural images and its application to \"\n            \"evaluating segmentation algorithms and measuring ecological \"\n            'statistics,\" Proceedings Eighth IEEE International '\n            \"Conference on Computer Vision. ICCV 2001, Vancouver, BC, \"\n            \"Canada, 2001, pp. 416-423 vol.2, doi: \"\n            \"10.1109/ICCV.2001.937655.\",\n            files=[\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_1.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_2.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_3.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_4.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_5.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_6.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_7.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_8.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_9.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_10.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_11.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_12.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_13.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_14.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_15.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_16.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_17.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_18.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_19.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_20.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_21.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_22.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_23.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_24.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_25.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_26.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_27.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_28.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_29.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_30.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_31.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_32.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_33.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_34.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_35.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_36.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_37.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_38.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_39.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_40.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_41.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_42.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_43.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_44.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_45.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_46.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_47.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_48.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_49.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_50.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_51.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_52.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_53.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_54.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_55.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_56.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_57.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_58.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_59.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_60.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_61.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_62.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_63.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_64.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_65.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_66.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_67.tiff\",\n                \"BSD68_reproducibility_data/test/images/bsd68_gaussian25_68.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_1.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_2.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_3.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_4.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_5.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_6.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_7.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_8.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_9.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_10.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_11.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_12.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_13.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_14.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_15.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_16.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_17.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_18.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_19.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_20.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_21.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_22.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_23.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_24.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_25.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_26.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_27.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_28.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_29.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_30.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_31.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_32.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_33.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_34.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_35.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_36.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_37.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_38.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_39.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_40.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_41.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_42.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_43.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_44.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_45.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_46.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_47.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_48.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_49.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_50.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_51.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_52.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_53.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_54.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_55.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_56.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_57.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_58.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_59.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_60.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_61.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_62.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_63.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_64.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_65.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_66.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_67.tiff\",\n                \"BSD68_reproducibility_data/test/gt/bsd68_groundtruth_68.tiff\",\n                \"BSD68_reproducibility_data/train/DCNN400_train_gaussian25.tiff\",\n                \"BSD68_reproducibility_data/val/DCNN400_validation_gaussian25.tiff\",\n            ],\n            size=395.0,\n            tags=[\"denoising\", \"natural images\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.N2V_RGB","title":"<code>N2V_RGB</code>","text":"<p>             Bases: <code>PortfolioEntry</code></p> <p>RGB dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. files (list[str]): List of files in the dataset. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class N2V_RGB(PortfolioEntry):\n    \"\"\"RGB dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        files (list[str]): List of files in the dataset.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"N2V_RGB\",\n            url=\"https://download.fht.org/jug/n2v/RGB.zip\",\n            file_name=\"RGB.zip\",\n            sha256=\"4c2010c6b5c253d3a580afe744cbff969d387617c9dde29fea4463636d285657\",\n            description=\"Banner of the CVPR 2019 conference with extra noise.\",\n            license=\"CC-BY-4.0\",\n            citation='A. Krull, T.-O. Buchholz and F. Jug, \"Noise2Void - Learning '\n            'Denoising From Single Noisy Images,\" 2019 IEEE/CVF '\n            \"Conference on Computer Vision and Pattern Recognition (CVPR),\"\n            \" 2019, pp. 2124-2132\",\n            files=[\n                \"longBeach.png\",\n            ],\n            size=10.4,\n            tags=[\"denoising\", \"natural images\", \"RGB\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.N2V_SEM","title":"<code>N2V_SEM</code>","text":"<p>             Bases: <code>PortfolioEntry</code></p> <p>SEM dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. files (list[str]): List of files in the dataset. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class N2V_SEM(PortfolioEntry):\n    \"\"\"SEM dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        files (list[str]): List of files in the dataset.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"N2V_SEM\",\n            url=\"https://download.fht.org/jug/n2v/SEM.zip\",\n            file_name=\"SEM.zip\",\n            sha256=\"7600a17c3dbd4992ea547be12458640c21e797eef6a9f776f36ba5890f26855d\",\n            description=\"Cropped images from a SEM dataset from T.-O. Buchholz et al \"\n            \"(Methods Cell Biol, 2020).\",\n            license=\"CC-BY-4.0\",\n            citation=\"T.-O. Buchholz, A. Krull, R. Shahidi, G. Pigino, G. J\u00e9kely, \"\n            'F. Jug, \"Content-aware image restoration for electron '\n            'microscopy\", Methods Cell Biol 152, 277-289',\n            files=[\"train.tif\", \"validation.tif\"],\n            size=13.0,\n            tags=[\"denoising\", \"electron microscopy\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/","title":"portfolio","text":""},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg","title":"<code>DenoiSeg</code>","text":"<p>             Bases: <code>IterablePortfolio</code></p> <p>An IterablePortfolio of DenoiSeg datasets.</p> <p>Attributes:</p> Name Type Description <code>DSB2018_n0 (DSB2018)</code> <code>DSB2018 dataset with noise level 0.</code> <p>DSB2018_n10 (DSB2018): DSB2018 dataset with noise level 10. DSB2018_n20 (DSB2018): DSB2018 dataset with noise level 20. Flywing_n0 (SegFlywing): Flywing dataset with noise level 0. Flywing_n10 (SegFlywing): Flywing dataset with noise level 10. Flywing_n20 (SegFlywing): Flywing dataset with noise level 20. MouseNuclei_n0 (MouseNuclei): MouseNuclei dataset with noise level 0. MouseNuclei_n10 (MouseNuclei): MouseNuclei dataset with noise level 10. MouseNuclei_n20 (MouseNuclei): MouseNuclei dataset with noise level 20.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>class DenoiSeg(IterablePortfolio):\n    \"\"\"An IterablePortfolio of DenoiSeg datasets.\n\n    Attributes\n    ----------\n        DSB2018_n0 (DSB2018): DSB2018 dataset with noise level 0.\n        DSB2018_n10 (DSB2018): DSB2018 dataset with noise level 10.\n        DSB2018_n20 (DSB2018): DSB2018 dataset with noise level 20.\n        Flywing_n0 (SegFlywing): Flywing dataset with noise level 0.\n        Flywing_n10 (SegFlywing): Flywing dataset with noise level 10.\n        Flywing_n20 (SegFlywing): Flywing dataset with noise level 20.\n        MouseNuclei_n0 (MouseNuclei): MouseNuclei dataset with noise level 0.\n        MouseNuclei_n10 (MouseNuclei): MouseNuclei dataset with noise level 10.\n        MouseNuclei_n20 (MouseNuclei): MouseNuclei dataset with noise level 20.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._DSB2018_n0 = DSB2018(NoiseLevel.N0)\n        self._DSB2018_n10 = DSB2018(NoiseLevel.N10)\n        self._DSB2018_n20 = DSB2018(NoiseLevel.N20)\n        self._SegFlywing_n0 = SegFlywing(NoiseLevel.N0)\n        self._SegFlywing_n10 = SegFlywing(NoiseLevel.N10)\n        self._SegFlywing_n20 = SegFlywing(NoiseLevel.N20)\n        self._MouseNuclei_n0 = MouseNuclei(NoiseLevel.N0)\n        self._MouseNuclei_n10 = MouseNuclei(NoiseLevel.N10)\n        self._MouseNuclei_n20 = MouseNuclei(NoiseLevel.N20)\n\n        super().__init__(DENOISEG)\n\n    @property\n    def DSB2018_n0(self) -&gt; DSB2018:\n        \"\"\"DSB2018 dataset with noise level 0.\n\n        Returns\n        -------\n        DSB2018\n            DSB2018 dataset with noise level 0.\n        \"\"\"\n        return self._DSB2018_n0\n\n    @property\n    def DSB2018_n10(self) -&gt; DSB2018:\n        \"\"\"DSB2018 dataset with noise level 10.\n\n        Returns\n        -------\n        DSB2018\n            DSB2018 dataset with noise level 10.\n        \"\"\"\n        return self._DSB2018_n10\n\n    @property\n    def DSB2018_n20(self) -&gt; DSB2018:\n        \"\"\"DSB2018 dataset with noise level 20.\n\n        Returns\n        -------\n        DSB2018\n            DSB2018 dataset with noise level 20.\n        \"\"\"\n        return self._DSB2018_n20\n\n    @property\n    def Flywing_n0(self) -&gt; SegFlywing:\n        \"\"\"Flywing dataset with noise level 0.\n\n        Returns\n        -------\n        SegFlywing\n            Flywing dataset with noise level 0.\n        \"\"\"\n        return self._SegFlywing_n0\n\n    @property\n    def Flywing_n10(self) -&gt; SegFlywing:\n        \"\"\"Flywing dataset with noise level 10.\n\n        Returns\n        -------\n        SegFlywing\n            Flywing dataset with noise level 10.\n        \"\"\"\n        return self._SegFlywing_n10\n\n    @property\n    def Flywing_n20(self) -&gt; SegFlywing:\n        \"\"\"Flywing dataset with noise level 20.\n\n        Returns\n        -------\n        SegFlywing\n            Flywing dataset with noise level 20.\n        \"\"\"\n        return self._SegFlywing_n20\n\n    @property\n    def MouseNuclei_n0(self) -&gt; MouseNuclei:\n        \"\"\"MouseNuclei dataset with noise level 0.\n\n        Returns\n        -------\n        MouseNuclei\n            MouseNuclei dataset with noise level 0.\n        \"\"\"\n        return self._MouseNuclei_n0\n\n    @property\n    def MouseNuclei_n10(self) -&gt; MouseNuclei:\n        \"\"\"MouseNuclei dataset with noise level 10.\n\n        Returns\n        -------\n        MouseNuclei\n            MouseNuclei dataset with noise level 10.\n        \"\"\"\n        return self._MouseNuclei_n10\n\n    @property\n    def MouseNuclei_n20(self) -&gt; MouseNuclei:\n        \"\"\"MouseNuclei dataset with noise level 20.\n\n        Returns\n        -------\n        MouseNuclei\n            MouseNuclei dataset with noise level 20.\n        \"\"\"\n        return self._MouseNuclei_n20\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.DSB2018_n0","title":"<code>DSB2018_n0: DSB2018</code>  <code>property</code>","text":"<p>DSB2018 dataset with noise level 0.</p> <p>Returns:</p> Type Description <code>DSB2018</code> <p>DSB2018 dataset with noise level 0.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.DSB2018_n10","title":"<code>DSB2018_n10: DSB2018</code>  <code>property</code>","text":"<p>DSB2018 dataset with noise level 10.</p> <p>Returns:</p> Type Description <code>DSB2018</code> <p>DSB2018 dataset with noise level 10.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.DSB2018_n20","title":"<code>DSB2018_n20: DSB2018</code>  <code>property</code>","text":"<p>DSB2018 dataset with noise level 20.</p> <p>Returns:</p> Type Description <code>DSB2018</code> <p>DSB2018 dataset with noise level 20.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.Flywing_n0","title":"<code>Flywing_n0: SegFlywing</code>  <code>property</code>","text":"<p>Flywing dataset with noise level 0.</p> <p>Returns:</p> Type Description <code>SegFlywing</code> <p>Flywing dataset with noise level 0.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.Flywing_n10","title":"<code>Flywing_n10: SegFlywing</code>  <code>property</code>","text":"<p>Flywing dataset with noise level 10.</p> <p>Returns:</p> Type Description <code>SegFlywing</code> <p>Flywing dataset with noise level 10.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.Flywing_n20","title":"<code>Flywing_n20: SegFlywing</code>  <code>property</code>","text":"<p>Flywing dataset with noise level 20.</p> <p>Returns:</p> Type Description <code>SegFlywing</code> <p>Flywing dataset with noise level 20.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.MouseNuclei_n0","title":"<code>MouseNuclei_n0: MouseNuclei</code>  <code>property</code>","text":"<p>MouseNuclei dataset with noise level 0.</p> <p>Returns:</p> Type Description <code>MouseNuclei</code> <p>MouseNuclei dataset with noise level 0.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.MouseNuclei_n10","title":"<code>MouseNuclei_n10: MouseNuclei</code>  <code>property</code>","text":"<p>MouseNuclei dataset with noise level 10.</p> <p>Returns:</p> Type Description <code>MouseNuclei</code> <p>MouseNuclei dataset with noise level 10.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.MouseNuclei_n20","title":"<code>MouseNuclei_n20: MouseNuclei</code>  <code>property</code>","text":"<p>MouseNuclei dataset with noise level 20.</p> <p>Returns:</p> Type Description <code>MouseNuclei</code> <p>MouseNuclei dataset with noise level 20.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising","title":"<code>Denoising</code>","text":"<p>             Bases: <code>IterablePortfolio</code></p> <p>An IterablePortfolio of denoising datasets.</p> <p>Attributes:</p> Name Type Description <code>N2V_BSD68 (N2V_BSD68)</code> <code>BSD68 dataset.</code> <code>N2V_SEM (N2V_SEM)</code> <code>SEM dataset.</code> <code>N2V_RGB (N2V_RGB)</code> <code>RGB dataset.</code> <code>flywing (Flywing)</code> <code>Flywing dataset.</code> <code>Convallaria (Convallaria)</code> <code>Convallaria dataset.</code> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>class Denoising(IterablePortfolio):\n    \"\"\"An IterablePortfolio of denoising datasets.\n\n    Attributes\n    ----------\n    N2V_BSD68 (N2V_BSD68): BSD68 dataset.\n    N2V_SEM (N2V_SEM): SEM dataset.\n    N2V_RGB (N2V_RGB): RGB dataset.\n    flywing (Flywing): Flywing dataset.\n    Convallaria (Convallaria): Convallaria dataset.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._N2V_BSD68 = N2V_BSD68()\n        self._N2V_SEM = N2V_SEM()\n        self._N2V_RGB = N2V_RGB()\n        self._flywing = Flywing()\n        self._Convallaria = Convallaria()\n\n        super().__init__(DENOISING)\n\n    @property\n    def N2V_BSD68(self) -&gt; N2V_BSD68:\n        \"\"\"BSD68 dataset.\n\n        Returns\n        -------\n        N2V_BSD68\n            BSD68 dataset.\n        \"\"\"\n        return self._N2V_BSD68\n\n    @property\n    def N2V_SEM(self) -&gt; N2V_SEM:\n        \"\"\"SEM dataset.\n\n        Returns\n        -------\n        N2V_SEM\n            SEM dataset.\n        \"\"\"\n        return self._N2V_SEM\n\n    @property\n    def N2V_RGB(self) -&gt; N2V_RGB:\n        \"\"\"RGB dataset.\n\n        Returns\n        -------\n        N2V_RGB\n            RGB dataset.\n        \"\"\"\n        return self._N2V_RGB\n\n    @property\n    def Flywing(self) -&gt; Flywing:\n        \"\"\"Flywing dataset.\n\n        Returns\n        -------\n        Flywing\n            Flywing dataset.\n        \"\"\"\n        return self._flywing\n\n    @property\n    def Convallaria(self) -&gt; Convallaria:\n        \"\"\"Convallaria dataset.\n\n        Returns\n        -------\n        Convallaria\n            Convallaria dataset.\n        \"\"\"\n        return self._Convallaria\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.Convallaria","title":"<code>Convallaria: Convallaria</code>  <code>property</code>","text":"<p>Convallaria dataset.</p> <p>Returns:</p> Type Description <code>Convallaria</code> <p>Convallaria dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.Flywing","title":"<code>Flywing: Flywing</code>  <code>property</code>","text":"<p>Flywing dataset.</p> <p>Returns:</p> Type Description <code>Flywing</code> <p>Flywing dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.N2V_BSD68","title":"<code>N2V_BSD68: N2V_BSD68</code>  <code>property</code>","text":"<p>BSD68 dataset.</p> <p>Returns:</p> Type Description <code>N2V_BSD68</code> <p>BSD68 dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.N2V_RGB","title":"<code>N2V_RGB: N2V_RGB</code>  <code>property</code>","text":"<p>RGB dataset.</p> <p>Returns:</p> Type Description <code>N2V_RGB</code> <p>RGB dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.N2V_SEM","title":"<code>N2V_SEM: N2V_SEM</code>  <code>property</code>","text":"<p>SEM dataset.</p> <p>Returns:</p> Type Description <code>N2V_SEM</code> <p>SEM dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.ItarablePortfolioEncoder","title":"<code>ItarablePortfolioEncoder</code>","text":"<p>             Bases: <code>JSONEncoder</code></p> <p>Portfolio encoder class.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>class ItarablePortfolioEncoder(JSONEncoder):\n    \"\"\"Portfolio encoder class.\"\"\"\n\n    def default(self, o: IterablePortfolio) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Default method for json export.\n\n        Parameters\n        ----------\n        o : IterablePortfolio\n            Portfolio to export.\n\n        Returns\n        -------\n        dict[str, str]\n            Dictionary representation of the portfolio.\n        \"\"\"\n        return o.as_dict()\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.ItarablePortfolioEncoder.default","title":"<code>default(o)</code>","text":"<p>Default method for json export.</p> <p>Parameters:</p> Name Type Description Default <code>o</code> <code>IterablePortfolio</code> <p>Portfolio to export.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary representation of the portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def default(self, o: IterablePortfolio) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Default method for json export.\n\n    Parameters\n    ----------\n    o : IterablePortfolio\n        Portfolio to export.\n\n    Returns\n    -------\n    dict[str, str]\n        Dictionary representation of the portfolio.\n    \"\"\"\n    return o.as_dict()\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio","title":"<code>IterablePortfolio</code>","text":"<p>Iterable portfolio class.</p> <p>Subclass this class and add PortfolioEntry objects as attributes.</p> <p>Attributes:</p> Name Type Description <code>_name</code> <code>str</code> <p>Name of the portfolio.</p> <code>_datasets</code> <code>List[PortfolioEntry]</code> <p>List of datasets in the portfolio.</p> <code>_current_index</code> <code>int</code> <code>Current index of the iterator.</code> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>class IterablePortfolio:\n    \"\"\"Iterable portfolio class.\n\n    Subclass this class and add PortfolioEntry objects as attributes.\n\n\n    Attributes\n    ----------\n    _name : str\n        Name of the portfolio.\n    _datasets : List[PortfolioEntry]\n        List of datasets in the portfolio.\n    _current_index : int\n    Current index of the iterator.\n    \"\"\"\n\n    def __init__(self, name: str) -&gt; None:\n        self._name = name\n\n        # create list of datasets\n        datasets = []\n        for dataset in vars(self).values():\n            if isinstance(dataset, PortfolioEntry):\n                datasets.append(dataset)\n\n        # record datasets\n        self._datasets = datasets\n        self._current_index = 0\n\n    def __iter__(self) -&gt; IterablePortfolio:\n        \"\"\"Iterator method.\n\n        Returns\n        -------\n        IterablePortfolio\n            Iterator over the portfolio.\n        \"\"\"\n        return self\n\n    def __next__(self) -&gt; PortfolioEntry:\n        \"\"\"Next method.\n\n        Returns\n        -------\n        PortfolioEntry\n            Next dataset in the portfolio.\n        \"\"\"\n        if self._current_index &lt; len(self._datasets):\n            next_dataset = self._datasets[self._current_index]\n            self._current_index += 1\n            return next_dataset\n        raise StopIteration(\"The iterator does not have any more elements.\")\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Name of the portfolio.\n\n        Returns\n        -------\n        str\n            Name of the portfolio.\n        \"\"\"\n        return self._name\n\n    def list_datasets(self) -&gt; list[str]:\n        \"\"\"List datasets in the portfolio using friendly names.\n\n        The friendly names are the names of the portfolio entries, rather\n        than that of the IterablePortfolio attributes.\n\n        Returns\n        -------\n        list[str]\n            List of datasets in the portfolio.\n        \"\"\"\n        attributes = []\n\n        # for each attribute\n        for attribute in vars(self).values():\n            if isinstance(attribute, PortfolioEntry):\n                attributes.append(attribute.name)\n\n        return attributes\n\n    def as_dict(self) -&gt; dict:\n        \"\"\"Dictionary representation of a portfolio.\n\n        Used to serialize the class to json, with friendly names as entries.\n\n        Returns\n        -------\n        dict[str]\n            Dictionary representation of the DenoiSeg portfolio.\n        \"\"\"\n        entries = {}\n\n        # for each attribute\n        for attribute in vars(self).values():\n            # if the attribute is a PortfolioEntry\n            if isinstance(attribute, PortfolioEntry):\n                # add the attribute to the entries dictionary\n                entries[attribute.name] = {\n                    \"URL\": attribute.url,\n                    \"Description\": attribute.description,\n                    \"Citation\": attribute.citation,\n                    \"License\": attribute.license,\n                    \"Hash\": attribute.hash,\n                    \"File size\": f\"{attribute.size} MB\",\n                    \"Tags\": attribute.tags,\n                }\n        return entries\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of a portfolio.\n\n        Returns\n        -------\n        str\n        String representation of a portfolio.\n        \"\"\"\n        return f\"{self.name} datasets: {self.list_datasets()}\"\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.name","title":"<code>name: str</code>  <code>property</code>","text":"<p>Name of the portfolio.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the portfolio.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterator method.</p> <p>Returns:</p> Type Description <code>IterablePortfolio</code> <p>Iterator over the portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def __iter__(self) -&gt; IterablePortfolio:\n    \"\"\"Iterator method.\n\n    Returns\n    -------\n    IterablePortfolio\n        Iterator over the portfolio.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.__next__","title":"<code>__next__()</code>","text":"<p>Next method.</p> <p>Returns:</p> Type Description <code>PortfolioEntry</code> <p>Next dataset in the portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def __next__(self) -&gt; PortfolioEntry:\n    \"\"\"Next method.\n\n    Returns\n    -------\n    PortfolioEntry\n        Next dataset in the portfolio.\n    \"\"\"\n    if self._current_index &lt; len(self._datasets):\n        next_dataset = self._datasets[self._current_index]\n        self._current_index += 1\n        return next_dataset\n    raise StopIteration(\"The iterator does not have any more elements.\")\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.__str__","title":"<code>__str__()</code>","text":"<p>String representation of a portfolio.</p> <p>Returns:</p> Type Description <code>str</code> <code>String representation of a portfolio.</code> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of a portfolio.\n\n    Returns\n    -------\n    str\n    String representation of a portfolio.\n    \"\"\"\n    return f\"{self.name} datasets: {self.list_datasets()}\"\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.as_dict","title":"<code>as_dict()</code>","text":"<p>Dictionary representation of a portfolio.</p> <p>Used to serialize the class to json, with friendly names as entries.</p> <p>Returns:</p> Type Description <code>dict[str]</code> <p>Dictionary representation of the DenoiSeg portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def as_dict(self) -&gt; dict:\n    \"\"\"Dictionary representation of a portfolio.\n\n    Used to serialize the class to json, with friendly names as entries.\n\n    Returns\n    -------\n    dict[str]\n        Dictionary representation of the DenoiSeg portfolio.\n    \"\"\"\n    entries = {}\n\n    # for each attribute\n    for attribute in vars(self).values():\n        # if the attribute is a PortfolioEntry\n        if isinstance(attribute, PortfolioEntry):\n            # add the attribute to the entries dictionary\n            entries[attribute.name] = {\n                \"URL\": attribute.url,\n                \"Description\": attribute.description,\n                \"Citation\": attribute.citation,\n                \"License\": attribute.license,\n                \"Hash\": attribute.hash,\n                \"File size\": f\"{attribute.size} MB\",\n                \"Tags\": attribute.tags,\n            }\n    return entries\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.list_datasets","title":"<code>list_datasets()</code>","text":"<p>List datasets in the portfolio using friendly names.</p> <p>The friendly names are the names of the portfolio entries, rather than that of the IterablePortfolio attributes.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of datasets in the portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def list_datasets(self) -&gt; list[str]:\n    \"\"\"List datasets in the portfolio using friendly names.\n\n    The friendly names are the names of the portfolio entries, rather\n    than that of the IterablePortfolio attributes.\n\n    Returns\n    -------\n    list[str]\n        List of datasets in the portfolio.\n    \"\"\"\n    attributes = []\n\n    # for each attribute\n    for attribute in vars(self).values():\n        if isinstance(attribute, PortfolioEntry):\n            attributes.append(attribute.name)\n\n    return attributes\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager","title":"<code>PortfolioManager</code>  <code>dataclass</code>","text":"<p>Portfolio of datasets.</p> <p>Attributes:</p> Name Type Description <code>denoising (Denoising)</code> <code>Denoising datasets.</code> <code>denoiseg (DenoiSeg)</code> <code>DenoiSeg datasets.</code> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>@dataclass\nclass PortfolioManager:\n    \"\"\"Portfolio of datasets.\n\n    Attributes\n    ----------\n    denoising (Denoising): Denoising datasets.\n    denoiseg (DenoiSeg): DenoiSeg datasets.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._denoising = Denoising()\n        self._denoiseg = DenoiSeg()\n        # self._segmentation = Segmentation()\n\n    @property\n    def denoising(self) -&gt; Denoising:\n        \"\"\"Denoising datasets.\n\n        Returns\n        -------\n        Denoising\n            Denoising datasets.\n        \"\"\"\n        return self._denoising\n\n    @property\n    def denoiseg(self) -&gt; DenoiSeg:\n        \"\"\"DenoiSeg datasets.\n\n        Returns\n        -------\n        DenoiSeg\n            DenoiSeg datasets.\n        \"\"\"\n        return self._denoiseg\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the portfolio.\n\n        This method allows having a frendly representation of the portfolio as string.\n\n        Returns\n        -------\n        str\n            String representation of the portfolio.\n        \"\"\"\n        return (\n            f\"Portfolio:\\n\"\n            f\"Denoising datasets: {self.denoising.list_datasets()}\\n\"\n            f\"DenoiSeg datasets: {self.denoiseg.list_datasets()}\"\n        )\n\n    def as_dict(self) -&gt; dict[str, IterablePortfolio]:\n        \"\"\"Portfolio as dictionary.\n\n        This method is used during json serialization to maintain human readable\n        keys.\n\n        Returns\n        -------\n        dict[str, IterablePortfolio]\n            Portfolio as dictionary.\n        \"\"\"\n        attributes = {}\n\n        for attribute in vars(self).values():\n            if isinstance(attribute, IterablePortfolio):\n                attributes[attribute.name] = attribute\n\n        return attributes\n\n    def to_json(self, path: str | Path) -&gt; None:\n        \"\"\"Save portfolio to json file using the `as_dict` method.\n\n        Parameters\n        ----------\n        path : str or Path\n            Path to json file.\n        \"\"\"\n        with open(path, \"w\") as f:\n            json.dump(self.as_dict(), f, indent=4, cls=ItarablePortfolioEncoder)\n\n    def to_registry(self, path: str | Path) -&gt; None:\n        \"\"\"Save portfolio as registry (Pooch).\n\n        See: https://www.fatiando.org/pooch/latest/registry-files.html\n\n        Parameters\n        ----------\n        path : str or Path\n            Path to json file.\n        \"\"\"\n        portfolios = self.as_dict()\n        with open(path, \"w\") as file:\n            file.write(\"# Portfolio datasets - pooch registry\\n\")\n            file.write(\"# Generated by running \" \"scripts/update_registry.py\\n\\n\")\n\n            # write each portfolio\n            for key in portfolios.keys():\n                file.write(f\"# {key} \\n\")\n                for entry in portfolios[key]:\n                    file.write(\n                        f\"{entry.get_registry_name()} \" f\"{entry.hash} {entry.url}\\n\"\n                    )\n                file.write(\"\\n\")\n\n            # add pale blue dot for testing purposes\n            file.write(\"# Test sample\\n\")\n            pale_blue_dot = PaleBlueDot()\n            file.write(\n                f\"{pale_blue_dot.get_registry_name()} \"\n                f\"{pale_blue_dot.hash} {pale_blue_dot.url}\\n\"\n            )\n            pale_blue_dot_zip = PaleBlueDotZip()\n            file.write(\n                f\"{pale_blue_dot_zip.get_registry_name()} \"\n                f\"{pale_blue_dot_zip.hash} {pale_blue_dot_zip.url}\\n\"\n            )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.denoiseg","title":"<code>denoiseg: DenoiSeg</code>  <code>property</code>","text":"<p>DenoiSeg datasets.</p> <p>Returns:</p> Type Description <code>DenoiSeg</code> <p>DenoiSeg datasets.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.denoising","title":"<code>denoising: Denoising</code>  <code>property</code>","text":"<p>Denoising datasets.</p> <p>Returns:</p> Type Description <code>Denoising</code> <p>Denoising datasets.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the portfolio.</p> <p>This method allows having a frendly representation of the portfolio as string.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the portfolio.\n\n    This method allows having a frendly representation of the portfolio as string.\n\n    Returns\n    -------\n    str\n        String representation of the portfolio.\n    \"\"\"\n    return (\n        f\"Portfolio:\\n\"\n        f\"Denoising datasets: {self.denoising.list_datasets()}\\n\"\n        f\"DenoiSeg datasets: {self.denoiseg.list_datasets()}\"\n    )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.as_dict","title":"<code>as_dict()</code>","text":"<p>Portfolio as dictionary.</p> <p>This method is used during json serialization to maintain human readable keys.</p> <p>Returns:</p> Type Description <code>dict[str, IterablePortfolio]</code> <p>Portfolio as dictionary.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def as_dict(self) -&gt; dict[str, IterablePortfolio]:\n    \"\"\"Portfolio as dictionary.\n\n    This method is used during json serialization to maintain human readable\n    keys.\n\n    Returns\n    -------\n    dict[str, IterablePortfolio]\n        Portfolio as dictionary.\n    \"\"\"\n    attributes = {}\n\n    for attribute in vars(self).values():\n        if isinstance(attribute, IterablePortfolio):\n            attributes[attribute.name] = attribute\n\n    return attributes\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.to_json","title":"<code>to_json(path)</code>","text":"<p>Save portfolio to json file using the <code>as_dict</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Path to json file.</p> required Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def to_json(self, path: str | Path) -&gt; None:\n    \"\"\"Save portfolio to json file using the `as_dict` method.\n\n    Parameters\n    ----------\n    path : str or Path\n        Path to json file.\n    \"\"\"\n    with open(path, \"w\") as f:\n        json.dump(self.as_dict(), f, indent=4, cls=ItarablePortfolioEncoder)\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.to_registry","title":"<code>to_registry(path)</code>","text":"<p>Save portfolio as registry (Pooch).</p> <p>See: https://www.fatiando.org/pooch/latest/registry-files.html</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Path to json file.</p> required Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def to_registry(self, path: str | Path) -&gt; None:\n    \"\"\"Save portfolio as registry (Pooch).\n\n    See: https://www.fatiando.org/pooch/latest/registry-files.html\n\n    Parameters\n    ----------\n    path : str or Path\n        Path to json file.\n    \"\"\"\n    portfolios = self.as_dict()\n    with open(path, \"w\") as file:\n        file.write(\"# Portfolio datasets - pooch registry\\n\")\n        file.write(\"# Generated by running \" \"scripts/update_registry.py\\n\\n\")\n\n        # write each portfolio\n        for key in portfolios.keys():\n            file.write(f\"# {key} \\n\")\n            for entry in portfolios[key]:\n                file.write(\n                    f\"{entry.get_registry_name()} \" f\"{entry.hash} {entry.url}\\n\"\n                )\n            file.write(\"\\n\")\n\n        # add pale blue dot for testing purposes\n        file.write(\"# Test sample\\n\")\n        pale_blue_dot = PaleBlueDot()\n        file.write(\n            f\"{pale_blue_dot.get_registry_name()} \"\n            f\"{pale_blue_dot.hash} {pale_blue_dot.url}\\n\"\n        )\n        pale_blue_dot_zip = PaleBlueDotZip()\n        file.write(\n            f\"{pale_blue_dot_zip.get_registry_name()} \"\n            f\"{pale_blue_dot_zip.hash} {pale_blue_dot_zip.url}\\n\"\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.update_registry","title":"<code>update_registry(path=None)</code>","text":"<p>Update the registry.txt file.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def update_registry(path: str | Path | None = None) -&gt; None:\n    \"\"\"Update the registry.txt file.\"\"\"\n    if path is None:\n        path = get_registry_path()\n\n    portfolio = PortfolioManager()\n    portfolio.to_registry(path)\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio_entry/","title":"portfolio_entry","text":""},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry","title":"<code>PortfolioEntry</code>","text":"<p>Base class for portfolio entries.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. files (list[str]): List of files in the dataset. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/portfolio_entry.py</code> <pre><code>class PortfolioEntry:\n    \"\"\"Base class for portfolio entries.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        files (list[str]): List of files in the dataset.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(\n        self,\n        portfolio: str,\n        name: str,\n        url: str,\n        description: str,\n        license: str,\n        citation: str,\n        file_name: str,\n        sha256: str,\n        files: List[str],\n        size: float,\n        tags: List[str],\n        is_zip: bool = True,\n        **kwargs: str,\n    ) -&gt; None:\n        self._portfolio = portfolio\n\n        if \" \" in name:\n            raise ValueError(\"Dataset name cannot contain spaces.\")\n        self._name = name\n\n        self._url = url\n        self._description = description\n        self._license = license\n        self._citation = citation\n        self._file_name = file_name\n        self._hash = sha256\n        self._files = files\n        self._size = size\n        self._tags = tags\n        self._is_zip = is_zip\n\n    @property\n    def portfolio(self) -&gt; str:\n        \"\"\"Name of the portfolio the dataset belong to.\n\n        Returns\n        -------\n        str\n            Name of the portfolio the dataset belong to.\n        \"\"\"\n        return self._portfolio\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Name of the dataset.\n\n        Returns\n        -------\n        str\n            Name of the dataset.\n        \"\"\"\n        return self._name\n\n    @property\n    def url(self) -&gt; str:\n        \"\"\"URL of the dataset.\n\n        Returns\n        -------\n        str\n            URL of the dataset.\n        \"\"\"\n        return self._url\n\n    @property\n    def description(self) -&gt; str:\n        \"\"\"Description of the dataset.\n\n        Returns\n        -------\n        str\n            Description of the dataset.\n        \"\"\"\n        return self._description\n\n    @property\n    def license(self) -&gt; str:\n        \"\"\"License of the dataset.\n\n        Returns\n        -------\n        str\n            License of the dataset.\n        \"\"\"\n        return self._license\n\n    @property\n    def citation(self) -&gt; str:\n        \"\"\"Citation to use when referring to the dataset.\n\n        Returns\n        -------\n        str\n            Citation to use when referring to the dataset.\n        \"\"\"\n        return self._citation\n\n    @property\n    def file_name(self) -&gt; str:\n        \"\"\"Name of the downloaded file.\n\n        Returns\n        -------\n        str\n            Name of the downloaded file.\n        \"\"\"\n        return self._file_name\n\n    @property\n    def hash(self) -&gt; str:\n        \"\"\"SHA256 hash of the downloaded file.\n\n        Returns\n        -------\n        str\n            SHA256 hash of the downloaded file.\n        \"\"\"\n        return self._hash\n\n    @property\n    def files(self) -&gt; List[str]:\n        \"\"\"Dictionary of files in the dataset.\n\n        Returns\n        -------\n        dict[str, list]\n            Dictionary of files in the dataset.\n        \"\"\"\n        return self._files\n\n    @property\n    def size(self) -&gt; float:\n        \"\"\"Size of the dataset in MB.\n\n        Returns\n        -------\n        float\n            Size of the dataset in MB.\n        \"\"\"\n        return self._size\n\n    @property\n    def tags(self) -&gt; List[str]:\n        \"\"\"List of tags associated to the dataset.\n\n        Returns\n        -------\n        List[str]\n            List of tags associated to the dataset.\n        \"\"\"\n        return self._tags\n\n    @property\n    def is_zip(self) -&gt; bool:\n        \"\"\"Whether the dataset is a zip file.\n\n        Returns\n        -------\n        bool\n            Whether the dataset is a zip file.\n        \"\"\"\n        return self._is_zip\n\n    def __str__(self) -&gt; str:\n        \"\"\"Convert PortfolioEntry to a string.\n\n        Returns\n        -------\n        str: A string containing the PortfolioEntry attributes.\n        \"\"\"\n        return str(self.to_dict())\n\n    def get_registry_name(self) -&gt; str:\n        \"\"\"Return the name of the entry in the global registry.\n\n        Returns\n        -------\n        str\n            Name of the entry.\n        \"\"\"\n        return self.portfolio + \"-\" + self.name\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert PortfolioEntry to a dictionary.\n\n        Returns\n        -------\n            dict: A dictionary containing the PortfolioEntry attributes.\n        \"\"\"\n        return {\n            \"name\": self.name,\n            \"url\": self.url,\n            \"description\": self.description,\n            \"license\": self.license,\n            \"citation\": self.citation,\n            \"file_name\": self.file_name,\n            \"hash\": self.hash,\n            \"files\": self.files,\n            \"size\": self.size,\n            \"tags\": self.tags,\n        }\n\n    def download(\n        self,\n        path: Optional[Union[str, Path]] = None,\n    ) -&gt; Union[List[str], Any]:\n        \"\"\"Download dataset in the specified path.\n\n        By default the files will be downloaded in the system's cache folder,\n        and can be retrieved using this function without downloading the file\n        anew (thanks pooch!).\n\n        Parameters\n        ----------\n        path : str | Path\n            Path to the folder in which to download the dataset. Defaults to\n            None.\n\n        Returns\n        -------\n        List[str]\n            List of path(s) to the downloaded file(s).\n        \"\"\"\n        poochfolio = get_poochfolio(path)\n\n        # download data\n        if self.is_zip:\n            return poochfolio.fetch(\n                fname=self.get_registry_name(),\n                processor=Unzip(),\n                progressbar=True,\n            )\n        else:\n            return poochfolio.fetch(\n                fname=self.get_registry_name(),\n                progressbar=True,\n            )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.citation","title":"<code>citation: str</code>  <code>property</code>","text":"<p>Citation to use when referring to the dataset.</p> <p>Returns:</p> Type Description <code>str</code> <p>Citation to use when referring to the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.description","title":"<code>description: str</code>  <code>property</code>","text":"<p>Description of the dataset.</p> <p>Returns:</p> Type Description <code>str</code> <p>Description of the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.file_name","title":"<code>file_name: str</code>  <code>property</code>","text":"<p>Name of the downloaded file.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the downloaded file.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.files","title":"<code>files: List[str]</code>  <code>property</code>","text":"<p>Dictionary of files in the dataset.</p> <p>Returns:</p> Type Description <code>dict[str, list]</code> <p>Dictionary of files in the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.hash","title":"<code>hash: str</code>  <code>property</code>","text":"<p>SHA256 hash of the downloaded file.</p> <p>Returns:</p> Type Description <code>str</code> <p>SHA256 hash of the downloaded file.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.is_zip","title":"<code>is_zip: bool</code>  <code>property</code>","text":"<p>Whether the dataset is a zip file.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the dataset is a zip file.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.license","title":"<code>license: str</code>  <code>property</code>","text":"<p>License of the dataset.</p> <p>Returns:</p> Type Description <code>str</code> <p>License of the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.name","title":"<code>name: str</code>  <code>property</code>","text":"<p>Name of the dataset.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.portfolio","title":"<code>portfolio: str</code>  <code>property</code>","text":"<p>Name of the portfolio the dataset belong to.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the portfolio the dataset belong to.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.size","title":"<code>size: float</code>  <code>property</code>","text":"<p>Size of the dataset in MB.</p> <p>Returns:</p> Type Description <code>float</code> <p>Size of the dataset in MB.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.tags","title":"<code>tags: List[str]</code>  <code>property</code>","text":"<p>List of tags associated to the dataset.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of tags associated to the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.url","title":"<code>url: str</code>  <code>property</code>","text":"<p>URL of the dataset.</p> <p>Returns:</p> Type Description <code>str</code> <p>URL of the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.__str__","title":"<code>__str__()</code>","text":"<p>Convert PortfolioEntry to a string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>A string containing the PortfolioEntry attributes.</code> Source code in <code>src/careamics_portfolio/portfolio_entry.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Convert PortfolioEntry to a string.\n\n    Returns\n    -------\n    str: A string containing the PortfolioEntry attributes.\n    \"\"\"\n    return str(self.to_dict())\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.download","title":"<code>download(path=None)</code>","text":"<p>Download dataset in the specified path.</p> <p>By default the files will be downloaded in the system's cache folder, and can be retrieved using this function without downloading the file anew (thanks pooch!).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the folder in which to download the dataset. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of path(s) to the downloaded file(s).</p> Source code in <code>src/careamics_portfolio/portfolio_entry.py</code> <pre><code>def download(\n    self,\n    path: Optional[Union[str, Path]] = None,\n) -&gt; Union[List[str], Any]:\n    \"\"\"Download dataset in the specified path.\n\n    By default the files will be downloaded in the system's cache folder,\n    and can be retrieved using this function without downloading the file\n    anew (thanks pooch!).\n\n    Parameters\n    ----------\n    path : str | Path\n        Path to the folder in which to download the dataset. Defaults to\n        None.\n\n    Returns\n    -------\n    List[str]\n        List of path(s) to the downloaded file(s).\n    \"\"\"\n    poochfolio = get_poochfolio(path)\n\n    # download data\n    if self.is_zip:\n        return poochfolio.fetch(\n            fname=self.get_registry_name(),\n            processor=Unzip(),\n            progressbar=True,\n        )\n    else:\n        return poochfolio.fetch(\n            fname=self.get_registry_name(),\n            progressbar=True,\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.get_registry_name","title":"<code>get_registry_name()</code>","text":"<p>Return the name of the entry in the global registry.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the entry.</p> Source code in <code>src/careamics_portfolio/portfolio_entry.py</code> <pre><code>def get_registry_name(self) -&gt; str:\n    \"\"\"Return the name of the entry in the global registry.\n\n    Returns\n    -------\n    str\n        Name of the entry.\n    \"\"\"\n    return self.portfolio + \"-\" + self.name\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert PortfolioEntry to a dictionary.</p> <p>Returns:</p> Type Description <code>    dict: A dictionary containing the PortfolioEntry attributes.</code> Source code in <code>src/careamics_portfolio/portfolio_entry.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Convert PortfolioEntry to a dictionary.\n\n    Returns\n    -------\n        dict: A dictionary containing the PortfolioEntry attributes.\n    \"\"\"\n    return {\n        \"name\": self.name,\n        \"url\": self.url,\n        \"description\": self.description,\n        \"license\": self.license,\n        \"citation\": self.citation,\n        \"file_name\": self.file_name,\n        \"hash\": self.hash,\n        \"files\": self.files,\n        \"size\": self.size,\n        \"tags\": self.tags,\n    }\n</code></pre>"},{"location":"reference/careamics_portfolio/utils/download_utils/","title":"download_utils","text":""},{"location":"reference/careamics_portfolio/utils/download_utils/#careamics_portfolio.utils.download_utils.get_poochfolio","title":"<code>get_poochfolio(path=None)</code>","text":"<p>Create the pooch object for the whole portfolio.</p> <p>By default the files will be downloaded and cached in the user's cache folder and can be retrieved automatically without downloading the file anew (thanks pooch!).</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>Path</code> <p>Path to the folder in which to download the dataset. Defaults to None.</p> <p>Returns:</p> Type Description <code>Pooch</code> <p>Pooch object for the whole portfolio.</p> Source code in <code>src/careamics_portfolio/utils/download_utils.py</code> <pre><code>def get_poochfolio(path: Optional[Union[str, Path]] = None) -&gt; Pooch:\n    \"\"\"Create the pooch object for the whole portfolio.\n\n    By default the files will be downloaded and cached in the user's\n    cache folder and can be retrieved automatically without downloading\n    the file anew (thanks pooch!).\n\n\n    Attributes\n    ----------\n    path : Path\n        Path to the folder in which to download the dataset. Defaults to None.\n\n    Returns\n    -------\n    Pooch\n        Pooch object for the whole portfolio.\n\n    \"\"\"\n    if path is None:\n        path = pooch.os_cache(\"portfolio\")\n\n    poochfolio = pooch.create(\n        path=path,\n        base_url=\"\",\n    )\n\n    # Path to the registry.txt file\n    poochfolio.load_registry(get_registry_path())\n\n    return poochfolio\n</code></pre>"},{"location":"reference/careamics_portfolio/utils/download_utils/#careamics_portfolio.utils.download_utils.get_registry_path","title":"<code>get_registry_path()</code>","text":"<p>Get the path to the registry.txt file.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the registry.txt file.</p> Source code in <code>src/careamics_portfolio/utils/download_utils.py</code> <pre><code>def get_registry_path() -&gt; Path:\n    \"\"\"Get the path to the registry.txt file.\n\n    Returns\n    -------\n    Path\n        Path to the registry.txt file.\n    \"\"\"\n    return Path(__file__).parent / \"../registry/registry.txt\"\n</code></pre>"},{"location":"reference/careamics_portfolio/utils/pale_blue_dot/","title":"pale_blue_dot","text":""},{"location":"reference/careamics_portfolio/utils/pale_blue_dot/#careamics_portfolio.utils.pale_blue_dot.PaleBlueDot","title":"<code>PaleBlueDot</code>","text":"<p>             Bases: <code>PortfolioEntry</code></p> <p>The original Pale Blue Dot image.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. files (list[str]): List of files in the dataset. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/utils/pale_blue_dot.py</code> <pre><code>class PaleBlueDot(PortfolioEntry):\n    \"\"\"The original Pale Blue Dot image.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        files (list[str]): List of files in the dataset.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=\"test\",\n            name=\"PaleBlueDot\",\n            url=\"https://download.fht.org/jug/careamics/P36254.jpg\",\n            file_name=\"P36254.jpg\",\n            sha256=\"68d0f037a448dc099e893b8cbf4d303ffa4b4289903c764f737101d6ad7555dd\",\n            description=\"Pale Blue Dot, credit NASA/JPL-Caltech.\"\n            \"Original caption: This narrow-angle color image of the\"\n            \" Earth, dubbed 'Pale Blue Dot', is a part of the first\"\n            \" ever 'portrait' of the solar system taken by Voyager \"\n            \"1. The spacecraft acquired a total of 60 frames for a \"\n            \"mosaic of the solar system from a distance of more \"\n            \"than 4 billion miles from Earth and about 32 degrees \"\n            \"above the ecliptic. From Voyager's great distance \"\n            \"Earth is a mere point of light, less than the size of \"\n            \"a picture element even in the narrow-angle camera. \"\n            \"Earth was a crescent only 0.12 pixel in size. \"\n            \"Coincidentally, Earth lies right in the center of one \"\n            \"of the scattered light rays resulting from taking the \"\n            \"image so close to the sun. This blown-up image of the \"\n            \"Earth was taken through three color filters - violet, \"\n            \"blue and green - and recombined to produce the color \"\n            \"image. The background features in the image are \"\n            \"artifacts resulting from the magnification.\",\n            citation=\"NASA/JPL-Caltech\",\n            license=\"Public domain\",\n            files=[\n                \"P36254.jpg\",\n            ],\n            size=0.4,\n            tags=[\"pale blue dot\", \"voyager\", \"nasa\", \"jpl\"],\n            is_zip=False,\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/utils/pale_blue_dot_zip/","title":"pale_blue_dot_zip","text":""},{"location":"reference/careamics_portfolio/utils/pale_blue_dot_zip/#careamics_portfolio.utils.pale_blue_dot_zip.PaleBlueDotZip","title":"<code>PaleBlueDotZip</code>","text":"<p>             Bases: <code>PortfolioEntry</code></p> <p>The original Pale Blue Dot image.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. files (list[str]): List of files in the dataset. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/utils/pale_blue_dot_zip.py</code> <pre><code>class PaleBlueDotZip(PortfolioEntry):\n    \"\"\"The original Pale Blue Dot image.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        files (list[str]): List of files in the dataset.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=\"test\",\n            name=\"PaleBlueDotZip\",\n            url=\"https://download.fht.org/jug/careamics/pale_blue_dot.zip\",\n            file_name=\"pale_blue_dot.zip\",\n            sha256=\"90b03ec7a9e1980fd112a40c2c935015bb349cdf89fbf3db78c715dd2a49db47\",\n            description=\"Pale Blue Dot, credit NASA/JPL-Caltech.\"\n            \"Original caption: This narrow-angle color image of the\"\n            \" Earth, dubbed 'Pale Blue Dot', is a part of the first\"\n            \" ever 'portrait' of the solar system taken by Voyager \"\n            \"1. The spacecraft acquired a total of 60 frames for a \"\n            \"mosaic of the solar system from a distance of more \"\n            \"than 4 billion miles from Earth and about 32 degrees \"\n            \"above the ecliptic. From Voyager's great distance \"\n            \"Earth is a mere point of light, less than the size of \"\n            \"a picture element even in the narrow-angle camera. \"\n            \"Earth was a crescent only 0.12 pixel in size. \"\n            \"Coincidentally, Earth lies right in the center of one \"\n            \"of the scattered light rays resulting from taking the \"\n            \"image so close to the sun. This blown-up image of the \"\n            \"Earth was taken through three color filters - violet, \"\n            \"blue and green - and recombined to produce the color \"\n            \"image. The background features in the image are \"\n            \"artifacts resulting from the magnification.\",\n            citation=\"NASA/JPL-Caltech\",\n            license=\"Public domain\",\n            files=[\n                \"P36254.jpg\",\n            ],\n            size=0.4,\n            tags=[\"pale blue dot\", \"voyager\", \"nasa\", \"jpl\"],\n            is_zip=True,\n        )\n</code></pre>"}]}